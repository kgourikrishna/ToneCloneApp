{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gbdionne/toneclone/blob/main/spectrogramCNN_alt9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mIYygHe1JGIV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7914063a-d80e-4934-ee05-27d83c1ff564"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/final_datasets\n",
        "\n",
        "!cp \"/content/drive/MyDrive/Capstone 210/Data/Final Datasets/final_real.h5\" \"/content/final_datasets/final_real.h5\"\n",
        "!cp \"/content/drive/MyDrive/Capstone 210/Data/Final Datasets/final_real.csv\" \"/content/final_datasets/final_real.csv\"\n",
        "\n",
        "!cp \"/content/drive/MyDrive/Capstone 210/Data/Final Datasets/test_extra_TRM_DLY.h5\" \"/content/final_datasets/test_extra_TRM_DLY.h5\"\n",
        "!cp \"/content/drive/MyDrive/Capstone 210/Data/Final Datasets/test_extra_TRM_DLY.csv\" \"/content/final_datasets/test_extra_TRM_DLY.csv\"\n",
        "\n",
        "!cp \"/content/drive/MyDrive/Capstone 210/Data/Final Datasets/validate_extra_TRM_DLY.h5\" \"/content/final_datasets/validate_extra_TRM_DLY.h5\"\n",
        "!cp \"/content/drive/MyDrive/Capstone 210/Data/Final Datasets/validate_extra_TRM_DLY.csv\" \"/content/final_datasets/validate_extra_TRM_DLY.csv\"\n",
        "\n",
        "!cp \"/content/drive/MyDrive/Capstone 210/Data/Final Datasets/train_extra_TRM_DLY.h5\" \"/content/final_datasets/train_extra_TRM_DLY.h5\"\n",
        "!cp \"/content/drive/MyDrive/Capstone 210/Data/Final Datasets/train_extra_TRM_DLY.csv\" \"/content/final_datasets/train_extra_TRM_DLY.csv\""
      ],
      "metadata": {
        "id": "7QQiSvhn9atV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hvDlTB85Sraj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import h5py\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "import torchaudio.transforms as T\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", message=\"Downcasting object dtype arrays on .fillna\")\n",
        "\n",
        "class SpectrogramDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom dataset for spectrogram data with data augmentation.\n",
        "    Includes:\n",
        "    - Random Gaussian noise\n",
        "    - Pitch shifting using torch.roll() with zero-padding (prevents wrapping)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hdf5_file, csv_file, augment=True, noise_level=0.03, pitch_shift_range=(-0.5, 0.5)):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            hdf5_file (str): Path to the HDF5 file containing spectrograms.\n",
        "            csv_file (str): Path to CSV file with labels.\n",
        "            augment (bool): Whether to apply data augmentation.\n",
        "            noise_level (float): Standard deviation of Gaussian noise to add.\n",
        "            pitch_shift_range (tuple): Min/max semitones for pitch shifting.\n",
        "        \"\"\"\n",
        "        self.hdf5_file_path = hdf5_file\n",
        "        self.labels = pd.read_csv(csv_file)\n",
        "\n",
        "        # Manually define only important columns\n",
        "        self.label_map = [\n",
        "            'overdrive', 'distortion', 'fuzz', 'tremolo', 'phaser',\n",
        "            'flanger', 'chorus', 'delay', 'hall_reverb', 'plate_reverb',\n",
        "            'octaver', 'auto_filter'\n",
        "        ]\n",
        "\n",
        "        # Drop all non-label columns\n",
        "        self.labels = self.labels[['key'] + self.label_map]\n",
        "\n",
        "        self.hdf5_file = None  # Open HDF5 file once per worker\n",
        "\n",
        "        self.augment = augment\n",
        "        self.noise_level = noise_level\n",
        "        self.pitch_shift_range = pitch_shift_range\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Open HDF5 file per worker to avoid threading issues\n",
        "        if self.hdf5_file is None:\n",
        "            self.hdf5_file = h5py.File(self.hdf5_file_path, \"r\", swmr=True)\n",
        "\n",
        "        # Retrieve spectrogram\n",
        "        key = self.labels.iloc[idx]['key']\n",
        "        spectrogram = torch.tensor(self.hdf5_file[key][()], dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "        # Retrieve labels\n",
        "        label_values = self.labels.iloc[idx][1:].fillna(0).astype(float).values\n",
        "        label = torch.tensor(label_values, dtype=torch.float32)\n",
        "\n",
        "        # Data augmentation\n",
        "        if self.augment:\n",
        "            spectrogram = self.add_noise(spectrogram)\n",
        "            spectrogram = self.pitch_shift(spectrogram)\n",
        "\n",
        "        return spectrogram, label\n",
        "\n",
        "    def add_noise(self, spectrogram):\n",
        "        \"\"\"Adds Gaussian noise where noise level is randomly chosen between 0 and self.noise_level.\"\"\"\n",
        "        noise_level = random.uniform(0, self.noise_level)  # Random noise per sample\n",
        "        noise = torch.randn_like(spectrogram) * noise_level  # Scale noise\n",
        "        return spectrogram + noise\n",
        "\n",
        "    def pitch_shift(self, spectrogram):\n",
        "        \"\"\"Shifts spectrogram frequency bins using torch.roll() with zero padding.\"\"\"\n",
        "        semitone_shift = random.uniform(*self.pitch_shift_range)  # Random shift between min/max\n",
        "        shift_bins = int(semitone_shift / 12 * spectrogram.shape[-2])  # Convert semitone shift to frequency bins\n",
        "\n",
        "        # Apply frequency bin shift using torch.roll() with zero-padding\n",
        "        shifted = torch.roll(spectrogram, shifts=shift_bins, dims=-2)  # Shift along frequency axis\n",
        "\n",
        "        if shift_bins > 0:  # Shift up (higher pitch)\n",
        "            shifted[..., :shift_bins, :] = 0  # Zero-pad low frequencies\n",
        "        elif shift_bins < 0:  # Shift down (lower pitch)\n",
        "            shifted[..., shift_bins:, :] = 0  # Zero-pad high frequencies\n",
        "\n",
        "        return shifted\n",
        "\n",
        "    def __del__(self):\n",
        "        if self.hdf5_file is not None:\n",
        "            self.hdf5_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pVGFYMDhDnI9"
      },
      "outputs": [],
      "source": [
        "class spectrogramCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(spectrogramCNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(512)\n",
        "\n",
        "        # Global average pooling\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(512, 256)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.max_pool2d(x, 2)  # Max pooling\n",
        "\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = F.relu(self.bn5(self.conv5(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = self.global_avg_pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x) # Dropout\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "p3BlietYUQpv"
      },
      "outputs": [],
      "source": [
        "# Initialize dataset from HD5F and csv file\n",
        "\n",
        "h5_train_path = '/content/final_datasets/train_extra_TRM_DLY.h5'\n",
        "csv_train_path = '/content/final_datasets/train_extra_TRM_DLY.csv'\n",
        "\n",
        "h5_val_path = '/content/final_datasets/validate_extra_TRM_DLY.h5'\n",
        "csv_val_path = '/content/final_datasets/validate_extra_TRM_DLY.csv'\n",
        "\n",
        "model_save_path = \"/content/drive/MyDrive/Capstone 210/Models/final_multi_effects_alt9.mod\"\n",
        "\n",
        "train_dataset = SpectrogramDataset(h5_train_path, csv_train_path)\n",
        "val_dataset = SpectrogramDataset(h5_val_path, csv_val_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUEbBB7wX05C",
        "outputId": "9131da25-1a75-4e8b-f367-69bf0bebde86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/25], Batch [100/4502], Loss: 0.2853\n",
            "Epoch [1/25], Batch [200/4502], Loss: 0.2481\n",
            "Epoch [1/25], Batch [300/4502], Loss: 0.1728\n",
            "Epoch [1/25], Batch [400/4502], Loss: 0.1511\n",
            "Epoch [1/25], Batch [500/4502], Loss: 0.1333\n",
            "Epoch [1/25], Batch [600/4502], Loss: 0.1355\n",
            "Epoch [1/25], Batch [700/4502], Loss: 0.1112\n",
            "Epoch [1/25], Batch [800/4502], Loss: 0.1123\n",
            "Epoch [1/25], Batch [900/4502], Loss: 0.0947\n",
            "Epoch [1/25], Batch [1000/4502], Loss: 0.0733\n",
            "Epoch [1/25], Batch [1100/4502], Loss: 0.0978\n",
            "Epoch [1/25], Batch [1200/4502], Loss: 0.0783\n",
            "Epoch [1/25], Batch [1300/4502], Loss: 0.1070\n",
            "Epoch [1/25], Batch [1400/4502], Loss: 0.0775\n",
            "Epoch [1/25], Batch [1500/4502], Loss: 0.0689\n",
            "Epoch [1/25], Batch [1600/4502], Loss: 0.0731\n",
            "Epoch [1/25], Batch [1700/4502], Loss: 0.0833\n",
            "Epoch [1/25], Batch [1800/4502], Loss: 0.0465\n",
            "Epoch [1/25], Batch [1900/4502], Loss: 0.0411\n",
            "Epoch [1/25], Batch [2000/4502], Loss: 0.0399\n",
            "Epoch [1/25], Batch [2100/4502], Loss: 0.0342\n",
            "Epoch [1/25], Batch [2200/4502], Loss: 0.0360\n",
            "Epoch [1/25], Batch [2300/4502], Loss: 0.0537\n",
            "Epoch [1/25], Batch [2400/4502], Loss: 0.0360\n",
            "Epoch [1/25], Batch [2500/4502], Loss: 0.0337\n",
            "Epoch [1/25], Batch [2600/4502], Loss: 0.0483\n",
            "Epoch [1/25], Batch [2700/4502], Loss: 0.0515\n",
            "Epoch [1/25], Batch [2800/4502], Loss: 0.0309\n",
            "Epoch [1/25], Batch [2900/4502], Loss: 0.0217\n",
            "Epoch [1/25], Batch [3000/4502], Loss: 0.0376\n",
            "Epoch [1/25], Batch [3100/4502], Loss: 0.0273\n",
            "Epoch [1/25], Batch [3200/4502], Loss: 0.0328\n",
            "Epoch [1/25], Batch [3300/4502], Loss: 0.0296\n",
            "Epoch [1/25], Batch [3400/4502], Loss: 0.0335\n",
            "Epoch [1/25], Batch [3500/4502], Loss: 0.0314\n",
            "Epoch [1/25], Batch [3600/4502], Loss: 0.0239\n",
            "Epoch [1/25], Batch [3700/4502], Loss: 0.0260\n",
            "Epoch [1/25], Batch [3800/4502], Loss: 0.0366\n",
            "Epoch [1/25], Batch [3900/4502], Loss: 0.0295\n",
            "Epoch [1/25], Batch [4000/4502], Loss: 0.0236\n",
            "Epoch [1/25], Batch [4100/4502], Loss: 0.0310\n",
            "Epoch [1/25], Batch [4200/4502], Loss: 0.0354\n",
            "Epoch [1/25], Batch [4300/4502], Loss: 0.0198\n",
            "Epoch [1/25], Batch [4400/4502], Loss: 0.0413\n",
            "Epoch [1/25], Batch [4500/4502], Loss: 0.0246\n",
            "Epoch 1/25, Loss: 0.07629323360187042\n",
            "Updated Learning Rate: [8.681e-05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   overdrive       0.99      0.96      0.98      3012\n",
            "  distortion       1.00      0.89      0.94      4518\n",
            "        fuzz       0.94      1.00      0.97      5271\n",
            "     tremolo       1.00      0.97      0.99      5671\n",
            "      phaser       1.00      0.98      0.99      4518\n",
            "     flanger       0.99      0.90      0.95      3012\n",
            "      chorus       1.00      1.00      1.00      5671\n",
            "       delay       0.40      1.00      0.57      7530\n",
            " hall_reverb       0.95      0.80      0.87      4518\n",
            "plate_reverb       0.97      0.84      0.90      3012\n",
            "     octaver       0.95      0.99      0.97      2259\n",
            " auto_filter       1.00      0.98      0.99      3765\n",
            "\n",
            "   micro avg       0.80      0.95      0.87     52757\n",
            "   macro avg       0.93      0.94      0.92     52757\n",
            "weighted avg       0.90      0.95      0.90     52757\n",
            " samples avg       0.80      0.92      0.84     52757\n",
            "\n",
            "\n",
            "Validation Loss: 0.1243, Accuracy: 0.5664, Precision: 0.9319, Recall: 0.9424, F1-score: 0.9248\n",
            "\n",
            "Model saved to /content/drive/MyDrive/Capstone 210/Models/final_multi_effects_alt9.mod\n",
            "Epoch [2/25], Batch [100/4502], Loss: 0.0380\n",
            "Epoch [2/25], Batch [200/4502], Loss: 0.0242\n",
            "Epoch [2/25], Batch [300/4502], Loss: 0.0365\n",
            "Epoch [2/25], Batch [400/4502], Loss: 0.0330\n",
            "Epoch [2/25], Batch [500/4502], Loss: 0.0095\n",
            "Epoch [2/25], Batch [600/4502], Loss: 0.0135\n",
            "Epoch [2/25], Batch [700/4502], Loss: 0.0195\n",
            "Epoch [2/25], Batch [800/4502], Loss: 0.0087\n",
            "Epoch [2/25], Batch [900/4502], Loss: 0.0135\n",
            "Epoch [2/25], Batch [1000/4502], Loss: 0.0245\n",
            "Epoch [2/25], Batch [1100/4502], Loss: 0.0217\n",
            "Epoch [2/25], Batch [1200/4502], Loss: 0.0100\n",
            "Epoch [2/25], Batch [1300/4502], Loss: 0.0495\n",
            "Epoch [2/25], Batch [1400/4502], Loss: 0.0148\n",
            "Epoch [2/25], Batch [1500/4502], Loss: 0.0233\n",
            "Epoch [2/25], Batch [1600/4502], Loss: 0.0184\n",
            "Epoch [2/25], Batch [1700/4502], Loss: 0.0224\n",
            "Epoch [2/25], Batch [1800/4502], Loss: 0.0190\n",
            "Epoch [2/25], Batch [1900/4502], Loss: 0.0137\n",
            "Epoch [2/25], Batch [2000/4502], Loss: 0.0292\n",
            "Epoch [2/25], Batch [2100/4502], Loss: 0.0122\n",
            "Epoch [2/25], Batch [2200/4502], Loss: 0.0057\n",
            "Epoch [2/25], Batch [2300/4502], Loss: 0.0095\n",
            "Epoch [2/25], Batch [2400/4502], Loss: 0.0113\n",
            "Epoch [2/25], Batch [2500/4502], Loss: 0.0244\n",
            "Epoch [2/25], Batch [2600/4502], Loss: 0.0069\n",
            "Epoch [2/25], Batch [2700/4502], Loss: 0.0102\n",
            "Epoch [2/25], Batch [2800/4502], Loss: 0.0209\n",
            "Epoch [2/25], Batch [2900/4502], Loss: 0.0071\n",
            "Epoch [2/25], Batch [3000/4502], Loss: 0.0204\n",
            "Epoch [2/25], Batch [3100/4502], Loss: 0.0117\n",
            "Epoch [2/25], Batch [3200/4502], Loss: 0.0193\n",
            "Epoch [2/25], Batch [3300/4502], Loss: 0.0285\n",
            "Epoch [2/25], Batch [3400/4502], Loss: 0.0144\n",
            "Epoch [2/25], Batch [3500/4502], Loss: 0.0143\n",
            "Epoch [2/25], Batch [3600/4502], Loss: 0.0221\n",
            "Epoch [2/25], Batch [3700/4502], Loss: 0.0176\n",
            "Epoch [2/25], Batch [3800/4502], Loss: 0.0190\n",
            "Epoch [2/25], Batch [3900/4502], Loss: 0.0111\n",
            "Epoch [2/25], Batch [4000/4502], Loss: 0.0308\n",
            "Epoch [2/25], Batch [4100/4502], Loss: 0.0061\n",
            "Epoch [2/25], Batch [4200/4502], Loss: 0.0091\n",
            "Epoch [2/25], Batch [4300/4502], Loss: 0.0174\n",
            "Epoch [2/25], Batch [4400/4502], Loss: 0.0036\n",
            "Epoch [2/25], Batch [4500/4502], Loss: 0.0048\n",
            "Epoch 2/25, Loss: 0.01994175128653225\n",
            "Updated Learning Rate: [7.5359761e-05]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   overdrive       0.99      1.00      0.99      3012\n",
            "  distortion       1.00      0.99      0.99      4518\n",
            "        fuzz       1.00      1.00      1.00      5271\n",
            "     tremolo       1.00      1.00      1.00      5671\n",
            "      phaser       1.00      0.99      1.00      4518\n",
            "     flanger       1.00      0.88      0.94      3012\n",
            "      chorus       1.00      1.00      1.00      5671\n",
            "       delay       0.95      0.98      0.97      7530\n",
            " hall_reverb       0.95      0.93      0.94      4518\n",
            "plate_reverb       0.97      0.91      0.94      3012\n",
            "     octaver       0.96      0.99      0.98      2259\n",
            " auto_filter       1.00      1.00      1.00      3765\n",
            "\n",
            "   micro avg       0.98      0.98      0.98     52757\n",
            "   macro avg       0.98      0.97      0.98     52757\n",
            "weighted avg       0.98      0.98      0.98     52757\n",
            " samples avg       0.95      0.95      0.95     52757\n",
            "\n",
            "\n",
            "Validation Loss: 0.0169, Accuracy: 0.9411, Precision: 0.9849, Recall: 0.9713, F1-score: 0.9777\n",
            "\n",
            "Model saved to /content/drive/MyDrive/Capstone 210/Models/final_multi_effects_alt9.mod\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/25], Batch [100/4502], Loss: 0.0146\n",
            "Epoch [3/25], Batch [200/4502], Loss: 0.0058\n",
            "Epoch [3/25], Batch [300/4502], Loss: 0.0116\n",
            "Epoch [3/25], Batch [400/4502], Loss: 0.0190\n",
            "Epoch [3/25], Batch [500/4502], Loss: 0.0220\n",
            "Epoch [3/25], Batch [600/4502], Loss: 0.0172\n",
            "Epoch [3/25], Batch [700/4502], Loss: 0.0151\n",
            "Epoch [3/25], Batch [800/4502], Loss: 0.0508\n",
            "Epoch [3/25], Batch [900/4502], Loss: 0.0055\n",
            "Epoch [3/25], Batch [1000/4502], Loss: 0.0117\n",
            "Epoch [3/25], Batch [1100/4502], Loss: 0.0085\n",
            "Epoch [3/25], Batch [1200/4502], Loss: 0.0177\n",
            "Epoch [3/25], Batch [1300/4502], Loss: 0.0030\n",
            "Epoch [3/25], Batch [1400/4502], Loss: 0.0041\n",
            "Epoch [3/25], Batch [1500/4502], Loss: 0.0212\n",
            "Epoch [3/25], Batch [1600/4502], Loss: 0.0071\n",
            "Epoch [3/25], Batch [1700/4502], Loss: 0.0165\n",
            "Epoch [3/25], Batch [1800/4502], Loss: 0.0067\n",
            "Epoch [3/25], Batch [1900/4502], Loss: 0.0086\n",
            "Epoch [3/25], Batch [2000/4502], Loss: 0.0031\n",
            "Epoch [3/25], Batch [2100/4502], Loss: 0.0054\n",
            "Epoch [3/25], Batch [2200/4502], Loss: 0.0137\n",
            "Epoch [3/25], Batch [2300/4502], Loss: 0.0152\n",
            "Epoch [3/25], Batch [2400/4502], Loss: 0.0058\n",
            "Epoch [3/25], Batch [2500/4502], Loss: 0.0292\n",
            "Epoch [3/25], Batch [2600/4502], Loss: 0.0065\n",
            "Epoch [3/25], Batch [2700/4502], Loss: 0.0025\n",
            "Epoch [3/25], Batch [2800/4502], Loss: 0.0126\n",
            "Epoch [3/25], Batch [2900/4502], Loss: 0.0268\n",
            "Epoch [3/25], Batch [3000/4502], Loss: 0.0105\n",
            "Epoch [3/25], Batch [3100/4502], Loss: 0.0230\n",
            "Epoch [3/25], Batch [3200/4502], Loss: 0.0059\n",
            "Epoch [3/25], Batch [3300/4502], Loss: 0.0187\n",
            "Epoch [3/25], Batch [3400/4502], Loss: 0.0097\n",
            "Epoch [3/25], Batch [3500/4502], Loss: 0.0033\n",
            "Epoch [3/25], Batch [3600/4502], Loss: 0.0133\n",
            "Epoch [3/25], Batch [3700/4502], Loss: 0.0079\n",
            "Epoch [3/25], Batch [3800/4502], Loss: 0.0042\n",
            "Epoch [3/25], Batch [3900/4502], Loss: 0.0208\n",
            "Epoch [3/25], Batch [4000/4502], Loss: 0.0200\n",
            "Epoch [3/25], Batch [4100/4502], Loss: 0.0038\n",
            "Epoch [3/25], Batch [4200/4502], Loss: 0.0252\n",
            "Epoch [3/25], Batch [4300/4502], Loss: 0.0137\n",
            "Epoch [3/25], Batch [4400/4502], Loss: 0.0297\n",
            "Epoch [3/25], Batch [4500/4502], Loss: 0.0338\n",
            "Epoch 3/25, Loss: 0.013050490844955891\n",
            "Updated Learning Rate: [6.54198085241e-05]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   overdrive       0.92      1.00      0.96      3012\n",
            "  distortion       1.00      0.99      1.00      4518\n",
            "        fuzz       1.00      0.99      1.00      5271\n",
            "     tremolo       1.00      0.97      0.99      5671\n",
            "      phaser       1.00      0.98      0.99      4518\n",
            "     flanger       0.99      0.97      0.98      3012\n",
            "      chorus       1.00      1.00      1.00      5671\n",
            "       delay       0.95      0.97      0.96      7530\n",
            " hall_reverb       0.93      0.89      0.91      4518\n",
            "plate_reverb       0.79      0.97      0.87      3012\n",
            "     octaver       0.98      0.98      0.98      2259\n",
            " auto_filter       1.00      1.00      1.00      3765\n",
            "\n",
            "   micro avg       0.96      0.98      0.97     52757\n",
            "   macro avg       0.96      0.98      0.97     52757\n",
            "weighted avg       0.97      0.98      0.97     52757\n",
            " samples avg       0.94      0.95      0.94     52757\n",
            "\n",
            "\n",
            "Validation Loss: 0.0234, Accuracy: 0.9182, Precision: 0.9621, Recall: 0.9766, F1-score: 0.9683\n",
            "\n",
            "Model saved to /content/drive/MyDrive/Capstone 210/Models/final_multi_effects_alt9.mod\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/25], Batch [100/4502], Loss: 0.0031\n",
            "Epoch [4/25], Batch [200/4502], Loss: 0.0111\n",
            "Epoch [4/25], Batch [300/4502], Loss: 0.0066\n",
            "Epoch [4/25], Batch [400/4502], Loss: 0.0062\n",
            "Epoch [4/25], Batch [500/4502], Loss: 0.0174\n",
            "Epoch [4/25], Batch [600/4502], Loss: 0.0209\n",
            "Epoch [4/25], Batch [700/4502], Loss: 0.0064\n",
            "Epoch [4/25], Batch [800/4502], Loss: 0.0061\n",
            "Epoch [4/25], Batch [900/4502], Loss: 0.0035\n",
            "Epoch [4/25], Batch [1000/4502], Loss: 0.0140\n",
            "Epoch [4/25], Batch [1100/4502], Loss: 0.0268\n",
            "Epoch [4/25], Batch [1200/4502], Loss: 0.0030\n",
            "Epoch [4/25], Batch [1300/4502], Loss: 0.0031\n",
            "Epoch [4/25], Batch [1400/4502], Loss: 0.0050\n",
            "Epoch [4/25], Batch [1500/4502], Loss: 0.0052\n",
            "Epoch [4/25], Batch [1600/4502], Loss: 0.0090\n",
            "Epoch [4/25], Batch [1700/4502], Loss: 0.0177\n",
            "Epoch [4/25], Batch [1800/4502], Loss: 0.0028\n",
            "Epoch [4/25], Batch [1900/4502], Loss: 0.0196\n",
            "Epoch [4/25], Batch [2000/4502], Loss: 0.0092\n",
            "Epoch [4/25], Batch [2100/4502], Loss: 0.0088\n",
            "Epoch [4/25], Batch [2200/4502], Loss: 0.0069\n",
            "Epoch [4/25], Batch [2300/4502], Loss: 0.0072\n",
            "Epoch [4/25], Batch [2400/4502], Loss: 0.0080\n",
            "Epoch [4/25], Batch [2500/4502], Loss: 0.0194\n",
            "Epoch [4/25], Batch [2600/4502], Loss: 0.0018\n",
            "Epoch [4/25], Batch [2700/4502], Loss: 0.0379\n",
            "Epoch [4/25], Batch [2800/4502], Loss: 0.0110\n",
            "Epoch [4/25], Batch [2900/4502], Loss: 0.0070\n",
            "Epoch [4/25], Batch [3000/4502], Loss: 0.0054\n",
            "Epoch [4/25], Batch [3100/4502], Loss: 0.0159\n",
            "Epoch [4/25], Batch [3200/4502], Loss: 0.0115\n",
            "Epoch [4/25], Batch [3300/4502], Loss: 0.0099\n",
            "Epoch [4/25], Batch [3400/4502], Loss: 0.0055\n",
            "Epoch [4/25], Batch [3500/4502], Loss: 0.0025\n",
            "Epoch [4/25], Batch [3600/4502], Loss: 0.0242\n",
            "Epoch [4/25], Batch [3700/4502], Loss: 0.0061\n",
            "Epoch [4/25], Batch [3800/4502], Loss: 0.0178\n",
            "Epoch [4/25], Batch [3900/4502], Loss: 0.0025\n",
            "Epoch [4/25], Batch [4000/4502], Loss: 0.0110\n",
            "Epoch [4/25], Batch [4100/4502], Loss: 0.0129\n",
            "Epoch [4/25], Batch [4200/4502], Loss: 0.0056\n",
            "Epoch [4/25], Batch [4300/4502], Loss: 0.0083\n",
            "Epoch [4/25], Batch [4400/4502], Loss: 0.0020\n",
            "Epoch [4/25], Batch [4500/4502], Loss: 0.0091\n",
            "Epoch 4/25, Loss: 0.009750427205519675\n",
            "Updated Learning Rate: [5.679093577977121e-05]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   overdrive       1.00      1.00      1.00      3012\n",
            "  distortion       1.00      1.00      1.00      4518\n",
            "        fuzz       1.00      1.00      1.00      5271\n",
            "     tremolo       1.00      1.00      1.00      5671\n",
            "      phaser       0.99      1.00      1.00      4518\n",
            "     flanger       0.99      0.99      0.99      3012\n",
            "      chorus       1.00      1.00      1.00      5671\n",
            "       delay       0.98      0.98      0.98      7530\n",
            " hall_reverb       0.93      0.99      0.96      4518\n",
            "plate_reverb       0.97      0.96      0.97      3012\n",
            "     octaver       0.99      1.00      0.99      2259\n",
            " auto_filter       1.00      1.00      1.00      3765\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     52757\n",
            "   macro avg       0.99      0.99      0.99     52757\n",
            "weighted avg       0.99      0.99      0.99     52757\n",
            " samples avg       0.96      0.97      0.96     52757\n",
            "\n",
            "\n",
            "Validation Loss: 0.0083, Accuracy: 0.9685, Precision: 0.9876, Recall: 0.9913, F1-score: 0.9894\n",
            "\n",
            "Model saved to /content/drive/MyDrive/Capstone 210/Models/final_multi_effects_alt9.mod\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/25], Batch [100/4502], Loss: 0.0026\n",
            "Epoch [5/25], Batch [200/4502], Loss: 0.0163\n",
            "Epoch [5/25], Batch [300/4502], Loss: 0.0013\n",
            "Epoch [5/25], Batch [400/4502], Loss: 0.0046\n",
            "Epoch [5/25], Batch [500/4502], Loss: 0.0090\n",
            "Epoch [5/25], Batch [600/4502], Loss: 0.0101\n",
            "Epoch [5/25], Batch [700/4502], Loss: 0.0011\n",
            "Epoch [5/25], Batch [800/4502], Loss: 0.0031\n",
            "Epoch [5/25], Batch [900/4502], Loss: 0.0060\n",
            "Epoch [5/25], Batch [1000/4502], Loss: 0.0054\n",
            "Epoch [5/25], Batch [1100/4502], Loss: 0.0176\n",
            "Epoch [5/25], Batch [1200/4502], Loss: 0.0011\n",
            "Epoch [5/25], Batch [1300/4502], Loss: 0.0127\n",
            "Epoch [5/25], Batch [1400/4502], Loss: 0.0026\n",
            "Epoch [5/25], Batch [1500/4502], Loss: 0.0172\n",
            "Epoch [5/25], Batch [1600/4502], Loss: 0.0032\n",
            "Epoch [5/25], Batch [1700/4502], Loss: 0.0015\n",
            "Epoch [5/25], Batch [1800/4502], Loss: 0.0102\n",
            "Epoch [5/25], Batch [1900/4502], Loss: 0.0032\n",
            "Epoch [5/25], Batch [2000/4502], Loss: 0.0006\n",
            "Epoch [5/25], Batch [2100/4502], Loss: 0.0153\n",
            "Epoch [5/25], Batch [2200/4502], Loss: 0.0028\n",
            "Epoch [5/25], Batch [2300/4502], Loss: 0.0026\n",
            "Epoch [5/25], Batch [2400/4502], Loss: 0.0007\n",
            "Epoch [5/25], Batch [2500/4502], Loss: 0.0015\n",
            "Epoch [5/25], Batch [2600/4502], Loss: 0.0028\n",
            "Epoch [5/25], Batch [2700/4502], Loss: 0.0022\n",
            "Epoch [5/25], Batch [2800/4502], Loss: 0.0103\n",
            "Epoch [5/25], Batch [2900/4502], Loss: 0.0055\n",
            "Epoch [5/25], Batch [3000/4502], Loss: 0.0008\n",
            "Epoch [5/25], Batch [3100/4502], Loss: 0.0045\n",
            "Epoch [5/25], Batch [3200/4502], Loss: 0.0022\n",
            "Epoch [5/25], Batch [3300/4502], Loss: 0.0014\n",
            "Epoch [5/25], Batch [3400/4502], Loss: 0.0013\n",
            "Epoch [5/25], Batch [3500/4502], Loss: 0.0039\n",
            "Epoch [5/25], Batch [3600/4502], Loss: 0.0021\n",
            "Epoch [5/25], Batch [3700/4502], Loss: 0.0007\n",
            "Epoch [5/25], Batch [3800/4502], Loss: 0.0078\n",
            "Epoch [5/25], Batch [3900/4502], Loss: 0.0013\n",
            "Epoch [5/25], Batch [4000/4502], Loss: 0.0029\n",
            "Epoch [5/25], Batch [4100/4502], Loss: 0.0073\n",
            "Epoch [5/25], Batch [4200/4502], Loss: 0.0156\n",
            "Epoch [5/25], Batch [4300/4502], Loss: 0.0010\n",
            "Epoch [5/25], Batch [4400/4502], Loss: 0.0011\n",
            "Epoch [5/25], Batch [4500/4502], Loss: 0.0153\n",
            "Epoch 5/25, Loss: 0.007877657545145758\n",
            "Updated Learning Rate: [4.930021135041938e-05]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   overdrive       0.96      1.00      0.98      3012\n",
            "  distortion       1.00      0.99      0.99      4518\n",
            "        fuzz       1.00      1.00      1.00      5271\n",
            "     tremolo       1.00      0.99      1.00      5671\n",
            "      phaser       1.00      1.00      1.00      4518\n",
            "     flanger       0.99      0.99      0.99      3012\n",
            "      chorus       1.00      1.00      1.00      5671\n",
            "       delay       0.96      0.99      0.97      7530\n",
            " hall_reverb       1.00      0.87      0.93      4518\n",
            "plate_reverb       0.91      0.96      0.94      3012\n",
            "     octaver       0.99      0.99      0.99      2259\n",
            " auto_filter       1.00      0.99      1.00      3765\n",
            "\n",
            "   micro avg       0.98      0.98      0.98     52757\n",
            "   macro avg       0.98      0.98      0.98     52757\n",
            "weighted avg       0.98      0.98      0.98     52757\n",
            " samples avg       0.96      0.96      0.96     52757\n",
            "\n",
            "\n",
            "Validation Loss: 0.0135, Accuracy: 0.9483, Precision: 0.9829, Recall: 0.9809, F1-score: 0.9814\n",
            "\n",
            "Model saved to /content/drive/MyDrive/Capstone 210/Models/final_multi_effects_alt9.mod\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/25], Batch [100/4502], Loss: 0.0309\n",
            "Epoch [6/25], Batch [200/4502], Loss: 0.0176\n",
            "Epoch [6/25], Batch [300/4502], Loss: 0.0045\n",
            "Epoch [6/25], Batch [400/4502], Loss: 0.0029\n",
            "Epoch [6/25], Batch [500/4502], Loss: 0.0038\n",
            "Epoch [6/25], Batch [600/4502], Loss: 0.0059\n",
            "Epoch [6/25], Batch [700/4502], Loss: 0.0210\n",
            "Epoch [6/25], Batch [800/4502], Loss: 0.0011\n",
            "Epoch [6/25], Batch [900/4502], Loss: 0.0010\n",
            "Epoch [6/25], Batch [1000/4502], Loss: 0.0097\n",
            "Epoch [6/25], Batch [1100/4502], Loss: 0.0022\n",
            "Epoch [6/25], Batch [1200/4502], Loss: 0.0189\n",
            "Epoch [6/25], Batch [1300/4502], Loss: 0.0051\n",
            "Epoch [6/25], Batch [1400/4502], Loss: 0.0029\n",
            "Epoch [6/25], Batch [1500/4502], Loss: 0.0058\n",
            "Epoch [6/25], Batch [1600/4502], Loss: 0.0205\n",
            "Epoch [6/25], Batch [1700/4502], Loss: 0.0029\n",
            "Epoch [6/25], Batch [1800/4502], Loss: 0.0063\n",
            "Epoch [6/25], Batch [1900/4502], Loss: 0.0037\n",
            "Epoch [6/25], Batch [2000/4502], Loss: 0.0035\n",
            "Epoch [6/25], Batch [2100/4502], Loss: 0.0009\n",
            "Epoch [6/25], Batch [2200/4502], Loss: 0.0017\n",
            "Epoch [6/25], Batch [2300/4502], Loss: 0.0002\n",
            "Epoch [6/25], Batch [2400/4502], Loss: 0.0004\n",
            "Epoch [6/25], Batch [2500/4502], Loss: 0.0017\n",
            "Epoch [6/25], Batch [2600/4502], Loss: 0.0002\n",
            "Epoch [6/25], Batch [2700/4502], Loss: 0.0069\n",
            "Epoch [6/25], Batch [2800/4502], Loss: 0.0009\n",
            "Epoch [6/25], Batch [2900/4502], Loss: 0.0166\n",
            "Epoch [6/25], Batch [3000/4502], Loss: 0.0276\n",
            "Epoch [6/25], Batch [3100/4502], Loss: 0.0112\n",
            "Epoch [6/25], Batch [3200/4502], Loss: 0.0042\n",
            "Epoch [6/25], Batch [3300/4502], Loss: 0.0007\n",
            "Epoch [6/25], Batch [3400/4502], Loss: 0.0116\n",
            "Epoch [6/25], Batch [3500/4502], Loss: 0.0015\n",
            "Epoch [6/25], Batch [3600/4502], Loss: 0.0028\n",
            "Epoch [6/25], Batch [3700/4502], Loss: 0.0047\n",
            "Epoch [6/25], Batch [3800/4502], Loss: 0.0137\n",
            "Epoch [6/25], Batch [3900/4502], Loss: 0.0006\n",
            "Epoch [6/25], Batch [4000/4502], Loss: 0.0040\n",
            "Epoch [6/25], Batch [4100/4502], Loss: 0.0117\n",
            "Epoch [6/25], Batch [4200/4502], Loss: 0.0061\n",
            "Epoch [6/25], Batch [4300/4502], Loss: 0.0024\n",
            "Epoch [6/25], Batch [4400/4502], Loss: 0.0023\n",
            "Epoch [6/25], Batch [4500/4502], Loss: 0.0026\n",
            "Epoch 6/25, Loss: 0.0068819149840054486\n",
            "Updated Learning Rate: [4.279751347329907e-05]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   overdrive       1.00      1.00      1.00      3012\n",
            "  distortion       1.00      1.00      1.00      4518\n",
            "        fuzz       1.00      1.00      1.00      5271\n",
            "     tremolo       1.00      1.00      1.00      5671\n",
            "      phaser       1.00      1.00      1.00      4518\n",
            "     flanger       1.00      0.98      0.99      3012\n",
            "      chorus       1.00      1.00      1.00      5671\n",
            "       delay       1.00      0.94      0.97      7530\n",
            " hall_reverb       0.92      0.95      0.93      4518\n",
            "plate_reverb       0.83      1.00      0.91      3012\n",
            "     octaver       0.95      1.00      0.97      2259\n",
            " auto_filter       1.00      1.00      1.00      3765\n",
            "\n",
            "   micro avg       0.98      0.98      0.98     52757\n",
            "   macro avg       0.97      0.99      0.98     52757\n",
            "weighted avg       0.98      0.98      0.98     52757\n",
            " samples avg       0.95      0.96      0.95     52757\n",
            "\n",
            "\n",
            "Validation Loss: 0.0169, Accuracy: 0.9488, Precision: 0.9732, Recall: 0.9876, F1-score: 0.9796\n",
            "\n",
            "Model saved to /content/drive/MyDrive/Capstone 210/Models/final_multi_effects_alt9.mod\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/25], Batch [100/4502], Loss: 0.0075\n",
            "Epoch [7/25], Batch [200/4502], Loss: 0.0052\n",
            "Epoch [7/25], Batch [300/4502], Loss: 0.0079\n",
            "Epoch [7/25], Batch [400/4502], Loss: 0.0009\n",
            "Epoch [7/25], Batch [500/4502], Loss: 0.0009\n",
            "Epoch [7/25], Batch [600/4502], Loss: 0.0161\n",
            "Epoch [7/25], Batch [700/4502], Loss: 0.0046\n",
            "Epoch [7/25], Batch [800/4502], Loss: 0.0018\n",
            "Epoch [7/25], Batch [900/4502], Loss: 0.0211\n",
            "Epoch [7/25], Batch [1000/4502], Loss: 0.0009\n",
            "Epoch [7/25], Batch [1100/4502], Loss: 0.0007\n",
            "Epoch [7/25], Batch [1200/4502], Loss: 0.0096\n",
            "Epoch [7/25], Batch [1300/4502], Loss: 0.0049\n",
            "Epoch [7/25], Batch [1400/4502], Loss: 0.0055\n",
            "Epoch [7/25], Batch [1500/4502], Loss: 0.0008\n",
            "Epoch [7/25], Batch [1600/4502], Loss: 0.0010\n",
            "Epoch [7/25], Batch [1700/4502], Loss: 0.0113\n",
            "Epoch [7/25], Batch [1800/4502], Loss: 0.0202\n",
            "Epoch [7/25], Batch [1900/4502], Loss: 0.0055\n",
            "Epoch [7/25], Batch [2000/4502], Loss: 0.0052\n",
            "Epoch [7/25], Batch [2100/4502], Loss: 0.0020\n",
            "Epoch [7/25], Batch [2200/4502], Loss: 0.0023\n",
            "Epoch [7/25], Batch [2300/4502], Loss: 0.0022\n",
            "Epoch [7/25], Batch [2400/4502], Loss: 0.0014\n",
            "Epoch [7/25], Batch [2500/4502], Loss: 0.0034\n",
            "Epoch [7/25], Batch [2600/4502], Loss: 0.0004\n",
            "Epoch [7/25], Batch [2700/4502], Loss: 0.0245\n",
            "Epoch [7/25], Batch [2800/4502], Loss: 0.0008\n",
            "Epoch [7/25], Batch [2900/4502], Loss: 0.0009\n",
            "Epoch [7/25], Batch [3000/4502], Loss: 0.0089\n",
            "Epoch [7/25], Batch [3100/4502], Loss: 0.0007\n",
            "Epoch [7/25], Batch [3200/4502], Loss: 0.0013\n",
            "Epoch [7/25], Batch [3300/4502], Loss: 0.0014\n",
            "Epoch [7/25], Batch [3400/4502], Loss: 0.0081\n",
            "Epoch [7/25], Batch [3500/4502], Loss: 0.0059\n",
            "Epoch [7/25], Batch [3600/4502], Loss: 0.0024\n",
            "Epoch [7/25], Batch [3700/4502], Loss: 0.0062\n",
            "Epoch [7/25], Batch [3800/4502], Loss: 0.0006\n",
            "Epoch [7/25], Batch [3900/4502], Loss: 0.0065\n",
            "Epoch [7/25], Batch [4000/4502], Loss: 0.0097\n",
            "Epoch [7/25], Batch [4100/4502], Loss: 0.0044\n",
            "Epoch [7/25], Batch [4200/4502], Loss: 0.0010\n",
            "Epoch [7/25], Batch [4300/4502], Loss: 0.0017\n",
            "Epoch [7/25], Batch [4400/4502], Loss: 0.0138\n",
            "Epoch [7/25], Batch [4500/4502], Loss: 0.0090\n",
            "Epoch 7/25, Loss: 0.005860661863243836\n",
            "Updated Learning Rate: [3.7152521446170917e-05]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   overdrive       1.00      0.99      0.99      3012\n",
            "  distortion       1.00      1.00      1.00      4518\n",
            "        fuzz       1.00      1.00      1.00      5271\n",
            "     tremolo       1.00      1.00      1.00      5671\n",
            "      phaser       0.99      1.00      1.00      4518\n",
            "     flanger       1.00      0.99      0.99      3012\n",
            "      chorus       1.00      1.00      1.00      5671\n",
            "       delay       0.99      0.96      0.98      7530\n",
            " hall_reverb       0.88      0.99      0.93      4518\n",
            "plate_reverb       0.92      1.00      0.96      3012\n",
            "     octaver       0.99      0.99      0.99      2259\n",
            " auto_filter       1.00      0.99      1.00      3765\n",
            "\n",
            "   micro avg       0.98      0.99      0.99     52757\n",
            "   macro avg       0.98      0.99      0.99     52757\n",
            "weighted avg       0.98      0.99      0.99     52757\n",
            " samples avg       0.96      0.97      0.96     52757\n",
            "\n",
            "\n",
            "Validation Loss: 0.0120, Accuracy: 0.9562, Precision: 0.9808, Recall: 0.9920, F1-score: 0.9860\n",
            "\n",
            "Model saved to /content/drive/MyDrive/Capstone 210/Models/final_multi_effects_alt9.mod\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/25], Batch [100/4502], Loss: 0.0140\n",
            "Epoch [8/25], Batch [200/4502], Loss: 0.0216\n",
            "Epoch [8/25], Batch [300/4502], Loss: 0.0102\n",
            "Epoch [8/25], Batch [400/4502], Loss: 0.0057\n",
            "Epoch [8/25], Batch [500/4502], Loss: 0.0010\n",
            "Epoch [8/25], Batch [600/4502], Loss: 0.0070\n",
            "Epoch [8/25], Batch [700/4502], Loss: 0.0003\n",
            "Epoch [8/25], Batch [800/4502], Loss: 0.0134\n",
            "Epoch [8/25], Batch [900/4502], Loss: 0.0007\n",
            "Epoch [8/25], Batch [1000/4502], Loss: 0.0152\n",
            "Epoch [8/25], Batch [1100/4502], Loss: 0.0033\n",
            "Epoch [8/25], Batch [1200/4502], Loss: 0.0003\n",
            "Epoch [8/25], Batch [1300/4502], Loss: 0.0055\n",
            "Epoch [8/25], Batch [1400/4502], Loss: 0.0021\n",
            "Epoch [8/25], Batch [1500/4502], Loss: 0.0017\n",
            "Epoch [8/25], Batch [1600/4502], Loss: 0.0009\n",
            "Epoch [8/25], Batch [1700/4502], Loss: 0.0048\n",
            "Epoch [8/25], Batch [1800/4502], Loss: 0.0008\n",
            "Epoch [8/25], Batch [1900/4502], Loss: 0.0048\n",
            "Epoch [8/25], Batch [2000/4502], Loss: 0.0013\n",
            "Epoch [8/25], Batch [2100/4502], Loss: 0.0160\n",
            "Epoch [8/25], Batch [2200/4502], Loss: 0.0042\n",
            "Epoch [8/25], Batch [2300/4502], Loss: 0.0018\n",
            "Epoch [8/25], Batch [2400/4502], Loss: 0.0010\n",
            "Epoch [8/25], Batch [2500/4502], Loss: 0.0024\n",
            "Epoch [8/25], Batch [2600/4502], Loss: 0.0028\n",
            "Epoch [8/25], Batch [2700/4502], Loss: 0.0237\n",
            "Epoch [8/25], Batch [2800/4502], Loss: 0.0037\n",
            "Epoch [8/25], Batch [2900/4502], Loss: 0.0004\n",
            "Epoch [8/25], Batch [3000/4502], Loss: 0.0076\n",
            "Epoch [8/25], Batch [3100/4502], Loss: 0.0032\n",
            "Epoch [8/25], Batch [3200/4502], Loss: 0.0012\n",
            "Epoch [8/25], Batch [3300/4502], Loss: 0.0118\n",
            "Epoch [8/25], Batch [3400/4502], Loss: 0.0014\n",
            "Epoch [8/25], Batch [3500/4502], Loss: 0.0017\n",
            "Epoch [8/25], Batch [3600/4502], Loss: 0.0093\n",
            "Epoch [8/25], Batch [3700/4502], Loss: 0.0083\n",
            "Epoch [8/25], Batch [3800/4502], Loss: 0.0004\n",
            "Epoch [8/25], Batch [3900/4502], Loss: 0.0068\n",
            "Epoch [8/25], Batch [4000/4502], Loss: 0.0052\n",
            "Epoch [8/25], Batch [4100/4502], Loss: 0.0078\n",
            "Epoch [8/25], Batch [4200/4502], Loss: 0.0003\n",
            "Epoch [8/25], Batch [4300/4502], Loss: 0.0053\n",
            "Epoch [8/25], Batch [4400/4502], Loss: 0.0028\n",
            "Epoch [8/25], Batch [4500/4502], Loss: 0.0019\n",
            "Epoch 8/25, Loss: 0.00523815613028865\n",
            "Updated Learning Rate: [3.225210386742097e-05]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   overdrive       1.00      1.00      1.00      3012\n",
            "  distortion       1.00      1.00      1.00      4518\n",
            "        fuzz       1.00      1.00      1.00      5271\n",
            "     tremolo       1.00      1.00      1.00      5671\n",
            "      phaser       1.00      1.00      1.00      4518\n",
            "     flanger       0.96      1.00      0.98      3012\n",
            "      chorus       1.00      1.00      1.00      5671\n",
            "       delay       0.98      0.99      0.98      7530\n",
            " hall_reverb       0.96      0.98      0.97      4518\n",
            "plate_reverb       0.99      0.97      0.98      3012\n",
            "     octaver       0.98      1.00      0.99      2259\n",
            " auto_filter       1.00      1.00      1.00      3765\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     52757\n",
            "   macro avg       0.99      0.99      0.99     52757\n",
            "weighted avg       0.99      0.99      0.99     52757\n",
            " samples avg       0.96      0.97      0.96     52757\n",
            "\n",
            "\n",
            "Validation Loss: 0.0073, Accuracy: 0.9737, Precision: 0.9885, Recall: 0.9929, F1-score: 0.9907\n",
            "\n",
            "Model saved to /content/drive/MyDrive/Capstone 210/Models/final_multi_effects_alt9.mod\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/25], Batch [100/4502], Loss: 0.0029\n",
            "Epoch [9/25], Batch [200/4502], Loss: 0.0010\n",
            "Epoch [9/25], Batch [300/4502], Loss: 0.0014\n",
            "Epoch [9/25], Batch [400/4502], Loss: 0.0012\n",
            "Epoch [9/25], Batch [500/4502], Loss: 0.0023\n",
            "Epoch [9/25], Batch [600/4502], Loss: 0.0006\n",
            "Epoch [9/25], Batch [700/4502], Loss: 0.0079\n",
            "Epoch [9/25], Batch [800/4502], Loss: 0.0115\n",
            "Epoch [9/25], Batch [900/4502], Loss: 0.0008\n",
            "Epoch [9/25], Batch [1000/4502], Loss: 0.0106\n",
            "Epoch [9/25], Batch [1100/4502], Loss: 0.0002\n",
            "Epoch [9/25], Batch [1200/4502], Loss: 0.0101\n",
            "Epoch [9/25], Batch [1300/4502], Loss: 0.0003\n",
            "Epoch [9/25], Batch [1400/4502], Loss: 0.0027\n",
            "Epoch [9/25], Batch [1500/4502], Loss: 0.0021\n",
            "Epoch [9/25], Batch [1600/4502], Loss: 0.0002\n",
            "Epoch [9/25], Batch [1700/4502], Loss: 0.0017\n",
            "Epoch [9/25], Batch [1800/4502], Loss: 0.0009\n",
            "Epoch [9/25], Batch [1900/4502], Loss: 0.0060\n",
            "Epoch [9/25], Batch [2000/4502], Loss: 0.0020\n",
            "Epoch [9/25], Batch [2100/4502], Loss: 0.0020\n",
            "Epoch [9/25], Batch [2200/4502], Loss: 0.0011\n",
            "Epoch [9/25], Batch [2300/4502], Loss: 0.0077\n",
            "Epoch [9/25], Batch [2400/4502], Loss: 0.0010\n",
            "Epoch [9/25], Batch [2500/4502], Loss: 0.0003\n",
            "Epoch [9/25], Batch [2600/4502], Loss: 0.0291\n",
            "Epoch [9/25], Batch [2700/4502], Loss: 0.0004\n",
            "Epoch [9/25], Batch [2800/4502], Loss: 0.0103\n",
            "Epoch [9/25], Batch [2900/4502], Loss: 0.0005\n",
            "Epoch [9/25], Batch [3000/4502], Loss: 0.0024\n",
            "Epoch [9/25], Batch [3100/4502], Loss: 0.0043\n",
            "Epoch [9/25], Batch [3200/4502], Loss: 0.0126\n",
            "Epoch [9/25], Batch [3300/4502], Loss: 0.0117\n",
            "Epoch [9/25], Batch [3400/4502], Loss: 0.0016\n",
            "Epoch [9/25], Batch [3500/4502], Loss: 0.0030\n",
            "Epoch [9/25], Batch [3600/4502], Loss: 0.0016\n",
            "Epoch [9/25], Batch [3700/4502], Loss: 0.0027\n",
            "Epoch [9/25], Batch [3800/4502], Loss: 0.0027\n",
            "Epoch [9/25], Batch [3900/4502], Loss: 0.0040\n",
            "Epoch [9/25], Batch [4000/4502], Loss: 0.0010\n",
            "Epoch [9/25], Batch [4100/4502], Loss: 0.0157\n",
            "Epoch [9/25], Batch [4200/4502], Loss: 0.0117\n",
            "Epoch [9/25], Batch [4300/4502], Loss: 0.0011\n",
            "Epoch [9/25], Batch [4400/4502], Loss: 0.0155\n",
            "Epoch [9/25], Batch [4500/4502], Loss: 0.0066\n",
            "Epoch 9/25, Loss: 0.0046274885091943324\n",
            "Updated Learning Rate: [2.7998051367308148e-05]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   overdrive       0.99      1.00      0.99      3012\n",
            "  distortion       1.00      1.00      1.00      4518\n",
            "        fuzz       1.00      1.00      1.00      5271\n",
            "     tremolo       1.00      1.00      1.00      5671\n",
            "      phaser       1.00      1.00      1.00      4518\n",
            "     flanger       0.99      1.00      0.99      3012\n",
            "      chorus       1.00      1.00      1.00      5671\n",
            "       delay       0.98      0.99      0.99      7530\n",
            " hall_reverb       0.98      0.97      0.98      4518\n",
            "plate_reverb       0.99      0.98      0.98      3012\n",
            "     octaver       0.97      1.00      0.98      2259\n",
            " auto_filter       1.00      1.00      1.00      3765\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     52757\n",
            "   macro avg       0.99      0.99      0.99     52757\n",
            "weighted avg       0.99      0.99      0.99     52757\n",
            " samples avg       0.97      0.97      0.97     52757\n",
            "\n",
            "\n",
            "Validation Loss: 0.0061, Accuracy: 0.9778, Precision: 0.9909, Recall: 0.9932, F1-score: 0.9920\n",
            "\n",
            "Model saved to /content/drive/MyDrive/Capstone 210/Models/final_multi_effects_alt9.mod\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/25], Batch [100/4502], Loss: 0.0007\n",
            "Epoch [10/25], Batch [200/4502], Loss: 0.0064\n",
            "Epoch [10/25], Batch [300/4502], Loss: 0.0069\n",
            "Epoch [10/25], Batch [400/4502], Loss: 0.0002\n",
            "Epoch [10/25], Batch [500/4502], Loss: 0.0020\n",
            "Epoch [10/25], Batch [600/4502], Loss: 0.0004\n",
            "Epoch [10/25], Batch [700/4502], Loss: 0.0117\n",
            "Epoch [10/25], Batch [800/4502], Loss: 0.0009\n",
            "Epoch [10/25], Batch [900/4502], Loss: 0.0133\n",
            "Epoch [10/25], Batch [1000/4502], Loss: 0.0034\n",
            "Epoch [10/25], Batch [1100/4502], Loss: 0.0006\n",
            "Epoch [10/25], Batch [1200/4502], Loss: 0.0052\n",
            "Epoch [10/25], Batch [1300/4502], Loss: 0.0009\n",
            "Epoch [10/25], Batch [1400/4502], Loss: 0.0012\n",
            "Epoch [10/25], Batch [1500/4502], Loss: 0.0109\n",
            "Epoch [10/25], Batch [1600/4502], Loss: 0.0002\n",
            "Epoch [10/25], Batch [1700/4502], Loss: 0.0006\n",
            "Epoch [10/25], Batch [1800/4502], Loss: 0.0041\n",
            "Epoch [10/25], Batch [1900/4502], Loss: 0.0151\n",
            "Epoch [10/25], Batch [2000/4502], Loss: 0.0058\n",
            "Epoch [10/25], Batch [2100/4502], Loss: 0.0016\n",
            "Epoch [10/25], Batch [2200/4502], Loss: 0.0029\n",
            "Epoch [10/25], Batch [2300/4502], Loss: 0.0059\n",
            "Epoch [10/25], Batch [2400/4502], Loss: 0.0131\n",
            "Epoch [10/25], Batch [2500/4502], Loss: 0.0007\n",
            "Epoch [10/25], Batch [2600/4502], Loss: 0.0037\n",
            "Epoch [10/25], Batch [2700/4502], Loss: 0.0005\n",
            "Epoch [10/25], Batch [2800/4502], Loss: 0.0150\n",
            "Epoch [10/25], Batch [2900/4502], Loss: 0.0004\n",
            "Epoch [10/25], Batch [3000/4502], Loss: 0.0005\n",
            "Epoch [10/25], Batch [3100/4502], Loss: 0.0008\n",
            "Epoch [10/25], Batch [3200/4502], Loss: 0.0006\n",
            "Epoch [10/25], Batch [3300/4502], Loss: 0.0003\n",
            "Epoch [10/25], Batch [3400/4502], Loss: 0.0002\n",
            "Epoch [10/25], Batch [3500/4502], Loss: 0.0061\n",
            "Epoch [10/25], Batch [3600/4502], Loss: 0.0027\n",
            "Epoch [10/25], Batch [3700/4502], Loss: 0.0043\n",
            "Epoch [10/25], Batch [3800/4502], Loss: 0.0019\n",
            "Epoch [10/25], Batch [3900/4502], Loss: 0.0015\n",
            "Epoch [10/25], Batch [4000/4502], Loss: 0.0016\n",
            "Epoch [10/25], Batch [4100/4502], Loss: 0.0004\n",
            "Epoch [10/25], Batch [4200/4502], Loss: 0.0006\n",
            "Epoch [10/25], Batch [4300/4502], Loss: 0.0091\n",
            "Epoch [10/25], Batch [4400/4502], Loss: 0.0009\n",
            "Epoch [10/25], Batch [4500/4502], Loss: 0.0002\n",
            "Epoch 10/25, Loss: 0.004256802137643826\n",
            "Updated Learning Rate: [2.4305108391960204e-05]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   overdrive       1.00      0.99      1.00      3012\n",
            "  distortion       1.00      1.00      1.00      4518\n",
            "        fuzz       1.00      1.00      1.00      5271\n",
            "     tremolo       1.00      1.00      1.00      5671\n",
            "      phaser       1.00      1.00      1.00      4518\n",
            "     flanger       1.00      0.99      0.99      3012\n",
            "      chorus       1.00      1.00      1.00      5671\n",
            "       delay       0.99      0.98      0.98      7530\n",
            " hall_reverb       0.96      0.99      0.97      4518\n",
            "plate_reverb       1.00      0.97      0.98      3012\n",
            "     octaver       0.98      1.00      0.99      2259\n",
            " auto_filter       1.00      1.00      1.00      3765\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     52757\n",
            "   macro avg       0.99      0.99      0.99     52757\n",
            "weighted avg       0.99      0.99      0.99     52757\n",
            " samples avg       0.97      0.97      0.97     52757\n",
            "\n",
            "\n",
            "Validation Loss: 0.0062, Accuracy: 0.9780, Precision: 0.9928, Recall: 0.9922, F1-score: 0.9924\n",
            "\n",
            "Model saved to /content/drive/MyDrive/Capstone 210/Models/final_multi_effects_alt9.mod\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/25], Batch [100/4502], Loss: 0.0080\n",
            "Epoch [11/25], Batch [200/4502], Loss: 0.0169\n",
            "Epoch [11/25], Batch [300/4502], Loss: 0.0003\n",
            "Epoch [11/25], Batch [400/4502], Loss: 0.0196\n",
            "Epoch [11/25], Batch [500/4502], Loss: 0.0008\n",
            "Epoch [11/25], Batch [600/4502], Loss: 0.0018\n",
            "Epoch [11/25], Batch [700/4502], Loss: 0.0003\n",
            "Epoch [11/25], Batch [800/4502], Loss: 0.0014\n",
            "Epoch [11/25], Batch [900/4502], Loss: 0.0076\n",
            "Epoch [11/25], Batch [1000/4502], Loss: 0.0130\n",
            "Epoch [11/25], Batch [1100/4502], Loss: 0.0005\n",
            "Epoch [11/25], Batch [1200/4502], Loss: 0.0012\n",
            "Epoch [11/25], Batch [1300/4502], Loss: 0.0028\n",
            "Epoch [11/25], Batch [1400/4502], Loss: 0.0003\n",
            "Epoch [11/25], Batch [1500/4502], Loss: 0.0004\n",
            "Epoch [11/25], Batch [1600/4502], Loss: 0.0025\n",
            "Epoch [11/25], Batch [1700/4502], Loss: 0.0006\n",
            "Epoch [11/25], Batch [1800/4502], Loss: 0.0019\n",
            "Epoch [11/25], Batch [1900/4502], Loss: 0.0002\n",
            "Epoch [11/25], Batch [2000/4502], Loss: 0.0010\n",
            "Epoch [11/25], Batch [2100/4502], Loss: 0.0046\n",
            "Epoch [11/25], Batch [2200/4502], Loss: 0.0112\n",
            "Epoch [11/25], Batch [2300/4502], Loss: 0.0027\n",
            "Epoch [11/25], Batch [2400/4502], Loss: 0.0011\n",
            "Epoch [11/25], Batch [2500/4502], Loss: 0.0028\n",
            "Epoch [11/25], Batch [2600/4502], Loss: 0.0011\n",
            "Epoch [11/25], Batch [2700/4502], Loss: 0.0003\n",
            "Epoch [11/25], Batch [2800/4502], Loss: 0.0106\n",
            "Epoch [11/25], Batch [2900/4502], Loss: 0.0014\n",
            "Epoch [11/25], Batch [3000/4502], Loss: 0.0003\n",
            "Epoch [11/25], Batch [3100/4502], Loss: 0.0007\n",
            "Epoch [11/25], Batch [3200/4502], Loss: 0.0014\n",
            "Epoch [11/25], Batch [3300/4502], Loss: 0.0008\n",
            "Epoch [11/25], Batch [3400/4502], Loss: 0.0016\n",
            "Epoch [11/25], Batch [3500/4502], Loss: 0.0031\n",
            "Epoch [11/25], Batch [3600/4502], Loss: 0.0158\n",
            "Epoch [11/25], Batch [3700/4502], Loss: 0.0023\n",
            "Epoch [11/25], Batch [3800/4502], Loss: 0.0002\n",
            "Epoch [11/25], Batch [3900/4502], Loss: 0.0017\n",
            "Epoch [11/25], Batch [4000/4502], Loss: 0.0000\n",
            "Epoch [11/25], Batch [4100/4502], Loss: 0.0016\n",
            "Epoch [11/25], Batch [4200/4502], Loss: 0.0062\n",
            "Epoch [11/25], Batch [4300/4502], Loss: 0.0003\n",
            "Epoch [11/25], Batch [4400/4502], Loss: 0.0043\n",
            "Epoch [11/25], Batch [4500/4502], Loss: 0.0020\n",
            "Epoch 11/25, Loss: 0.0036899146592560797\n",
            "Updated Learning Rate: [2.1099264595060654e-05]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   overdrive       1.00      1.00      1.00      3012\n",
            "  distortion       1.00      1.00      1.00      4518\n",
            "        fuzz       1.00      1.00      1.00      5271\n",
            "     tremolo       1.00      1.00      1.00      5671\n",
            "      phaser       1.00      1.00      1.00      4518\n",
            "     flanger       1.00      1.00      1.00      3012\n",
            "      chorus       1.00      1.00      1.00      5671\n",
            "       delay       0.99      0.98      0.98      7530\n",
            " hall_reverb       0.96      0.98      0.97      4518\n",
            "plate_reverb       0.98      0.99      0.98      3012\n",
            "     octaver       0.99      1.00      0.99      2259\n",
            " auto_filter       1.00      1.00      1.00      3765\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     52757\n",
            "   macro avg       0.99      0.99      0.99     52757\n",
            "weighted avg       0.99      0.99      0.99     52757\n",
            " samples avg       0.97      0.97      0.97     52757\n",
            "\n",
            "\n",
            "Validation Loss: 0.0061, Accuracy: 0.9788, Precision: 0.9925, Recall: 0.9939, F1-score: 0.9932\n",
            "\n",
            "Model saved to /content/drive/MyDrive/Capstone 210/Models/final_multi_effects_alt9.mod\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/25], Batch [100/4502], Loss: 0.0026\n",
            "Epoch [12/25], Batch [200/4502], Loss: 0.0025\n",
            "Epoch [12/25], Batch [300/4502], Loss: 0.0007\n",
            "Epoch [12/25], Batch [400/4502], Loss: 0.0017\n",
            "Epoch [12/25], Batch [500/4502], Loss: 0.0009\n",
            "Epoch [12/25], Batch [600/4502], Loss: 0.0007\n",
            "Epoch [12/25], Batch [700/4502], Loss: 0.0090\n",
            "Epoch [12/25], Batch [800/4502], Loss: 0.0037\n",
            "Epoch [12/25], Batch [900/4502], Loss: 0.0002\n",
            "Epoch [12/25], Batch [1000/4502], Loss: 0.0002\n",
            "Epoch [12/25], Batch [1100/4502], Loss: 0.0004\n",
            "Epoch [12/25], Batch [1200/4502], Loss: 0.0111\n",
            "Epoch [12/25], Batch [1300/4502], Loss: 0.0005\n",
            "Epoch [12/25], Batch [1400/4502], Loss: 0.0011\n",
            "Epoch [12/25], Batch [1500/4502], Loss: 0.0001\n",
            "Epoch [12/25], Batch [1600/4502], Loss: 0.0014\n",
            "Epoch [12/25], Batch [1700/4502], Loss: 0.0021\n",
            "Epoch [12/25], Batch [1800/4502], Loss: 0.0011\n",
            "Epoch [12/25], Batch [1900/4502], Loss: 0.0049\n",
            "Epoch [12/25], Batch [2000/4502], Loss: 0.0039\n",
            "Epoch [12/25], Batch [2100/4502], Loss: 0.0008\n",
            "Epoch [12/25], Batch [2200/4502], Loss: 0.0153\n",
            "Epoch [12/25], Batch [2300/4502], Loss: 0.0077\n",
            "Epoch [12/25], Batch [2400/4502], Loss: 0.0096\n",
            "Epoch [12/25], Batch [2500/4502], Loss: 0.0091\n",
            "Epoch [12/25], Batch [2600/4502], Loss: 0.0018\n",
            "Epoch [12/25], Batch [2700/4502], Loss: 0.0128\n",
            "Epoch [12/25], Batch [2800/4502], Loss: 0.0008\n",
            "Epoch [12/25], Batch [2900/4502], Loss: 0.0015\n",
            "Epoch [12/25], Batch [3000/4502], Loss: 0.0002\n",
            "Epoch [12/25], Batch [3100/4502], Loss: 0.0006\n",
            "Epoch [12/25], Batch [3200/4502], Loss: 0.0052\n",
            "Epoch [12/25], Batch [3300/4502], Loss: 0.0010\n",
            "Epoch [12/25], Batch [3400/4502], Loss: 0.0004\n",
            "Epoch [12/25], Batch [3500/4502], Loss: 0.0097\n",
            "Epoch [12/25], Batch [3600/4502], Loss: 0.0018\n",
            "Epoch [12/25], Batch [3700/4502], Loss: 0.0006\n",
            "Epoch [12/25], Batch [3800/4502], Loss: 0.0051\n",
            "Epoch [12/25], Batch [3900/4502], Loss: 0.0006\n",
            "Epoch [12/25], Batch [4000/4502], Loss: 0.0059\n",
            "Epoch [12/25], Batch [4100/4502], Loss: 0.0011\n",
            "Epoch [12/25], Batch [4200/4502], Loss: 0.0001\n",
            "Epoch [12/25], Batch [4300/4502], Loss: 0.0032\n",
            "Epoch [12/25], Batch [4400/4502], Loss: 0.0002\n",
            "Epoch [12/25], Batch [4500/4502], Loss: 0.0016\n",
            "Epoch 12/25, Loss: 0.00383065089906895\n",
            "Updated Learning Rate: [1.8316271594972154e-05]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   overdrive       1.00      1.00      1.00      3012\n",
            "  distortion       1.00      1.00      1.00      4518\n",
            "        fuzz       1.00      1.00      1.00      5271\n",
            "     tremolo       1.00      1.00      1.00      5671\n",
            "      phaser       1.00      1.00      1.00      4518\n",
            "     flanger       1.00      1.00      1.00      3012\n",
            "      chorus       1.00      1.00      1.00      5671\n",
            "       delay       0.99      0.98      0.99      7530\n",
            " hall_reverb       0.98      0.98      0.98      4518\n",
            "plate_reverb       0.97      1.00      0.98      3012\n",
            "     octaver       0.99      1.00      0.99      2259\n",
            " auto_filter       1.00      1.00      1.00      3765\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     52757\n",
            "   macro avg       0.99      0.99      0.99     52757\n",
            "weighted avg       0.99      0.99      0.99     52757\n",
            " samples avg       0.97      0.97      0.97     52757\n",
            "\n",
            "\n",
            "Validation Loss: 0.0055, Accuracy: 0.9817, Precision: 0.9933, Recall: 0.9940, F1-score: 0.9936\n",
            "\n",
            "Model saved to /content/drive/MyDrive/Capstone 210/Models/final_multi_effects_alt9.mod\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/25], Batch [100/4502], Loss: 0.0006\n",
            "Epoch [13/25], Batch [200/4502], Loss: 0.0004\n",
            "Epoch [13/25], Batch [300/4502], Loss: 0.0028\n",
            "Epoch [13/25], Batch [400/4502], Loss: 0.0150\n",
            "Epoch [13/25], Batch [500/4502], Loss: 0.0002\n",
            "Epoch [13/25], Batch [600/4502], Loss: 0.0010\n",
            "Epoch [13/25], Batch [700/4502], Loss: 0.0006\n",
            "Epoch [13/25], Batch [800/4502], Loss: 0.0007\n",
            "Epoch [13/25], Batch [900/4502], Loss: 0.0005\n",
            "Epoch [13/25], Batch [1000/4502], Loss: 0.0021\n",
            "Epoch [13/25], Batch [1100/4502], Loss: 0.0123\n",
            "Epoch [13/25], Batch [1200/4502], Loss: 0.0049\n",
            "Epoch [13/25], Batch [1300/4502], Loss: 0.0027\n",
            "Epoch [13/25], Batch [1400/4502], Loss: 0.0049\n",
            "Epoch [13/25], Batch [1500/4502], Loss: 0.0003\n",
            "Epoch [13/25], Batch [1600/4502], Loss: 0.0017\n",
            "Epoch [13/25], Batch [1700/4502], Loss: 0.0012\n",
            "Epoch [13/25], Batch [1800/4502], Loss: 0.0004\n",
            "Epoch [13/25], Batch [1900/4502], Loss: 0.0002\n",
            "Epoch [13/25], Batch [2000/4502], Loss: 0.0090\n",
            "Epoch [13/25], Batch [2100/4502], Loss: 0.0009\n",
            "Epoch [13/25], Batch [2200/4502], Loss: 0.0006\n",
            "Epoch [13/25], Batch [2300/4502], Loss: 0.0064\n",
            "Epoch [13/25], Batch [2400/4502], Loss: 0.0017\n",
            "Epoch [13/25], Batch [2500/4502], Loss: 0.0011\n",
            "Epoch [13/25], Batch [2600/4502], Loss: 0.0011\n",
            "Epoch [13/25], Batch [2700/4502], Loss: 0.0013\n",
            "Epoch [13/25], Batch [2800/4502], Loss: 0.0030\n",
            "Epoch [13/25], Batch [2900/4502], Loss: 0.0068\n",
            "Epoch [13/25], Batch [3000/4502], Loss: 0.0017\n",
            "Epoch [13/25], Batch [3100/4502], Loss: 0.0007\n",
            "Epoch [13/25], Batch [3200/4502], Loss: 0.0001\n",
            "Epoch [13/25], Batch [3300/4502], Loss: 0.0005\n",
            "Epoch [13/25], Batch [3400/4502], Loss: 0.0010\n",
            "Epoch [13/25], Batch [3500/4502], Loss: 0.0017\n",
            "Epoch [13/25], Batch [3600/4502], Loss: 0.0018\n",
            "Epoch [13/25], Batch [3700/4502], Loss: 0.0005\n",
            "Epoch [13/25], Batch [3800/4502], Loss: 0.0022\n",
            "Epoch [13/25], Batch [3900/4502], Loss: 0.0006\n",
            "Epoch [13/25], Batch [4000/4502], Loss: 0.0052\n",
            "Epoch [13/25], Batch [4100/4502], Loss: 0.0050\n",
            "Epoch [13/25], Batch [4200/4502], Loss: 0.0047\n",
            "Epoch [13/25], Batch [4300/4502], Loss: 0.0003\n",
            "Epoch [13/25], Batch [4400/4502], Loss: 0.0010\n",
            "Epoch [13/25], Batch [4500/4502], Loss: 0.0010\n",
            "Epoch 13/25, Loss: 0.003486128211912156\n",
            "Updated Learning Rate: [1.5900355371595327e-05]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   overdrive       1.00      1.00      1.00      3012\n",
            "  distortion       1.00      1.00      1.00      4518\n",
            "        fuzz       1.00      1.00      1.00      5271\n",
            "     tremolo       1.00      1.00      1.00      5671\n",
            "      phaser       1.00      1.00      1.00      4518\n",
            "     flanger       1.00      0.99      1.00      3012\n",
            "      chorus       1.00      1.00      1.00      5671\n",
            "       delay       0.99      0.98      0.99      7530\n",
            " hall_reverb       0.99      0.96      0.97      4518\n",
            "plate_reverb       0.96      1.00      0.98      3012\n",
            "     octaver       0.99      1.00      0.99      2259\n",
            " auto_filter       1.00      1.00      1.00      3765\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     52757\n",
            "   macro avg       0.99      0.99      0.99     52757\n",
            "weighted avg       0.99      0.99      0.99     52757\n",
            " samples avg       0.97      0.97      0.97     52757\n",
            "\n",
            "\n",
            "Validation Loss: 0.0065, Accuracy: 0.9812, Precision: 0.9937, Recall: 0.9925, F1-score: 0.9930\n",
            "\n",
            "Model saved to /content/drive/MyDrive/Capstone 210/Models/final_multi_effects_alt9.mod\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/25], Batch [100/4502], Loss: 0.0006\n",
            "Epoch [14/25], Batch [200/4502], Loss: 0.0028\n",
            "Epoch [14/25], Batch [300/4502], Loss: 0.0218\n",
            "Epoch [14/25], Batch [400/4502], Loss: 0.0019\n",
            "Epoch [14/25], Batch [500/4502], Loss: 0.0059\n",
            "Epoch [14/25], Batch [600/4502], Loss: 0.0035\n",
            "Epoch [14/25], Batch [700/4502], Loss: 0.0022\n",
            "Epoch [14/25], Batch [800/4502], Loss: 0.0015\n",
            "Epoch [14/25], Batch [900/4502], Loss: 0.0003\n",
            "Epoch [14/25], Batch [1000/4502], Loss: 0.0006\n",
            "Epoch [14/25], Batch [1100/4502], Loss: 0.0130\n",
            "Epoch [14/25], Batch [1200/4502], Loss: 0.0017\n",
            "Epoch [14/25], Batch [1300/4502], Loss: 0.0154\n",
            "Epoch [14/25], Batch [1400/4502], Loss: 0.0003\n",
            "Epoch [14/25], Batch [1500/4502], Loss: 0.0003\n",
            "Epoch [14/25], Batch [1600/4502], Loss: 0.0004\n",
            "Epoch [14/25], Batch [1700/4502], Loss: 0.0005\n",
            "Epoch [14/25], Batch [1800/4502], Loss: 0.0018\n",
            "Epoch [14/25], Batch [1900/4502], Loss: 0.0022\n",
            "Epoch [14/25], Batch [2000/4502], Loss: 0.0048\n",
            "Epoch [14/25], Batch [2100/4502], Loss: 0.0027\n",
            "Epoch [14/25], Batch [2200/4502], Loss: 0.0063\n",
            "Epoch [14/25], Batch [2300/4502], Loss: 0.0001\n",
            "Epoch [14/25], Batch [2400/4502], Loss: 0.0017\n",
            "Epoch [14/25], Batch [2500/4502], Loss: 0.0032\n",
            "Epoch [14/25], Batch [2600/4502], Loss: 0.0074\n",
            "Epoch [14/25], Batch [2700/4502], Loss: 0.0003\n",
            "Epoch [14/25], Batch [2800/4502], Loss: 0.0000\n",
            "Epoch [14/25], Batch [2900/4502], Loss: 0.0002\n",
            "Epoch [14/25], Batch [3000/4502], Loss: 0.0001\n",
            "Epoch [14/25], Batch [3100/4502], Loss: 0.0033\n",
            "Epoch [14/25], Batch [3200/4502], Loss: 0.0018\n",
            "Epoch [14/25], Batch [3300/4502], Loss: 0.0001\n",
            "Epoch [14/25], Batch [3400/4502], Loss: 0.0003\n",
            "Epoch [14/25], Batch [3500/4502], Loss: 0.0002\n",
            "Epoch [14/25], Batch [3600/4502], Loss: 0.0003\n",
            "Epoch [14/25], Batch [3700/4502], Loss: 0.0015\n",
            "Epoch [14/25], Batch [3800/4502], Loss: 0.0006\n",
            "Epoch [14/25], Batch [3900/4502], Loss: 0.0001\n",
            "Epoch [14/25], Batch [4000/4502], Loss: 0.0001\n",
            "Epoch [14/25], Batch [4100/4502], Loss: 0.0013\n",
            "Epoch [14/25], Batch [4200/4502], Loss: 0.0003\n",
            "Epoch [14/25], Batch [4300/4502], Loss: 0.0004\n",
            "Epoch [14/25], Batch [4400/4502], Loss: 0.0040\n",
            "Epoch [14/25], Batch [4500/4502], Loss: 0.0045\n",
            "Epoch 14/25, Loss: 0.0030144523243569765\n",
            "Updated Learning Rate: [1.3803098498081903e-05]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   overdrive       1.00      1.00      1.00      3012\n",
            "  distortion       1.00      1.00      1.00      4518\n",
            "        fuzz       1.00      1.00      1.00      5271\n",
            "     tremolo       1.00      1.00      1.00      5671\n",
            "      phaser       1.00      1.00      1.00      4518\n",
            "     flanger       0.98      1.00      0.99      3012\n",
            "      chorus       1.00      1.00      1.00      5671\n",
            "       delay       0.98      0.99      0.99      7530\n",
            " hall_reverb       0.98      0.97      0.98      4518\n",
            "plate_reverb       0.97      0.99      0.98      3012\n",
            "     octaver       0.99      1.00      0.99      2259\n",
            " auto_filter       1.00      1.00      1.00      3765\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     52757\n",
            "   macro avg       0.99      0.99      0.99     52757\n",
            "weighted avg       0.99      0.99      0.99     52757\n",
            " samples avg       0.97      0.97      0.97     52757\n",
            "\n",
            "\n",
            "Validation Loss: 0.0061, Accuracy: 0.9794, Precision: 0.9917, Recall: 0.9942, F1-score: 0.9929\n",
            "\n",
            "Model saved to /content/drive/MyDrive/Capstone 210/Models/final_multi_effects_alt9.mod\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/25], Batch [100/4502], Loss: 0.0001\n",
            "Epoch [15/25], Batch [200/4502], Loss: 0.0005\n",
            "Epoch [15/25], Batch [300/4502], Loss: 0.0001\n",
            "Epoch [15/25], Batch [400/4502], Loss: 0.0062\n",
            "Epoch [15/25], Batch [500/4502], Loss: 0.0009\n",
            "Epoch [15/25], Batch [600/4502], Loss: 0.0011\n",
            "Epoch [15/25], Batch [700/4502], Loss: 0.0010\n",
            "Epoch [15/25], Batch [800/4502], Loss: 0.0001\n",
            "Epoch [15/25], Batch [900/4502], Loss: 0.0002\n",
            "Epoch [15/25], Batch [1000/4502], Loss: 0.0013\n",
            "Epoch [15/25], Batch [1100/4502], Loss: 0.0088\n",
            "Epoch [15/25], Batch [1200/4502], Loss: 0.0103\n",
            "Epoch [15/25], Batch [1300/4502], Loss: 0.0002\n",
            "Epoch [15/25], Batch [1400/4502], Loss: 0.0004\n",
            "Epoch [15/25], Batch [1500/4502], Loss: 0.0001\n",
            "Epoch [15/25], Batch [1600/4502], Loss: 0.0002\n",
            "Epoch [15/25], Batch [1700/4502], Loss: 0.0007\n",
            "Epoch [15/25], Batch [1800/4502], Loss: 0.0005\n",
            "Epoch [15/25], Batch [1900/4502], Loss: 0.0002\n",
            "Epoch [15/25], Batch [2000/4502], Loss: 0.0011\n",
            "Epoch [15/25], Batch [2100/4502], Loss: 0.0001\n",
            "Epoch [15/25], Batch [2200/4502], Loss: 0.0008\n",
            "Epoch [15/25], Batch [2300/4502], Loss: 0.0138\n",
            "Epoch [15/25], Batch [2400/4502], Loss: 0.0002\n",
            "Epoch [15/25], Batch [2500/4502], Loss: 0.0011\n",
            "Epoch [15/25], Batch [2600/4502], Loss: 0.0145\n",
            "Epoch [15/25], Batch [2700/4502], Loss: 0.0002\n",
            "Epoch [15/25], Batch [2800/4502], Loss: 0.0022\n",
            "Epoch [15/25], Batch [2900/4502], Loss: 0.0023\n",
            "Epoch [15/25], Batch [3000/4502], Loss: 0.0003\n",
            "Epoch [15/25], Batch [3100/4502], Loss: 0.0050\n",
            "Epoch [15/25], Batch [3200/4502], Loss: 0.0071\n",
            "Epoch [15/25], Batch [3300/4502], Loss: 0.0002\n",
            "Epoch [15/25], Batch [3400/4502], Loss: 0.0112\n",
            "Epoch [15/25], Batch [3500/4502], Loss: 0.0002\n",
            "Epoch [15/25], Batch [3600/4502], Loss: 0.0005\n",
            "Epoch [15/25], Batch [3700/4502], Loss: 0.0056\n",
            "Epoch [15/25], Batch [3800/4502], Loss: 0.0079\n",
            "Epoch [15/25], Batch [3900/4502], Loss: 0.0017\n",
            "Epoch [15/25], Batch [4000/4502], Loss: 0.0057\n",
            "Epoch [15/25], Batch [4100/4502], Loss: 0.0042\n",
            "Epoch [15/25], Batch [4200/4502], Loss: 0.0001\n",
            "Epoch [15/25], Batch [4300/4502], Loss: 0.0007\n",
            "Epoch [15/25], Batch [4400/4502], Loss: 0.0146\n",
            "Epoch [15/25], Batch [4500/4502], Loss: 0.0003\n",
            "Epoch 15/25, Loss: 0.003030951430898819\n",
            "Updated Learning Rate: [1.19824698061849e-05]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   overdrive       1.00      1.00      1.00      3012\n",
            "  distortion       1.00      1.00      1.00      4518\n",
            "        fuzz       1.00      1.00      1.00      5271\n",
            "     tremolo       1.00      1.00      1.00      5671\n",
            "      phaser       1.00      1.00      1.00      4518\n",
            "     flanger       0.98      1.00      0.99      3012\n",
            "      chorus       1.00      1.00      1.00      5671\n",
            "       delay       0.98      0.98      0.98      7530\n",
            " hall_reverb       0.97      0.98      0.97      4518\n",
            "plate_reverb       0.94      1.00      0.97      3012\n",
            "     octaver       1.00      1.00      1.00      2259\n",
            " auto_filter       1.00      1.00      1.00      3765\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     52757\n",
            "   macro avg       0.99      0.99      0.99     52757\n",
            "weighted avg       0.99      0.99      0.99     52757\n",
            " samples avg       0.97      0.97      0.97     52757\n",
            "\n",
            "\n",
            "Validation Loss: 0.0069, Accuracy: 0.9770, Precision: 0.9886, Recall: 0.9947, F1-score: 0.9916\n",
            "\n",
            "Model saved to /content/drive/MyDrive/Capstone 210/Models/final_multi_effects_alt9.mod\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/25], Batch [100/4502], Loss: 0.0020\n",
            "Epoch [16/25], Batch [200/4502], Loss: 0.0014\n",
            "Epoch [16/25], Batch [300/4502], Loss: 0.0002\n",
            "Epoch [16/25], Batch [400/4502], Loss: 0.0002\n",
            "Epoch [16/25], Batch [500/4502], Loss: 0.0002\n",
            "Epoch [16/25], Batch [600/4502], Loss: 0.0011\n",
            "Epoch [16/25], Batch [700/4502], Loss: 0.0009\n",
            "Epoch [16/25], Batch [800/4502], Loss: 0.0000\n",
            "Epoch [16/25], Batch [900/4502], Loss: 0.0001\n",
            "Epoch [16/25], Batch [1000/4502], Loss: 0.0003\n",
            "Epoch [16/25], Batch [1100/4502], Loss: 0.0003\n",
            "Epoch [16/25], Batch [1200/4502], Loss: 0.0012\n",
            "Epoch [16/25], Batch [1300/4502], Loss: 0.0005\n",
            "Epoch [16/25], Batch [1400/4502], Loss: 0.0035\n",
            "Epoch [16/25], Batch [1500/4502], Loss: 0.0008\n",
            "Epoch [16/25], Batch [1600/4502], Loss: 0.0002\n",
            "Epoch [16/25], Batch [1700/4502], Loss: 0.0006\n",
            "Epoch [16/25], Batch [1800/4502], Loss: 0.0011\n",
            "Epoch [16/25], Batch [1900/4502], Loss: 0.0003\n",
            "Epoch [16/25], Batch [2000/4502], Loss: 0.0003\n",
            "Epoch [16/25], Batch [2100/4502], Loss: 0.0013\n",
            "Epoch [16/25], Batch [2200/4502], Loss: 0.0005\n",
            "Epoch [16/25], Batch [2300/4502], Loss: 0.0007\n",
            "Epoch [16/25], Batch [2400/4502], Loss: 0.0005\n",
            "Epoch [16/25], Batch [2500/4502], Loss: 0.0005\n",
            "Epoch [16/25], Batch [2600/4502], Loss: 0.0029\n",
            "Epoch [16/25], Batch [2700/4502], Loss: 0.0001\n",
            "Epoch [16/25], Batch [2800/4502], Loss: 0.0001\n",
            "Epoch [16/25], Batch [2900/4502], Loss: 0.0031\n",
            "Epoch [16/25], Batch [3000/4502], Loss: 0.0007\n",
            "Epoch [16/25], Batch [3100/4502], Loss: 0.0036\n",
            "Epoch [16/25], Batch [3200/4502], Loss: 0.0098\n",
            "Epoch [16/25], Batch [3300/4502], Loss: 0.0006\n",
            "Epoch [16/25], Batch [3400/4502], Loss: 0.0002\n",
            "Epoch [16/25], Batch [3500/4502], Loss: 0.0126\n",
            "Epoch [16/25], Batch [3600/4502], Loss: 0.0088\n",
            "Epoch [16/25], Batch [3700/4502], Loss: 0.0001\n",
            "Epoch [16/25], Batch [3800/4502], Loss: 0.0002\n",
            "Epoch [16/25], Batch [3900/4502], Loss: 0.0003\n",
            "Epoch [16/25], Batch [4000/4502], Loss: 0.0001\n",
            "Epoch [16/25], Batch [4100/4502], Loss: 0.0001\n",
            "Epoch [16/25], Batch [4200/4502], Loss: 0.0017\n",
            "Epoch [16/25], Batch [4300/4502], Loss: 0.0003\n",
            "Epoch [16/25], Batch [4400/4502], Loss: 0.0002\n",
            "Epoch [16/25], Batch [4500/4502], Loss: 0.0010\n",
            "Epoch 16/25, Loss: 0.002896628066432283\n",
            "Updated Learning Rate: [1.0401982038749112e-05]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   overdrive       1.00      1.00      1.00      3012\n",
            "  distortion       1.00      1.00      1.00      4518\n",
            "        fuzz       1.00      1.00      1.00      5271\n",
            "     tremolo       1.00      1.00      1.00      5671\n",
            "      phaser       1.00      1.00      1.00      4518\n",
            "     flanger       0.99      1.00      0.99      3012\n",
            "      chorus       1.00      1.00      1.00      5671\n",
            "       delay       0.98      0.99      0.99      7530\n",
            " hall_reverb       0.96      0.99      0.97      4518\n",
            "plate_reverb       0.97      1.00      0.98      3012\n",
            "     octaver       0.99      1.00      0.99      2259\n",
            " auto_filter       1.00      1.00      1.00      3765\n",
            "\n",
            "   micro avg       0.99      1.00      0.99     52757\n",
            "   macro avg       0.99      1.00      0.99     52757\n",
            "weighted avg       0.99      1.00      0.99     52757\n",
            " samples avg       0.97      0.97      0.97     52757\n",
            "\n",
            "\n",
            "Validation Loss: 0.0057, Accuracy: 0.9798, Precision: 0.9908, Recall: 0.9961, F1-score: 0.9934\n",
            "\n",
            "Model saved to /content/drive/MyDrive/Capstone 210/Models/final_multi_effects_alt9.mod\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/25], Batch [100/4502], Loss: 0.0001\n",
            "Epoch [17/25], Batch [200/4502], Loss: 0.0005\n",
            "Epoch [17/25], Batch [300/4502], Loss: 0.0010\n",
            "Epoch [17/25], Batch [400/4502], Loss: 0.0007\n",
            "Epoch [17/25], Batch [500/4502], Loss: 0.0000\n",
            "Epoch [17/25], Batch [600/4502], Loss: 0.0002\n",
            "Epoch [17/25], Batch [700/4502], Loss: 0.0023\n",
            "Epoch [17/25], Batch [800/4502], Loss: 0.0003\n",
            "Epoch [17/25], Batch [900/4502], Loss: 0.0001\n",
            "Epoch [17/25], Batch [1000/4502], Loss: 0.0003\n",
            "Epoch [17/25], Batch [1100/4502], Loss: 0.0001\n",
            "Epoch [17/25], Batch [1200/4502], Loss: 0.0007\n",
            "Epoch [17/25], Batch [1300/4502], Loss: 0.0011\n",
            "Epoch [17/25], Batch [1400/4502], Loss: 0.0000\n",
            "Epoch [17/25], Batch [1500/4502], Loss: 0.0085\n",
            "Epoch [17/25], Batch [1600/4502], Loss: 0.0039\n",
            "Epoch [17/25], Batch [1700/4502], Loss: 0.0000\n",
            "Epoch [17/25], Batch [1800/4502], Loss: 0.0105\n",
            "Epoch [17/25], Batch [1900/4502], Loss: 0.0057\n",
            "Epoch [17/25], Batch [2000/4502], Loss: 0.0082\n",
            "Epoch [17/25], Batch [2100/4502], Loss: 0.0002\n",
            "Epoch [17/25], Batch [2200/4502], Loss: 0.0003\n",
            "Epoch [17/25], Batch [2300/4502], Loss: 0.0129\n",
            "Epoch [17/25], Batch [2400/4502], Loss: 0.0105\n",
            "Epoch [17/25], Batch [2500/4502], Loss: 0.0001\n",
            "Epoch [17/25], Batch [2600/4502], Loss: 0.0013\n",
            "Epoch [17/25], Batch [2700/4502], Loss: 0.0056\n",
            "Epoch [17/25], Batch [2800/4502], Loss: 0.0012\n",
            "Epoch [17/25], Batch [2900/4502], Loss: 0.0004\n",
            "Epoch [17/25], Batch [3000/4502], Loss: 0.0042\n",
            "Epoch [17/25], Batch [3100/4502], Loss: 0.0003\n",
            "Epoch [17/25], Batch [3200/4502], Loss: 0.0006\n",
            "Epoch [17/25], Batch [3300/4502], Loss: 0.0104\n",
            "Epoch [17/25], Batch [3400/4502], Loss: 0.0014\n",
            "Epoch [17/25], Batch [3500/4502], Loss: 0.0095\n",
            "Epoch [17/25], Batch [3600/4502], Loss: 0.0066\n",
            "Epoch [17/25], Batch [3700/4502], Loss: 0.0047\n",
            "Epoch [17/25], Batch [3800/4502], Loss: 0.0014\n",
            "Epoch [17/25], Batch [3900/4502], Loss: 0.0037\n",
            "Epoch [17/25], Batch [4000/4502], Loss: 0.0114\n",
            "Epoch [17/25], Batch [4100/4502], Loss: 0.0000\n",
            "Epoch [17/25], Batch [4200/4502], Loss: 0.0018\n",
            "Epoch [17/25], Batch [4300/4502], Loss: 0.0019\n",
            "Epoch [17/25], Batch [4400/4502], Loss: 0.0009\n",
            "Epoch [17/25], Batch [4500/4502], Loss: 0.0132\n",
            "Epoch 17/25, Loss: 0.002674632989970933\n",
            "Updated Learning Rate: [9.029960607838104e-06]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   overdrive       1.00      1.00      1.00      3012\n",
            "  distortion       1.00      1.00      1.00      4518\n",
            "        fuzz       1.00      1.00      1.00      5271\n",
            "     tremolo       1.00      1.00      1.00      5671\n",
            "      phaser       1.00      1.00      1.00      4518\n",
            "     flanger       1.00      1.00      1.00      3012\n",
            "      chorus       1.00      1.00      1.00      5671\n",
            "       delay       0.98      0.99      0.99      7530\n",
            " hall_reverb       0.98      0.98      0.98      4518\n",
            "plate_reverb       0.99      0.99      0.99      3012\n",
            "     octaver       0.98      1.00      0.99      2259\n",
            " auto_filter       1.00      1.00      1.00      3765\n",
            "\n",
            "   micro avg       0.99      1.00      0.99     52757\n",
            "   macro avg       0.99      1.00      0.99     52757\n",
            "weighted avg       0.99      1.00      0.99     52757\n",
            " samples avg       0.97      0.97      0.97     52757\n",
            "\n",
            "\n",
            "Validation Loss: 0.0044, Accuracy: 0.9832, Precision: 0.9941, Recall: 0.9955, F1-score: 0.9948\n",
            "\n",
            "Model saved to /content/drive/MyDrive/Capstone 210/Models/final_multi_effects_alt9.mod\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/25], Batch [100/4502], Loss: 0.0016\n",
            "Epoch [18/25], Batch [200/4502], Loss: 0.0003\n",
            "Epoch [18/25], Batch [300/4502], Loss: 0.0047\n",
            "Epoch [18/25], Batch [400/4502], Loss: 0.0009\n",
            "Epoch [18/25], Batch [500/4502], Loss: 0.0034\n",
            "Epoch [18/25], Batch [600/4502], Loss: 0.0001\n",
            "Epoch [18/25], Batch [700/4502], Loss: 0.0098\n",
            "Epoch [18/25], Batch [800/4502], Loss: 0.0001\n",
            "Epoch [18/25], Batch [900/4502], Loss: 0.0009\n",
            "Epoch [18/25], Batch [1000/4502], Loss: 0.0010\n",
            "Epoch [18/25], Batch [1100/4502], Loss: 0.0001\n",
            "Epoch [18/25], Batch [1200/4502], Loss: 0.0032\n",
            "Epoch [18/25], Batch [1300/4502], Loss: 0.0010\n",
            "Epoch [18/25], Batch [1400/4502], Loss: 0.0002\n",
            "Epoch [18/25], Batch [1500/4502], Loss: 0.0035\n",
            "Epoch [18/25], Batch [1600/4502], Loss: 0.0013\n",
            "Epoch [18/25], Batch [1700/4502], Loss: 0.0049\n",
            "Epoch [18/25], Batch [1800/4502], Loss: 0.0048\n",
            "Epoch [18/25], Batch [1900/4502], Loss: 0.0000\n",
            "Epoch [18/25], Batch [2000/4502], Loss: 0.0020\n",
            "Epoch [18/25], Batch [2100/4502], Loss: 0.0031\n",
            "Epoch [18/25], Batch [2200/4502], Loss: 0.0045\n",
            "Epoch [18/25], Batch [2300/4502], Loss: 0.0002\n",
            "Epoch [18/25], Batch [2400/4502], Loss: 0.0016\n",
            "Epoch [18/25], Batch [2500/4502], Loss: 0.0007\n",
            "Epoch [18/25], Batch [2600/4502], Loss: 0.0001\n",
            "Epoch [18/25], Batch [2700/4502], Loss: 0.0017\n",
            "Epoch [18/25], Batch [2800/4502], Loss: 0.0002\n",
            "Epoch [18/25], Batch [2900/4502], Loss: 0.0006\n",
            "Epoch [18/25], Batch [3000/4502], Loss: 0.0038\n",
            "Epoch [18/25], Batch [3100/4502], Loss: 0.0009\n",
            "Epoch [18/25], Batch [3200/4502], Loss: 0.0000\n",
            "Epoch [18/25], Batch [3300/4502], Loss: 0.0106\n",
            "Epoch [18/25], Batch [3400/4502], Loss: 0.0032\n",
            "Epoch [18/25], Batch [3500/4502], Loss: 0.0002\n",
            "Epoch [18/25], Batch [3600/4502], Loss: 0.0019\n",
            "Epoch [18/25], Batch [3700/4502], Loss: 0.0020\n",
            "Epoch [18/25], Batch [3800/4502], Loss: 0.0095\n",
            "Epoch [18/25], Batch [3900/4502], Loss: 0.0005\n",
            "Epoch [18/25], Batch [4000/4502], Loss: 0.0007\n",
            "Epoch [18/25], Batch [4100/4502], Loss: 0.0009\n",
            "Epoch [18/25], Batch [4200/4502], Loss: 0.0007\n",
            "Epoch [18/25], Batch [4300/4502], Loss: 0.0002\n",
            "Epoch [18/25], Batch [4400/4502], Loss: 0.0000\n",
            "Epoch [18/25], Batch [4500/4502], Loss: 0.0003\n",
            "Epoch 18/25, Loss: 0.002439041686706468\n",
            "Updated Learning Rate: [7.838908803664258e-06]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   overdrive       1.00      1.00      1.00      3012\n",
            "  distortion       1.00      1.00      1.00      4518\n",
            "        fuzz       1.00      1.00      1.00      5271\n",
            "     tremolo       1.00      1.00      1.00      5671\n",
            "      phaser       1.00      1.00      1.00      4518\n",
            "     flanger       0.99      1.00      1.00      3012\n",
            "      chorus       1.00      1.00      1.00      5671\n",
            "       delay       1.00      0.97      0.98      7530\n",
            " hall_reverb       0.96      0.99      0.98      4518\n",
            "plate_reverb       0.98      1.00      0.99      3012\n",
            "     octaver       0.99      1.00      0.99      2259\n",
            " auto_filter       1.00      1.00      1.00      3765\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     52757\n",
            "   macro avg       0.99      0.99      0.99     52757\n",
            "weighted avg       0.99      0.99      0.99     52757\n",
            " samples avg       0.97      0.97      0.97     52757\n",
            "\n",
            "\n",
            "Validation Loss: 0.0054, Accuracy: 0.9814, Precision: 0.9933, Recall: 0.9948, F1-score: 0.9941\n",
            "\n",
            "Model saved to /content/drive/MyDrive/Capstone 210/Models/final_multi_effects_alt9.mod\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/25], Batch [100/4502], Loss: 0.0017\n",
            "Epoch [19/25], Batch [200/4502], Loss: 0.0002\n",
            "Epoch [19/25], Batch [300/4502], Loss: 0.0044\n",
            "Epoch [19/25], Batch [400/4502], Loss: 0.0001\n",
            "Epoch [19/25], Batch [500/4502], Loss: 0.0005\n",
            "Epoch [19/25], Batch [600/4502], Loss: 0.0010\n",
            "Epoch [19/25], Batch [700/4502], Loss: 0.0002\n",
            "Epoch [19/25], Batch [800/4502], Loss: 0.0006\n",
            "Epoch [19/25], Batch [900/4502], Loss: 0.0002\n",
            "Epoch [19/25], Batch [1000/4502], Loss: 0.0002\n",
            "Epoch [19/25], Batch [1100/4502], Loss: 0.0058\n",
            "Epoch [19/25], Batch [1200/4502], Loss: 0.0010\n",
            "Epoch [19/25], Batch [1300/4502], Loss: 0.0020\n",
            "Epoch [19/25], Batch [1400/4502], Loss: 0.0001\n",
            "Epoch [19/25], Batch [1500/4502], Loss: 0.0022\n",
            "Epoch [19/25], Batch [1600/4502], Loss: 0.0012\n",
            "Epoch [19/25], Batch [1700/4502], Loss: 0.0004\n",
            "Epoch [19/25], Batch [1800/4502], Loss: 0.0040\n",
            "Epoch [19/25], Batch [1900/4502], Loss: 0.0110\n",
            "Epoch [19/25], Batch [2000/4502], Loss: 0.0007\n",
            "Epoch [19/25], Batch [2100/4502], Loss: 0.0002\n",
            "Epoch [19/25], Batch [2200/4502], Loss: 0.0005\n",
            "Epoch [19/25], Batch [2300/4502], Loss: 0.0002\n",
            "Epoch [19/25], Batch [2400/4502], Loss: 0.0117\n",
            "Epoch [19/25], Batch [2500/4502], Loss: 0.0001\n",
            "Epoch [19/25], Batch [2600/4502], Loss: 0.0003\n",
            "Epoch [19/25], Batch [2700/4502], Loss: 0.0005\n",
            "Epoch [19/25], Batch [2800/4502], Loss: 0.0003\n",
            "Epoch [19/25], Batch [2900/4502], Loss: 0.0001\n",
            "Epoch [19/25], Batch [3000/4502], Loss: 0.0007\n",
            "Epoch [19/25], Batch [3100/4502], Loss: 0.0155\n",
            "Epoch [19/25], Batch [3200/4502], Loss: 0.0016\n",
            "Epoch [19/25], Batch [3300/4502], Loss: 0.0001\n",
            "Epoch [19/25], Batch [3400/4502], Loss: 0.0008\n",
            "Epoch [19/25], Batch [3500/4502], Loss: 0.0007\n",
            "Epoch [19/25], Batch [3600/4502], Loss: 0.0178\n",
            "Epoch [19/25], Batch [3700/4502], Loss: 0.0002\n",
            "Epoch [19/25], Batch [3800/4502], Loss: 0.0001\n",
            "Epoch [19/25], Batch [3900/4502], Loss: 0.0012\n",
            "Epoch [19/25], Batch [4000/4502], Loss: 0.0005\n",
            "Epoch [19/25], Batch [4100/4502], Loss: 0.0008\n",
            "Epoch [19/25], Batch [4200/4502], Loss: 0.0001\n",
            "Epoch [19/25], Batch [4300/4502], Loss: 0.0048\n",
            "Epoch [19/25], Batch [4400/4502], Loss: 0.0003\n",
            "Epoch [19/25], Batch [4500/4502], Loss: 0.0012\n",
            "Epoch 19/25, Loss: 0.002523580948229629\n",
            "Updated Learning Rate: [6.804956732460942e-06]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   overdrive       1.00      1.00      1.00      3012\n",
            "  distortion       1.00      1.00      1.00      4518\n",
            "        fuzz       1.00      1.00      1.00      5271\n",
            "     tremolo       1.00      1.00      1.00      5671\n",
            "      phaser       1.00      1.00      1.00      4518\n",
            "     flanger       1.00      1.00      1.00      3012\n",
            "      chorus       1.00      1.00      1.00      5671\n",
            "       delay       0.98      0.99      0.99      7530\n",
            " hall_reverb       0.97      0.99      0.98      4518\n",
            "plate_reverb       0.97      0.99      0.98      3012\n",
            "     octaver       0.99      1.00      0.99      2259\n",
            " auto_filter       1.00      1.00      1.00      3765\n",
            "\n",
            "   micro avg       0.99      1.00      0.99     52757\n",
            "   macro avg       0.99      1.00      0.99     52757\n",
            "weighted avg       0.99      1.00      0.99     52757\n",
            " samples avg       0.97      0.97      0.97     52757\n",
            "\n",
            "\n",
            "Validation Loss: 0.0047, Accuracy: 0.9824, Precision: 0.9925, Recall: 0.9963, F1-score: 0.9943\n",
            "\n",
            "Model saved to /content/drive/MyDrive/Capstone 210/Models/final_multi_effects_alt9.mod\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/25], Batch [100/4502], Loss: 0.0003\n",
            "Epoch [20/25], Batch [200/4502], Loss: 0.0001\n",
            "Epoch [20/25], Batch [300/4502], Loss: 0.0003\n",
            "Epoch [20/25], Batch [400/4502], Loss: 0.0003\n",
            "Epoch [20/25], Batch [500/4502], Loss: 0.0016\n",
            "Epoch [20/25], Batch [600/4502], Loss: 0.0002\n",
            "Epoch [20/25], Batch [700/4502], Loss: 0.0078\n",
            "Epoch [20/25], Batch [800/4502], Loss: 0.0000\n",
            "Epoch [20/25], Batch [900/4502], Loss: 0.0001\n",
            "Epoch [20/25], Batch [1000/4502], Loss: 0.0001\n",
            "Epoch [20/25], Batch [1100/4502], Loss: 0.0006\n",
            "Epoch [20/25], Batch [1200/4502], Loss: 0.0002\n",
            "Epoch [20/25], Batch [1300/4502], Loss: 0.0264\n",
            "Epoch [20/25], Batch [1400/4502], Loss: 0.0000\n",
            "Epoch [20/25], Batch [1500/4502], Loss: 0.0002\n",
            "Epoch [20/25], Batch [1600/4502], Loss: 0.0012\n",
            "Epoch [20/25], Batch [1700/4502], Loss: 0.0002\n",
            "Epoch [20/25], Batch [1800/4502], Loss: 0.0036\n",
            "Epoch [20/25], Batch [1900/4502], Loss: 0.0022\n",
            "Epoch [20/25], Batch [2000/4502], Loss: 0.0012\n",
            "Epoch [20/25], Batch [2100/4502], Loss: 0.0149\n",
            "Epoch [20/25], Batch [2200/4502], Loss: 0.0002\n",
            "Epoch [20/25], Batch [2300/4502], Loss: 0.0002\n",
            "Epoch [20/25], Batch [2400/4502], Loss: 0.0000\n",
            "Epoch [20/25], Batch [2500/4502], Loss: 0.0050\n",
            "Epoch [20/25], Batch [2600/4502], Loss: 0.0003\n",
            "Epoch [20/25], Batch [2700/4502], Loss: 0.0001\n",
            "Epoch [20/25], Batch [2800/4502], Loss: 0.0002\n",
            "Epoch [20/25], Batch [2900/4502], Loss: 0.0009\n",
            "Epoch [20/25], Batch [3000/4502], Loss: 0.0015\n",
            "Epoch [20/25], Batch [3100/4502], Loss: 0.0007\n",
            "Epoch [20/25], Batch [3200/4502], Loss: 0.0008\n",
            "Epoch [20/25], Batch [3300/4502], Loss: 0.0014\n",
            "Epoch [20/25], Batch [3400/4502], Loss: 0.0003\n",
            "Epoch [20/25], Batch [3500/4502], Loss: 0.0001\n",
            "Epoch [20/25], Batch [3600/4502], Loss: 0.0004\n",
            "Epoch [20/25], Batch [3700/4502], Loss: 0.0015\n",
            "Epoch [20/25], Batch [3800/4502], Loss: 0.0008\n",
            "Epoch [20/25], Batch [3900/4502], Loss: 0.0007\n",
            "Epoch [20/25], Batch [4000/4502], Loss: 0.0016\n",
            "Epoch [20/25], Batch [4100/4502], Loss: 0.0016\n",
            "Epoch [20/25], Batch [4200/4502], Loss: 0.0017\n",
            "Epoch [20/25], Batch [4300/4502], Loss: 0.0001\n",
            "Epoch [20/25], Batch [4400/4502], Loss: 0.0012\n",
            "Epoch [20/25], Batch [4500/4502], Loss: 0.0001\n",
            "Epoch 20/25, Loss: 0.0023198903391775817\n",
            "Updated Learning Rate: [5.907382939449344e-06]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   overdrive       1.00      1.00      1.00      3012\n",
            "  distortion       1.00      1.00      1.00      4518\n",
            "        fuzz       1.00      1.00      1.00      5271\n",
            "     tremolo       1.00      1.00      1.00      5671\n",
            "      phaser       1.00      1.00      1.00      4518\n",
            "     flanger       1.00      1.00      1.00      3012\n",
            "      chorus       1.00      1.00      1.00      5671\n",
            "       delay       0.99      0.98      0.99      7530\n",
            " hall_reverb       0.99      0.97      0.98      4518\n",
            "plate_reverb       0.98      0.99      0.99      3012\n",
            "     octaver       0.99      1.00      0.99      2259\n",
            " auto_filter       1.00      1.00      1.00      3765\n",
            "\n",
            "   micro avg       1.00      0.99      0.99     52757\n",
            "   macro avg       1.00      0.99      0.99     52757\n",
            "weighted avg       1.00      0.99      0.99     52757\n",
            " samples avg       0.97      0.97      0.97     52757\n",
            "\n",
            "\n",
            "Validation Loss: 0.0049, Accuracy: 0.9831, Precision: 0.9955, Recall: 0.9938, F1-score: 0.9946\n",
            "\n",
            "Model saved to /content/drive/MyDrive/Capstone 210/Models/final_multi_effects_alt9.mod\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21/25], Batch [100/4502], Loss: 0.0165\n",
            "Epoch [21/25], Batch [200/4502], Loss: 0.0002\n",
            "Epoch [21/25], Batch [300/4502], Loss: 0.0001\n",
            "Epoch [21/25], Batch [400/4502], Loss: 0.0011\n",
            "Epoch [21/25], Batch [500/4502], Loss: 0.0000\n",
            "Epoch [21/25], Batch [600/4502], Loss: 0.0023\n",
            "Epoch [21/25], Batch [700/4502], Loss: 0.0036\n",
            "Epoch [21/25], Batch [800/4502], Loss: 0.0001\n",
            "Epoch [21/25], Batch [900/4502], Loss: 0.0000\n",
            "Epoch [21/25], Batch [1000/4502], Loss: 0.0004\n",
            "Epoch [21/25], Batch [1100/4502], Loss: 0.0024\n",
            "Epoch [21/25], Batch [1200/4502], Loss: 0.0016\n",
            "Epoch [21/25], Batch [1300/4502], Loss: 0.0001\n",
            "Epoch [21/25], Batch [1400/4502], Loss: 0.0047\n",
            "Epoch [21/25], Batch [1500/4502], Loss: 0.0000\n",
            "Epoch [21/25], Batch [1600/4502], Loss: 0.0000\n",
            "Epoch [21/25], Batch [1700/4502], Loss: 0.0057\n",
            "Epoch [21/25], Batch [1800/4502], Loss: 0.0011\n",
            "Epoch [21/25], Batch [1900/4502], Loss: 0.0086\n",
            "Epoch [21/25], Batch [2000/4502], Loss: 0.0041\n",
            "Epoch [21/25], Batch [2100/4502], Loss: 0.0050\n",
            "Epoch [21/25], Batch [2200/4502], Loss: 0.0030\n",
            "Epoch [21/25], Batch [2300/4502], Loss: 0.0191\n",
            "Epoch [21/25], Batch [2400/4502], Loss: 0.0024\n",
            "Epoch [21/25], Batch [2500/4502], Loss: 0.0009\n",
            "Epoch [21/25], Batch [2600/4502], Loss: 0.0005\n",
            "Epoch [21/25], Batch [2700/4502], Loss: 0.0006\n",
            "Epoch [21/25], Batch [2800/4502], Loss: 0.0157\n",
            "Epoch [21/25], Batch [2900/4502], Loss: 0.0098\n",
            "Epoch [21/25], Batch [3000/4502], Loss: 0.0002\n",
            "Epoch [21/25], Batch [3100/4502], Loss: 0.0002\n",
            "Epoch [21/25], Batch [3200/4502], Loss: 0.0012\n",
            "Epoch [21/25], Batch [3300/4502], Loss: 0.0010\n",
            "Epoch [21/25], Batch [3400/4502], Loss: 0.0001\n",
            "Epoch [21/25], Batch [3500/4502], Loss: 0.0009\n",
            "Epoch [21/25], Batch [3600/4502], Loss: 0.0001\n",
            "Epoch [21/25], Batch [3700/4502], Loss: 0.0105\n",
            "Epoch [21/25], Batch [3800/4502], Loss: 0.0005\n",
            "Epoch [21/25], Batch [3900/4502], Loss: 0.0028\n",
            "Epoch [21/25], Batch [4000/4502], Loss: 0.0004\n",
            "Epoch [21/25], Batch [4100/4502], Loss: 0.0002\n",
            "Epoch [21/25], Batch [4200/4502], Loss: 0.0032\n",
            "Epoch [21/25], Batch [4300/4502], Loss: 0.0005\n",
            "Epoch [21/25], Batch [4400/4502], Loss: 0.0001\n",
            "Epoch [21/25], Batch [4500/4502], Loss: 0.0078\n",
            "Epoch 21/25, Loss: 0.0023068817802958156\n",
            "Updated Learning Rate: [5.128199129735975e-06]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   overdrive       1.00      1.00      1.00      3012\n",
            "  distortion       1.00      1.00      1.00      4518\n",
            "        fuzz       1.00      1.00      1.00      5271\n",
            "     tremolo       1.00      1.00      1.00      5671\n",
            "      phaser       1.00      1.00      1.00      4518\n",
            "     flanger       0.99      1.00      1.00      3012\n",
            "      chorus       1.00      1.00      1.00      5671\n",
            "       delay       0.99      0.99      0.99      7530\n",
            " hall_reverb       0.99      0.97      0.98      4518\n",
            "plate_reverb       0.98      0.99      0.98      3012\n",
            "     octaver       0.99      1.00      1.00      2259\n",
            " auto_filter       1.00      1.00      1.00      3765\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     52757\n",
            "   macro avg       0.99      0.99      0.99     52757\n",
            "weighted avg       0.99      0.99      0.99     52757\n",
            " samples avg       0.97      0.97      0.97     52757\n",
            "\n",
            "\n",
            "Validation Loss: 0.0047, Accuracy: 0.9838, Precision: 0.9949, Recall: 0.9947, F1-score: 0.9948\n",
            "\n",
            "Model saved to /content/drive/MyDrive/Capstone 210/Models/final_multi_effects_alt9.mod\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22/25], Batch [100/4502], Loss: 0.0005\n",
            "Epoch [22/25], Batch [200/4502], Loss: 0.0011\n",
            "Epoch [22/25], Batch [300/4502], Loss: 0.0002\n",
            "Epoch [22/25], Batch [400/4502], Loss: 0.0028\n",
            "Epoch [22/25], Batch [500/4502], Loss: 0.0004\n",
            "Epoch [22/25], Batch [600/4502], Loss: 0.0007\n",
            "Epoch [22/25], Batch [700/4502], Loss: 0.0077\n",
            "Epoch [22/25], Batch [800/4502], Loss: 0.0002\n",
            "Epoch [22/25], Batch [900/4502], Loss: 0.0001\n",
            "Epoch [22/25], Batch [1000/4502], Loss: 0.0090\n",
            "Epoch [22/25], Batch [1100/4502], Loss: 0.0045\n",
            "Epoch [22/25], Batch [1200/4502], Loss: 0.0003\n",
            "Epoch [22/25], Batch [1300/4502], Loss: 0.0007\n",
            "Epoch [22/25], Batch [1400/4502], Loss: 0.0002\n",
            "Epoch [22/25], Batch [1500/4502], Loss: 0.0000\n",
            "Epoch [22/25], Batch [1600/4502], Loss: 0.0173\n",
            "Epoch [22/25], Batch [1700/4502], Loss: 0.0067\n",
            "Epoch [22/25], Batch [1800/4502], Loss: 0.0002\n",
            "Epoch [22/25], Batch [1900/4502], Loss: 0.0001\n",
            "Epoch [22/25], Batch [2000/4502], Loss: 0.0002\n",
            "Epoch [22/25], Batch [2100/4502], Loss: 0.0000\n",
            "Epoch [22/25], Batch [2200/4502], Loss: 0.0024\n",
            "Epoch [22/25], Batch [2300/4502], Loss: 0.0002\n",
            "Epoch [22/25], Batch [2400/4502], Loss: 0.0002\n",
            "Epoch [22/25], Batch [2500/4502], Loss: 0.0007\n",
            "Epoch [22/25], Batch [2600/4502], Loss: 0.0017\n",
            "Epoch [22/25], Batch [2700/4502], Loss: 0.0009\n",
            "Epoch [22/25], Batch [2800/4502], Loss: 0.0004\n",
            "Epoch [22/25], Batch [2900/4502], Loss: 0.0000\n",
            "Epoch [22/25], Batch [3000/4502], Loss: 0.0002\n",
            "Epoch [22/25], Batch [3100/4502], Loss: 0.0001\n",
            "Epoch [22/25], Batch [3200/4502], Loss: 0.0016\n",
            "Epoch [22/25], Batch [3300/4502], Loss: 0.0083\n",
            "Epoch [22/25], Batch [3400/4502], Loss: 0.0002\n",
            "Epoch [22/25], Batch [3500/4502], Loss: 0.0002\n",
            "Epoch [22/25], Batch [3600/4502], Loss: 0.0036\n",
            "Epoch [22/25], Batch [3700/4502], Loss: 0.0022\n",
            "Epoch [22/25], Batch [3800/4502], Loss: 0.0004\n",
            "Epoch [22/25], Batch [3900/4502], Loss: 0.0001\n",
            "Epoch [22/25], Batch [4000/4502], Loss: 0.0000\n",
            "Epoch [22/25], Batch [4100/4502], Loss: 0.0084\n",
            "Epoch [22/25], Batch [4200/4502], Loss: 0.0010\n",
            "Epoch [22/25], Batch [4300/4502], Loss: 0.0043\n",
            "Epoch [22/25], Batch [4400/4502], Loss: 0.0001\n",
            "Epoch [22/25], Batch [4500/4502], Loss: 0.0002\n",
            "Epoch 22/25, Loss: 0.002170325545445383\n",
            "Updated Learning Rate: [4.4517896645238e-06]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   overdrive       1.00      1.00      1.00      3012\n",
            "  distortion       1.00      1.00      1.00      4518\n",
            "        fuzz       1.00      1.00      1.00      5271\n",
            "     tremolo       1.00      1.00      1.00      5671\n",
            "      phaser       1.00      1.00      1.00      4518\n",
            "     flanger       0.99      1.00      1.00      3012\n",
            "      chorus       1.00      1.00      1.00      5671\n",
            "       delay       0.99      0.98      0.99      7530\n",
            " hall_reverb       0.97      0.98      0.98      4518\n",
            "plate_reverb       0.97      1.00      0.98      3012\n",
            "     octaver       0.99      1.00      0.99      2259\n",
            " auto_filter       1.00      1.00      1.00      3765\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     52757\n",
            "   macro avg       0.99      1.00      0.99     52757\n",
            "weighted avg       0.99      0.99      0.99     52757\n",
            " samples avg       0.97      0.97      0.97     52757\n",
            "\n",
            "\n",
            "Validation Loss: 0.0055, Accuracy: 0.9815, Precision: 0.9927, Recall: 0.9951, F1-score: 0.9939\n",
            "\n",
            "Model saved to /content/drive/MyDrive/Capstone 210/Models/final_multi_effects_alt9.mod\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [23/25], Batch [100/4502], Loss: 0.0008\n",
            "Epoch [23/25], Batch [200/4502], Loss: 0.0004\n",
            "Epoch [23/25], Batch [300/4502], Loss: 0.0010\n",
            "Epoch [23/25], Batch [400/4502], Loss: 0.0001\n",
            "Epoch [23/25], Batch [500/4502], Loss: 0.0003\n",
            "Epoch [23/25], Batch [600/4502], Loss: 0.0007\n",
            "Epoch [23/25], Batch [700/4502], Loss: 0.0010\n",
            "Epoch [23/25], Batch [800/4502], Loss: 0.0001\n",
            "Epoch [23/25], Batch [900/4502], Loss: 0.0027\n",
            "Epoch [23/25], Batch [1000/4502], Loss: 0.0009\n",
            "Epoch [23/25], Batch [1100/4502], Loss: 0.0012\n",
            "Epoch [23/25], Batch [1200/4502], Loss: 0.0090\n",
            "Epoch [23/25], Batch [1300/4502], Loss: 0.0017\n",
            "Epoch [23/25], Batch [1400/4502], Loss: 0.0033\n",
            "Epoch [23/25], Batch [1500/4502], Loss: 0.0002\n",
            "Epoch [23/25], Batch [1600/4502], Loss: 0.0025\n",
            "Epoch [23/25], Batch [1700/4502], Loss: 0.0002\n",
            "Epoch [23/25], Batch [1800/4502], Loss: 0.0000\n",
            "Epoch [23/25], Batch [1900/4502], Loss: 0.0013\n",
            "Epoch [23/25], Batch [2000/4502], Loss: 0.0002\n",
            "Epoch [23/25], Batch [2100/4502], Loss: 0.0029\n",
            "Epoch [23/25], Batch [2200/4502], Loss: 0.0001\n",
            "Epoch [23/25], Batch [2300/4502], Loss: 0.0085\n",
            "Epoch [23/25], Batch [2400/4502], Loss: 0.0021\n",
            "Epoch [23/25], Batch [2500/4502], Loss: 0.0001\n",
            "Epoch [23/25], Batch [2600/4502], Loss: 0.0082\n",
            "Epoch [23/25], Batch [2700/4502], Loss: 0.0007\n",
            "Epoch [23/25], Batch [2800/4502], Loss: 0.0013\n",
            "Epoch [23/25], Batch [2900/4502], Loss: 0.0095\n",
            "Epoch [23/25], Batch [3000/4502], Loss: 0.0022\n",
            "Epoch [23/25], Batch [3100/4502], Loss: 0.0009\n",
            "Epoch [23/25], Batch [3200/4502], Loss: 0.0001\n",
            "Epoch [23/25], Batch [3300/4502], Loss: 0.0004\n",
            "Epoch [23/25], Batch [3400/4502], Loss: 0.0012\n",
            "Epoch [23/25], Batch [3500/4502], Loss: 0.0002\n",
            "Epoch [23/25], Batch [3600/4502], Loss: 0.0064\n",
            "Epoch [23/25], Batch [3700/4502], Loss: 0.0148\n",
            "Epoch [23/25], Batch [3800/4502], Loss: 0.0019\n",
            "Epoch [23/25], Batch [3900/4502], Loss: 0.0000\n",
            "Epoch [23/25], Batch [4000/4502], Loss: 0.0003\n",
            "Epoch [23/25], Batch [4100/4502], Loss: 0.0079\n",
            "Epoch [23/25], Batch [4200/4502], Loss: 0.0008\n",
            "Epoch [23/25], Batch [4300/4502], Loss: 0.0003\n",
            "Epoch [23/25], Batch [4400/4502], Loss: 0.0010\n",
            "Epoch [23/25], Batch [4500/4502], Loss: 0.0076\n",
            "Epoch 23/25, Loss: 0.0026558262460602052\n",
            "Updated Learning Rate: [3.864598607773111e-06]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   overdrive       1.00      1.00      1.00      3012\n",
            "  distortion       1.00      1.00      1.00      4518\n",
            "        fuzz       1.00      1.00      1.00      5271\n",
            "     tremolo       1.00      1.00      1.00      5671\n",
            "      phaser       1.00      1.00      1.00      4518\n",
            "     flanger       0.99      1.00      1.00      3012\n",
            "      chorus       1.00      1.00      1.00      5671\n",
            "       delay       0.98      0.99      0.99      7530\n",
            " hall_reverb       0.99      0.98      0.98      4518\n",
            "plate_reverb       0.98      0.99      0.99      3012\n",
            "     octaver       0.99      1.00      0.99      2259\n",
            " auto_filter       1.00      1.00      1.00      3765\n",
            "\n",
            "   micro avg       0.99      1.00      0.99     52757\n",
            "   macro avg       0.99      1.00      0.99     52757\n",
            "weighted avg       0.99      1.00      0.99     52757\n",
            " samples avg       0.97      0.97      0.97     52757\n",
            "\n",
            "\n",
            "Validation Loss: 0.0046, Accuracy: 0.9842, Precision: 0.9944, Recall: 0.9953, F1-score: 0.9948\n",
            "\n",
            "Model saved to /content/drive/MyDrive/Capstone 210/Models/final_multi_effects_alt9.mod\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24/25], Batch [100/4502], Loss: 0.0164\n",
            "Epoch [24/25], Batch [200/4502], Loss: 0.0004\n",
            "Epoch [24/25], Batch [300/4502], Loss: 0.0007\n",
            "Epoch [24/25], Batch [400/4502], Loss: 0.0001\n",
            "Epoch [24/25], Batch [500/4502], Loss: 0.0001\n",
            "Epoch [24/25], Batch [600/4502], Loss: 0.0005\n",
            "Epoch [24/25], Batch [700/4502], Loss: 0.0014\n",
            "Epoch [24/25], Batch [800/4502], Loss: 0.0128\n",
            "Epoch [24/25], Batch [900/4502], Loss: 0.0010\n",
            "Epoch [24/25], Batch [1000/4502], Loss: 0.0007\n",
            "Epoch [24/25], Batch [1100/4502], Loss: 0.0032\n",
            "Epoch [24/25], Batch [1200/4502], Loss: 0.0000\n",
            "Epoch [24/25], Batch [1300/4502], Loss: 0.0023\n",
            "Epoch [24/25], Batch [1400/4502], Loss: 0.0003\n",
            "Epoch [24/25], Batch [1500/4502], Loss: 0.0001\n",
            "Epoch [24/25], Batch [1600/4502], Loss: 0.0001\n",
            "Epoch [24/25], Batch [1700/4502], Loss: 0.0006\n",
            "Epoch [24/25], Batch [1800/4502], Loss: 0.0001\n",
            "Epoch [24/25], Batch [1900/4502], Loss: 0.0038\n",
            "Epoch [24/25], Batch [2000/4502], Loss: 0.0046\n",
            "Epoch [24/25], Batch [2100/4502], Loss: 0.0024\n",
            "Epoch [24/25], Batch [2200/4502], Loss: 0.0003\n",
            "Epoch [24/25], Batch [2300/4502], Loss: 0.0028\n",
            "Epoch [24/25], Batch [2400/4502], Loss: 0.0015\n",
            "Epoch [24/25], Batch [2500/4502], Loss: 0.0001\n",
            "Epoch [24/25], Batch [2600/4502], Loss: 0.0001\n",
            "Epoch [24/25], Batch [2700/4502], Loss: 0.0005\n",
            "Epoch [24/25], Batch [2800/4502], Loss: 0.0000\n",
            "Epoch [24/25], Batch [2900/4502], Loss: 0.0001\n",
            "Epoch [24/25], Batch [3000/4502], Loss: 0.0008\n",
            "Epoch [24/25], Batch [3100/4502], Loss: 0.0015\n",
            "Epoch [24/25], Batch [3200/4502], Loss: 0.0003\n",
            "Epoch [24/25], Batch [3300/4502], Loss: 0.0048\n",
            "Epoch [24/25], Batch [3400/4502], Loss: 0.0001\n",
            "Epoch [24/25], Batch [3500/4502], Loss: 0.0022\n",
            "Epoch [24/25], Batch [3600/4502], Loss: 0.0003\n",
            "Epoch [24/25], Batch [3700/4502], Loss: 0.0011\n",
            "Epoch [24/25], Batch [3800/4502], Loss: 0.0080\n",
            "Epoch [24/25], Batch [3900/4502], Loss: 0.0002\n",
            "Epoch [24/25], Batch [4000/4502], Loss: 0.0049\n",
            "Epoch [24/25], Batch [4100/4502], Loss: 0.0017\n",
            "Epoch [24/25], Batch [4200/4502], Loss: 0.0012\n",
            "Epoch [24/25], Batch [4300/4502], Loss: 0.0003\n",
            "Epoch [24/25], Batch [4400/4502], Loss: 0.0002\n",
            "Epoch [24/25], Batch [4500/4502], Loss: 0.0003\n",
            "Epoch 24/25, Loss: 0.0022979232033978115\n",
            "Updated Learning Rate: [3.3548580514078373e-06]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   overdrive       1.00      1.00      1.00      3012\n",
            "  distortion       1.00      1.00      1.00      4518\n",
            "        fuzz       1.00      1.00      1.00      5271\n",
            "     tremolo       1.00      1.00      1.00      5671\n",
            "      phaser       1.00      1.00      1.00      4518\n",
            "     flanger       0.99      1.00      1.00      3012\n",
            "      chorus       1.00      1.00      1.00      5671\n",
            "       delay       0.99      0.99      0.99      7530\n",
            " hall_reverb       0.99      0.97      0.98      4518\n",
            "plate_reverb       0.97      1.00      0.98      3012\n",
            "     octaver       1.00      1.00      1.00      2259\n",
            " auto_filter       1.00      1.00      1.00      3765\n",
            "\n",
            "   micro avg       1.00      0.99      0.99     52757\n",
            "   macro avg       0.99      0.99      0.99     52757\n",
            "weighted avg       1.00      0.99      0.99     52757\n",
            " samples avg       0.97      0.97      0.97     52757\n",
            "\n",
            "\n",
            "Validation Loss: 0.0047, Accuracy: 0.9847, Precision: 0.9947, Recall: 0.9949, F1-score: 0.9948\n",
            "\n",
            "Model saved to /content/drive/MyDrive/Capstone 210/Models/final_multi_effects_alt9.mod\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [25/25], Batch [100/4502], Loss: 0.0188\n",
            "Epoch [25/25], Batch [200/4502], Loss: 0.0001\n",
            "Epoch [25/25], Batch [300/4502], Loss: 0.0084\n",
            "Epoch [25/25], Batch [400/4502], Loss: 0.0004\n",
            "Epoch [25/25], Batch [500/4502], Loss: 0.0017\n",
            "Epoch [25/25], Batch [600/4502], Loss: 0.0000\n",
            "Epoch [25/25], Batch [700/4502], Loss: 0.0001\n",
            "Epoch [25/25], Batch [800/4502], Loss: 0.0001\n",
            "Epoch [25/25], Batch [900/4502], Loss: 0.0019\n",
            "Epoch [25/25], Batch [1000/4502], Loss: 0.0002\n",
            "Epoch [25/25], Batch [1100/4502], Loss: 0.0067\n",
            "Epoch [25/25], Batch [1200/4502], Loss: 0.0001\n",
            "Epoch [25/25], Batch [1300/4502], Loss: 0.0005\n",
            "Epoch [25/25], Batch [1400/4502], Loss: 0.0021\n",
            "Epoch [25/25], Batch [1500/4502], Loss: 0.0079\n",
            "Epoch [25/25], Batch [1600/4502], Loss: 0.0002\n",
            "Epoch [25/25], Batch [1700/4502], Loss: 0.0005\n",
            "Epoch [25/25], Batch [1800/4502], Loss: 0.0002\n",
            "Epoch [25/25], Batch [1900/4502], Loss: 0.0005\n",
            "Epoch [25/25], Batch [2000/4502], Loss: 0.0085\n",
            "Epoch [25/25], Batch [2100/4502], Loss: 0.0002\n",
            "Epoch [25/25], Batch [2200/4502], Loss: 0.0018\n",
            "Epoch [25/25], Batch [2300/4502], Loss: 0.0003\n",
            "Epoch [25/25], Batch [2400/4502], Loss: 0.0017\n",
            "Epoch [25/25], Batch [2500/4502], Loss: 0.0005\n",
            "Epoch [25/25], Batch [2600/4502], Loss: 0.0042\n",
            "Epoch [25/25], Batch [2700/4502], Loss: 0.0019\n",
            "Epoch [25/25], Batch [2800/4502], Loss: 0.0002\n",
            "Epoch [25/25], Batch [2900/4502], Loss: 0.0001\n",
            "Epoch [25/25], Batch [3000/4502], Loss: 0.0013\n",
            "Epoch [25/25], Batch [3100/4502], Loss: 0.0004\n",
            "Epoch [25/25], Batch [3200/4502], Loss: 0.0009\n",
            "Epoch [25/25], Batch [3300/4502], Loss: 0.0003\n",
            "Epoch [25/25], Batch [3400/4502], Loss: 0.0008\n",
            "Epoch [25/25], Batch [3500/4502], Loss: 0.0001\n",
            "Epoch [25/25], Batch [3600/4502], Loss: 0.0165\n",
            "Epoch [25/25], Batch [3700/4502], Loss: 0.0003\n",
            "Epoch [25/25], Batch [3800/4502], Loss: 0.0032\n",
            "Epoch [25/25], Batch [3900/4502], Loss: 0.0001\n",
            "Epoch [25/25], Batch [4000/4502], Loss: 0.0009\n",
            "Epoch [25/25], Batch [4100/4502], Loss: 0.0149\n",
            "Epoch [25/25], Batch [4200/4502], Loss: 0.0000\n",
            "Epoch [25/25], Batch [4300/4502], Loss: 0.0001\n",
            "Epoch [25/25], Batch [4400/4502], Loss: 0.0000\n",
            "Epoch [25/25], Batch [4500/4502], Loss: 0.0009\n",
            "Epoch 25/25, Loss: 0.0024118920333707516\n",
            "Updated Learning Rate: [2.9123522744271436e-06]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   overdrive       1.00      1.00      1.00      3012\n",
            "  distortion       1.00      1.00      1.00      4518\n",
            "        fuzz       1.00      1.00      1.00      5271\n",
            "     tremolo       1.00      1.00      1.00      5671\n",
            "      phaser       1.00      1.00      1.00      4518\n",
            "     flanger       0.99      1.00      1.00      3012\n",
            "      chorus       1.00      1.00      1.00      5671\n",
            "       delay       0.99      0.97      0.98      7530\n",
            " hall_reverb       0.98      0.97      0.98      4518\n",
            "plate_reverb       0.97      1.00      0.98      3012\n",
            "     octaver       0.98      1.00      0.99      2259\n",
            " auto_filter       1.00      1.00      1.00      3765\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     52757\n",
            "   macro avg       0.99      0.99      0.99     52757\n",
            "weighted avg       0.99      0.99      0.99     52757\n",
            " samples avg       0.97      0.97      0.97     52757\n",
            "\n",
            "\n",
            "Validation Loss: 0.0055, Accuracy: 0.9822, Precision: 0.9937, Recall: 0.9940, F1-score: 0.9938\n",
            "\n",
            "Model saved to /content/drive/MyDrive/Capstone 210/Models/final_multi_effects_alt9.mod\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=12, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=6, pin_memory=True)\n",
        "\n",
        "num_classes = len(train_dataset.label_map)\n",
        "\n",
        "model = spectrogramCNN(num_classes).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8681)  # 0.0001 → 0.000005 over 25 epochs\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=0.0005, momentum=0.9, weight_decay=1e-4)\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 25\n",
        "print_freq = 100\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_idx, (spectrograms, labels) in enumerate(train_loader):\n",
        "        spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(spectrograms)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if (batch_idx + 1) % print_freq == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    train_losses.append(epoch_loss)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss}\")\n",
        "\n",
        "    # Update learning rate\n",
        "    scheduler.step()\n",
        "    print(f\"Updated Learning Rate: {scheduler.get_last_lr()}\")\n",
        "\n",
        "    # Validation step\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for spectrograms, labels in val_loader:\n",
        "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "            outputs = model(spectrograms)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Compute accuracy\n",
        "            predicted = (torch.sigmoid(outputs) > 0.5).float()  # Convert logits to binary predictions\n",
        "\n",
        "            # Store for metric computation\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    # Convert lists to numpy arrays for metric calculations\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    # Compute metrics\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
        "\n",
        "    # Print classification report\n",
        "    class_names = train_dataset.label_map\n",
        "    print(classification_report(all_labels, all_preds, target_names=class_names))\n",
        "\n",
        "    print(f\"\\nValidation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\\n\")\n",
        "\n",
        "    torch.save(model.state_dict(), model_save_path)\n",
        "    print(f\"Model saved to {model_save_path}\")\n",
        "\n",
        "train_losses = np.array(train_losses)\n",
        "val_losses = np.array(val_losses)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(range(1, num_epochs + 1), train_losses, label=\"Training Loss\", marker=\"o\")\n",
        "plt.plot(range(1, num_epochs + 1), val_losses, label=\"Validation Loss\", marker=\"s\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training vs. Validation Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "sIrX9pf2J2j_",
        "outputId": "febdab0a-07d8-4001-cf80-2fb8fc9e8645"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArwAAAIjCAYAAADhisjVAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAhlpJREFUeJzt3Xd4U9X/B/B3VpOme0AXhbJkLxkFREAFWkAERAREGSoqUgTrAmU6vjgRBH8gKOBiuBgqVgqCIhTZyp6FMtpCC91tmib398dtQkPTJm2TZvB+PU+eJDcnNyc5Lbxz+rnnSgRBEEBERERE5Kakju4AEREREZE9MfASERERkVtj4CUiIiIit8bAS0RERERujYGXiIiIiNwaAy8RERERuTUGXiIiIiJyawy8REREROTWGHiJiIiIyK0x8BKR0xk3bhyioqKq9dw5c+ZAIpHYtkN3kB07dkAikWDHjh3GbdaOx4ULFyCRSLBq1Sqb9ikqKgrjxo2z6T6J6M7CwEtEVpNIJFZdyoYlsp+2bduifv36qOwM8ffccw9CQkJQUlJSiz2rut27d2POnDnIyspydFeMVq1aBYlEgv379zu6K0RUQ3JHd4CIXMfXX39tcv+rr75CYmJiue0tWrSo0essX74cer2+Ws+dMWMGpk2bVqPXdxWjR4/GtGnTsHPnTvTs2bPc4xcuXEBSUhLi4uIgl1f/n/uajIe1du/ejblz52LcuHHw9/c3eezUqVOQSjk/Q0TVx8BLRFZ7/PHHTe7v2bMHiYmJ5bbfrqCgAGq12urXUSgU1eofAMjl8hqFO1fy2GOPYfr06Vi9erXZwLtmzRoIgoDRo0fX6HVqMh62oFQqHfr6ROT6+JWZiGyqd+/eaN26NQ4cOICePXtCrVbj9ddfBwBs3LgRAwcORHh4OJRKJRo3boy33noLOp3OZB+314waakM//PBDLFu2DI0bN4ZSqUTnzp2xb98+k+eaq+GVSCSIi4vDhg0b0Lp1ayiVSrRq1QoJCQnl+r9jxw506tQJKpUKjRs3xmeffWZVXXBcXBy8vb1RUFBQ7rFRo0YhNDTU+D7379+PmJgYBAcHw9PTEw0bNsSTTz5Z6f7NiYyMRM+ePfHDDz9Aq9WWe3z16tVo3LgxoqOjcfHiRTz//PNo1qwZPD09ERQUhOHDh+PChQsWX8dcDW9WVhbGjRsHPz8/+Pv7Y+zYsWbLEf777z+MGzcOjRo1gkqlQmhoKJ588klkZmYa28yZMwevvPIKAKBhw4bG0hhD38zV8J4/fx7Dhw9HYGAg1Go1unbtil9//dWkjaEe+bvvvsM777yDevXqQaVS4YEHHsDZs2ctvm9rHTp0CP3794evry+8vb3xwAMPYM+ePSZttFot5s6di6ZNm0KlUiEoKAg9evRAYmKisU1aWhrGjx+PevXqQalUIiwsDIMHD7ZqjIiocnfGNAgR1arMzEz0798fI0eOxOOPP46QkBAAYk2kt7c34uPj4e3tjT/++AOzZs1CTk4OPvjgA4v7Xb16NXJzc/Hss89CIpHg/fffx8MPP4zz589bnIX8+++/8dNPP+H555+Hj48PPvnkEwwbNgwpKSkICgoCIAaX2NhYhIWFYe7cudDpdHjzzTdRp04di30bMWIEPv30U/z6668YPny4cXtBQQF+/vlnjBs3DjKZDNeuXUO/fv1Qp04dTJs2Df7+/rhw4QJ++ukni69hzujRo/HMM8/g999/x4MPPmjcfuTIERw9ehSzZs0CAOzbtw+7d+/GyJEjUa9ePVy4cAFLlixB7969cfz48SrNwAuCgMGDB+Pvv//Gc889hxYtWmD9+vUYO3ZsubaJiYk4f/48xo8fj9DQUBw7dgzLli3DsWPHsGfPHkgkEjz88MM4ffo01qxZg48//hjBwcEAUOHnnp6eju7du6OgoAAvvPACgoKC8OWXX+Khhx7CDz/8gKFDh5q0f/fddyGVSvHyyy8jOzsb77//PkaPHo1//vnH6vdckWPHjuHee++Fr68vXn31VSgUCnz22Wfo3bs3/vzzT0RHRwMQQ/28efPw9NNPo0uXLsjJycH+/ftx8OBB9O3bFwAwbNgwHDt2DJMnT0ZUVBSuXbuGxMREpKSkVPsgTiIqJRARVdOkSZOE2/8Z6dWrlwBAWLp0abn2BQUF5bY9++yzglqtFoqKiozbxo4dKzRo0MB4Pzk5WQAgBAUFCTdu3DBu37hxowBA+Pnnn43bZs+eXa5PAAQPDw/h7Nmzxm3//vuvAEBYtGiRcdugQYMEtVotXLlyxbjtzJkzglwuL7fP2+n1eiEiIkIYNmyYyfbvvvtOACD89ddfgiAIwvr16wUAwr59+yrdn7Vu3LghKJVKYdSoUSbbp02bJgAQTp06JQiC+c8+KSlJACB89dVXxm3bt28XAAjbt283brt9PDZs2CAAEN5//33jtpKSEuHee+8VAAgrV640bjf3umvWrDH5TARBED744AMBgJCcnFyufYMGDYSxY8ca70+dOlUAIOzcudO4LTc3V2jYsKEQFRUl6HQ6k/fSokULQaPRGNsuXLhQACAcOXKk3GuVtXLlSotjNWTIEMHDw0M4d+6ccdvVq1cFHx8foWfPnsZt7dq1EwYOHFjhfm7evCkAED744INK+0RE1cOSBiKyOaVSifHjx5fb7unpabydm5uLjIwM3HvvvSgoKMDJkyct7nfEiBEICAgw3r/33nsBiH/etqRPnz5o3Lix8X7btm3h6+trfK5Op8PWrVsxZMgQhIeHG9s1adIE/fv3t7h/iUSC4cOHY/PmzcjLyzNuX7duHSIiItCjRw8AMB6Q9csvv5gtQ6iqgIAADBgwAJs2bUJ+fj4AcQZ27dq16NSpE+666y4App+9VqtFZmYmmjRpAn9/fxw8eLBKr7l582bI5XJMnDjRuE0mk2Hy5Mnl2pZ93aKiImRkZKBr164AUOXXLfv6Xbp0MX6mAODt7Y1nnnkGFy5cwPHjx03ajx8/Hh4eHsb7Vfm5qYxOp8OWLVswZMgQNGrUyLg9LCwMjz32GP7++2/k5OQAEMf92LFjOHPmjNl9eXp6wsPDAzt27MDNmzdr1C8iKo+Bl4hsLiIiwiRgGBw7dgxDhw6Fn58ffH19UadOHeMBb9nZ2Rb3W79+fZP7hvBrTUC4/bmG5xuee+3aNRQWFqJJkybl2pnbZs6IESNQWFiITZs2AQDy8vKwefNmDB8+3FgD3KtXLwwbNgxz585FcHAwBg8ejJUrV0Kj0Vj1GuaMHj0a+fn52LhxIwBxxYMLFy6YHKxWWFiIWbNmITIyEkqlEsHBwahTpw6ysrKs+uzLunjxIsLCwuDt7W2yvVmzZuXa3rhxA1OmTEFISAg8PT1Rp04dNGzYEIB1Y17R65t7LcPqIBcvXjTZXpOfm8pcv34dBQUFFfZFr9fj0qVLAIA333wTWVlZuOuuu9CmTRu88sor+O+//4ztlUol3nvvPfz2228ICQlBz5498f777yMtLa1GfSQiEQMvEdlc2Vk9g6ysLPTq1Qv//vsv3nzzTfz8889ITEzEe++9BwBWLXslk8nMbhcqWYfWFs+1VteuXREVFYXvvvsOAPDzzz+jsLAQI0aMMLaRSCT44YcfjMuFXblyBU8++SQ6duxoMjNcFQ8++CD8/PywevVqAGKts0wmw8iRI41tJk+ejHfeeQePPvoovvvuO2zZsgWJiYkICgqy65Jjjz76KJYvX47nnnsOP/30E7Zs2WI8WNDeS50Z1MbYW9KzZ0+cO3cOK1asQOvWrfH555/j7rvvxueff25sM3XqVJw+fRrz5s2DSqXCzJkz0aJFCxw6dKjW+knkrhh4iahW7NixA5mZmVi1ahWmTJmCBx98EH369DEpUXCkunXrQqVSmT16vypH9D/66KNISEhATk4O1q1bh6ioKOOf8Mvq2rUr3nnnHezfvx/ffvstjh07hrVr11ar70qlEo888gi2bNmC9PR0fP/997j//vsRGhpqbPPDDz9g7Nix+Oijj/DII4+gb9++6NGjR7VO9NCgQQOkpqaWC+inTp0yuX/z5k1s27YN06ZNw9y5czF06FD07dvX5M//BlU5O16DBg3KvRYAY1lMgwYNrN5XTdSpUwdqtbrCvkilUkRGRhq3BQYGYvz48VizZg0uXbqEtm3bYs6cOSbPa9y4MV566SVs2bIFR48eRXFxMT766CN7vxUit8fAS0S1wjDLVnZWrbi4GP/3f//nqC6ZkMlk6NOnDzZs2ICrV68at589exa//fab1fsZMWIENBoNvvzySyQkJODRRx81efzmzZvlZhbbt28PACZlDefOncO5c+esft3Ro0dDq9Xi2WefxfXr18utvSuTycq97qJFi8otCWeNAQMGoKSkBEuWLDFu0+l0WLRoUbnXBMrPpC5YsKDcPr28vADAqgA+YMAA7N27F0lJScZt+fn5WLZsGaKiotCyZUtr30qNyGQy9OvXDxs3bjRZOiw9PR2rV69Gjx494OvrCwAmy7ABYs1xkyZNjGNeUFCAoqIikzaNGzeGj49PjcpdiEjEZcmIqFZ0794dAQEBGDt2LF544QVIJBJ8/fXXtfpnZUvmzJmDLVu24J577sHEiROh0+mwePFitG7dGocPH7ZqH3fffTeaNGmCN954AxqNxqScAQC+/PJL/N///R+GDh2Kxo0bIzc3F8uXL4evry8GDBhgbPfAAw8AgNVrsPbq1Qv16tXDxo0b4enpiYcfftjk8QcffBBff/01/Pz80LJlSyQlJWHr1q3GJdmqYtCgQbjnnnswbdo0XLhwAS1btsRPP/1UribX19fXWIuq1WoRERGBLVu2IDk5udw+O3bsCAB44403MHLkSCgUCgwaNMgYhMuaNm0a1qxZg/79++OFF15AYGAgvvzySyQnJ+PHH3+0+VnZVqxYYXbN5ilTpuDtt99GYmIievTogeeffx5yuRyfffYZNBoN3n//fWPbli1bonfv3ujYsSMCAwOxf/9+/PDDD4iLiwMAnD59Gg888AAeffRRtGzZEnK5HOvXr0d6erpJaQoRVQ8DLxHViqCgIPzyyy946aWXMGPGDAQEBODxxx/HAw88gJiYGEd3D4AYun777Te8/PLLmDlzJiIjI/Hmm2/ixIkTVq0iYTBixAi88847aNKkCe6++26Tx3r16oW9e/di7dq1SE9Ph5+fH7p06YJvv/3WeDBXdUilUowaNQoffPABBg0aBB8fH5PHFy5cCJlMhm+//RZFRUW45557sHXr1mp99lKpFJs2bcLUqVPxzTffQCKR4KGHHsJHH32EDh06mLRdvXo1Jk+ejE8//RSCIKBfv3747bffTFbCAIDOnTvjrbfewtKlS5GQkAC9Xo/k5GSzgTckJAS7d+/Ga6+9hkWLFqGoqAht27bFzz//jIEDB1b5/VhSdia7rHHjxqFVq1bYuXMnpk+fjnnz5kGv1yM6OhrffPONcQ1eAHjhhRewadMmbNmyBRqNBg0aNMDbb79tPOFGZGQkRo0ahW3btuHrr7+GXC5H8+bN8d1332HYsGE2f09EdxqJ4EzTK0RETmjIkCGVLilFRETOjTW8RERlFBYWmtw/c+YMNm/ejN69ezumQ0REVGOc4SUiKiMsLAzjxo1Do0aNcPHiRSxZsgQajQaHDh1C06ZNHd09IiKqBtbwEhGVERsbizVr1iAtLQ1KpRLdunXD//73P4ZdIiIXxhleIiIiInJrrOElIiIiIrfGwEtEREREbo01vGbo9XpcvXoVPj4+VTrdJRERERHVDkEQkJubi/DwcIsnnGHgNePq1asm5z8nIiIiIud06dIl1KtXr9I2DLxmGM5QdOnSJeN50LVaLbZs2YJ+/fpBoVA4sntkIxxT98RxdT8cU/fDMXVPtT2uOTk5iIyMLHdmSXMYeM0wlDH4+vqaBF61Wg1fX1/+croJjql74ri6H46p++GYuidHjas15ac8aI2IiIiI3BoDLxERERG5NQZeIiIiInJrrOElIiKiGtHpdNBqtVa312q1kMvlKCoqgk6ns2PPqDbZelxlMhnkcrlNlohl4CUiIqJqy8vLw+XLlyEIgtXPEQQBoaGhuHTpEte7dyP2GFe1Wo2wsDB4eHjUaD8MvERERFQtOp0Oly9fhlqtRp06dawOOXq9Hnl5efD29rZ4wgByHbYcV0EQUFxcjOvXryM5ORlNmzat0T4ZeImIiKhatFotBEFAnTp14OnpafXz9Ho9iouLoVKpGHjdiK3H1dPTEwqFAhcvXjTut7r4U0ZEREQ1wrIEshdbfSFi4CUiIiIit8bAS0RERERujYGXiIiIHEqnF5B0LhMbD19B0rlM6PTWr/jgLKKiorBgwQKr2+/YsQMSiQRZWVl26xPdwoPWiIiIyGESjqZi7s/HkZpdZNwW5qfC7EEtEds6zOavZ6neePbs2ZgzZ06V97tv3z54eXlZ3b579+5ITU2Fn59flV+rKnbs2IH77rsPN2/ehL+/v11fy5kx8BIREZFDJBxNw6TVh3D7fG5adhEmfnMQSx6/2+ahNzU11Xh73bp1mDVrFk6dOmXc5u3tbbwtCAJ0Oh3kcstxqU6dOlXqh4eHB0JDQ6v0HKo+ljQ4StYl4Orhii9ZlxzYOSIioqoTBAEFxSVWXfKKSjD3l+Plwi4A47Y5m44jt0hr1f6sPfFFaGio8eLn5weJRGK8f/LkSfj4+OC3335Dx44doVQq8ffff+PcuXMYPHgwQkJC4O3tjc6dO2Pr1q0m+729pEEikeDzzz/H0KFDoVar0bRpU2zatMn4+O0lDatWrYK/vz9+//13tGjRAt7e3oiNjTUJ6CUlJXjhhRfg7++PoKAgvPbaaxg7diyGDBli1Xs35+bNmxgzZgwCAgKgVqvRv39/nDlzxvj4xYsXMWjQIAQEBMDLywutWrXC5s2bjc8dPXq0cVm6Zs2a4dtvv612X+yJM7yOkHUJWNwRKNFU3EauBOIOAP6RtdcvIiKiGijU6tBy1u822ZcAIC2nCG3mbLGq/fE3Y6D2sE2smTZtGj788EM0atQIAQEBuHTpEgYMGIB33nkHSqUSX331FQYNGoRTp06hfv36Fe5n7ty5eP/99/HBBx9g0aJFGD16NC5evIjAwECz7QsKCvDhhx/i66+/hlQqxeOPP46XX37ZGCLfe+89fPvtt1i5ciVatGiBhQsXYsOGDbjvvvuq/V7HjRuHM2fOYNOmTfD19cVrr72GAQMG4Pjx41AoFJg0aRKKi4vx119/wcvLC8ePHzfOgs+cORPHjx/Hb7/9huDgYJw+fRqZmZnV7os9MfA6QkFm5WEXEB8vyGTgJSIiqmVvvvkm+vbta7wfGBiIdu3aGe+/9dZbWL9+PTZt2oS4uLgK9zNu3DiMGjUKAPC///0Pn3zyCfbu3YvY2Fiz7bVaLZYuXYrGjRsDAOLi4vDmm28aH1+0aBGmT5+OoUOHAgAWL15snG2tDkPQ3bVrF7p37w4A+PbbbxEZGYkNGzZg+PDhSElJwbBhw9CmTRsAQKNGjYzPT0lJQYcOHdCpUycAQP369ZGTk1Pt/tgTAy8RERHZhKdChuNvxlhsp9fr8eexy5j0/QmLbVeN74wuDc3PiN7+2rZiCHAGeXl5mDNnDn799VekpqaipKQEhYWFSElJqXQ/bdu2Nd728vKCr68vrl27VmF7tVptDLsAEBYWZmyfnZ2N9PR0dOnSxfi4TCZDx44dodfrq/T+DE6cOAG5XI7o6GjjtqCgIDRr1gwnTohj88ILL2DixInYsmUL+vTpg2HDhhnf18SJEzFs2DAcPHgQ/fr1w0MPPYTWrVtXqy/2xhpeIiIisgmJRAK1h9yqS9eGAQj1VaGiNRMkEFdruLdpHav2Z8uzvd2+2sLLL7+M9evX43//+x927tyJw4cPo02bNiguLq50PwqFwvQ9SSSVhlNz7a2tTbaXp59+GufPn8cTTzyBI0eOoFOnTli0aBEAoH///rh48SJefPFFXL16FX379sXMmTMd2t+KMPASERFRrZNJJZj1YAsAKBd6DfdnD2oJmdTxpy3etWsXxo0bh6FDh6JNmzYIDQ3FhQsXarUPfn5+CAkJwb59+4zbdDodDh48WO19tmjRAiUlJfjnn3+M2zIzM3Hq1Cm0bNnSuC0yMhLPPfccfvrpJ7z00ktYvny58bE6depg7Nix+OabbzB//nx8+eWX1e6PPbGkgYiIiBwitnUoljx+d7l1eEPtuA5vdTRt2hQ//fQTBg0aBIlEgpkzZ1a7jKAmJk+ejHnz5qFJkyZo3rw5Fi1ahJs3b1o1u33kyBH4+PgY70skErRr1w6DBw/GhAkT8Nlnn8HHxwfTpk1DREQEBg8eDACYOnUq+vfvj7vuugs3b97E9u3b0aKF+EVl1qxZ6NixI1q1agWNRoNff/0Vd911l33efA0x8BIREZHDxLYOQ9+WodibfAPXcotQ10eFLg0DnWJm12D+/Pl48skn0b17dwQHB+O1115zyMFZr732GtLS0jBmzBjIZDI888wziImJgUxmuX65Z8+eJvdlMhlKSkqwcuVKTJkyBQ8++CCKi4vRs2dPbN682VheodPpMGnSJFy+fBm+vr6IjY3Fxx9/DEBcS3j69Om4cOECPD090aNHD3zxxRe2f+M2IBEcXRzihHJycuDn54fs7Gz4+voCEI+c3Lx5MwYMGFCuxqbKrh4GlvWy3O6ZP4Hw9jV7LaqQTceUnAbH1f1wTJ1XUVERkpOT0bBhQ6hUKqufp9frkZOTA19fX0ilrK6sLr1ejxYtWuDRRx/FW2+95eju2GVcK/sZM5fXKsIZXkdQB4nr7Fpah1cdVHt9IiIiIqd28eJFbNmyBb169YJGo8HixYuRnJyMxx57zNFdc3oMvI7gHymeVKKgdHHmQ98C+5YBd/UHek8Tt6mDuAYvERERGUmlUqxatQovv/wyBEFA69atsXXrVmNNLVWMgddR/CNvBdorB8RrqYwlDERERGRWZGQkdu3a5ehuuCQWzjgDT3/xuijbod0gIiIickcMvM5A5SdeF2U5tBtERERE7oiB1xmo/MXrQs7wEhEREdkaA68zMAReljQQERER2ZzDA++nn36KqKgoqFQqREdHY+/evRW2PXbsGIYNG4aoqChIJBIsWLCgXJt58+ahc+fO8PHxQd26dTFkyBCcOnXKju/ABgwlDZocwAFnbiEiIiJyZw4NvOvWrUN8fDxmz56NgwcPol27doiJicG1a9fMti8oKECjRo3w7rvvIjQ01GybP//8E5MmTcKePXuQmJgIrVaLfv36IT8/355vpWZUhsWSBUDDWV4iIiIiW3Jo4J0/fz4mTJiA8ePHo2XLlli6dCnUajVWrFhhtn3nzp3xwQcfYOTIkVAqlWbbJCQkYNy4cWjVqhXatWuHVatWISUlBQcOHLDnW6kZuRKQe4q3WdZARER3iuxL4tlHK7pkXXJg5yrXu3dvTJ061Xg/KirK7F+ey5JIJNiwYUONX9tW+7mTOGwd3uLiYhw4cADTp083bpNKpejTpw+SkpJs9jrZ2WKADAwMrLCNRqOBRnPrrGeG82NrtVpotVrj7bLXtiZX+UGSVwhtXibgHWGX1yBT9h5TcgyOq/vhmDovrVYLQRCg1+uhr0JJniAIkORcgeTL+wBdxWcdFeRKCJP2AX62OxHTQw89BK1Wi99++63cYzt37kTv3r1x6NAhtG3b1uK+DO8dAP755x94eXlZ/Byq8lnNnTsXGzduxMGDB022X7lyBQEBAVX6zKtq1apViI+Px40bN6x+jiAIxmtb9U2v10MQBGi1WshkMpPHqvJvgsMCb0ZGBnQ6HUJCQky2h4SE4OTJkzZ5Db1ej6lTp+Kee+5B69atK2w3b948zJ07t9z2LVu2QK1Wm2xLTEy0Sd9ud1+JDL4A9v65BRk+l+3yGmSevcaUHIvj6n44ps5HLpcjNDQUeXl5KC4urtJzZUU3IKkk7AKApESDvOsp0En8atJNE6NGjcKYMWNw4sQJRESYTjAtX74cHTp0QFRUlHHyqyIlJSUoLi42tlMqlSgpKbH4vMLCQottDDQaDXQ6Xbn2arW63GSdrRUVFUEQBKv7WlZubq7N+lFcXIzCwkL89ddfKCkpMXmsoKDA6v249ZnWJk2ahKNHj+Lvv/+utN306dMRHx9vvJ+Tk4PIyEj069cPvr5ifa1Wq0ViYiL69u0LhUJh877Kri8GLl9BdLvmEJoPsPn+qTx7jyk5BsfV/XBMnVdRUREuXboEb29vqFQqQBAAreUQIggCCkqKrHoNLw8ZoJJZbqhQAxKJxWbDhw/HSy+9hJ9++glvvPGGcXteXh42btyI9957D1qtFpMnT8bOnTtx8+ZNNG7cGNOmTcOoUaOM7eVyOTw8PIw5oVGjRpgyZQqmTJkCADhz5gwmTJiAvXv3olGjRvj4448BAJ6ensbnTJs2DRs2bMDly5cRGhqKxx57DDNnzoRCocCqVavw3nvvAQACAgIAAF988QXGjRsHmUyGH3/8EUOGDAEAHDlyBC+++CKSkpKgVqvx8MMP46OPPoK3tzcAYPz48cjKykKPHj0wf/58FBcXY8SIEfj4448r/J1SqVSQSCTGvt4uJSUFL7zwAv744w9IpVLExMRg4cKFUKvV8PHxwX///Yf4+Hjs378fEokETZs2xZIlS9CpUydcvHgRkydPxq5du1BcXIyoqCi89957GDCgfP4pKiqCp6cnevbsKf6MlVGVMO6wwBscHAyZTIb09HST7enp6RUekFYVcXFx+OWXX/DXX3+hXr16lbZVKpVma4IVCkW5HwRz22yi9Gxrcm0ewH/Qa5XdxpQciuPqfjimzken00EikUAqlUIqlQLF+cC7lf+fa+Bj5WtIV/W3ruHrVwEPL4vNPDw8MGbMGHz55ZeYMWMGJKUh+ccff4ROp8Po0aORl5eHTp06Ydq0afD19cWvv/6KsWPHomnTpujSpYtxX4b3fvt9vV6PRx55BCEhIfjnn3+QnZ1trPc1flYAfH19sWrVKoSHh+PIkSOYMGECfH198eqrr2LUqFE4fvw4EhISsHXrVgCAn5+f8bmG/eTn56N///7o1q0b9u3bh2vXruHpp5/GCy+8gFWrVhn7tWPHDoSHh2P79u04e/YsRowYgQ4dOmDChAnmP/cyr3M7vV6PoUOHwtvbG3/++SdKSkowadIkPPbYY9iwYQMkEgmeeOIJdOjQAUuWLIFMJsPhw4ehVCohlUoxefJkFBcX46+//oKXlxeOHz8OX19fs68llUohkUgqzGTWcljg9fDwQMeOHbFt2zbjNxS9Xo9t27YhLi6u2vsVBAGTJ0/G+vXrsWPHDjRs2NBGPbYzrsVLRERUK5588kl88MEH+PPPP9G7d28AwMqVKzFs2DD4+fnBz88PL7/8srH95MmT8fvvv+O7774zCbwV2bp1K06ePInff/8d4eHhAID//e9/6N/fNLzPmDHDeDsqKgovv/wy1q5di1dffRWenp7w9vY2lo1UZPXq1SgqKsJXX30FLy8x8C9evBiDBg3Ce++9ZywdDQgIwOLFiyGTydC8eXMMHDgQ27ZtqzDwVmbbtm04cuQIkpOTERkp1ld/9dVXaNWqFQ4ePIjevXsjJSUFr7zyCpo3bw4AaNq0qfH5KSkpGDZsGNq0aQNAnB23N4eWNMTHx2Ps2LHo1KkTunTpggULFiA/Px/jx48HAIwZMwYRERGYN28eALGO4/jx48bbV65cweHDh+Ht7Y0mTZoAEMsYVq9ejY0bN8LHxwdpaWkAxG9Fnp6eDniXVjKeXpiBl4iIXJRCLc60WqDX65F/fg98vnvE8j6fTABCLR9ABoXacptSzZs3R/fu3bFixQr07t0bZ8+exc6dO/Hmm28CEGeu//e//+G7777DlStXUFxcDI1GU+64noqcOHECkZGRxrALAN26dSvXbt26dfjkk09w7tw55OXloaSkpMISgspeq127dsawCwD33HMP9Ho9Tp06ZQy8rVq1MjnoKywsDEeOHKnSa5V9zcjISGPYBYCWLVvC398fp0+fRu/evREfH4+nn34aX3/9Nfr06YPhw4ejcePGAIAXXngBEydOxJYtW9CnTx8MGzbMqoMEa8Khy5KNGDECH374IWbNmoX27dvj8OHDSEhIMA5OSkoKUlNTje2vXr2KDh06oEOHDkhNTcWHH36IDh064Omnnza2WbJkCbKzs9G7d2+EhYUZL+vWrav191clxsCb5dBuEBERVZtEIpYVWHORqyzvDxCX7bRmf1bU75b11FNP4ccff0Rubi5WrlyJxo0bo1evXgCADz74AAsXLsRrr72G7du34/Dhw4iJianygXmVSUpKwujRozFgwAD88ssvOHToEN544w2bvkZZt//5XyKR2HWVhzlz5uDYsWMYOHAg/vjjD7Rs2RLr168HADz99NM4f/48nnjiCRw5cgSdOnXCokWL7NYXwAkOWouLi6uwhGHHjh0m96OiooxLXlTE0uNOq7SGlzO8RERE9vfoo49iypQpWL16Nb766itMnDjRWM+7a9cuDB48GI8//jgAcUb69OnTaNmypVX7btGiBS5duoTU1FSEhYUBAPbs2WPSZvfu3WjQoIHJgXMXL140aePh4QGdTmfxtVatWoX8/HzjLO+uXbsglUrRrFkzq/pbVYb3d+nSJeMs7/Hjx5GVlWXymnfddRfuuusuvPjiixg1ahRWrlyJoUOHAgAiIyPx3HPP4bnnnsP06dOxfPlyTJ482S79BZzg1MJUiiUNRER0B9GrAiHIzZ9EykiuBNRBdnl9b29vjBgxAtOnT0dqairGjRtnfKxp06ZITEzE7t27ceLECTz77LPlDrKvTJ8+fXDXXXdh7Nix+Pfff7Fz506TYGt4jZSUFKxduxbnzp3DJ598YpwBNYiKikJycjIOHz6MjIwMs8uQjR49GiqVCmPHjsXRo0exfft2TJ48GU888US5pV+rSqfT4fDhwyaXEydOoE+fPmjTpg1Gjx6NgwcPYu/evRgzZgx69eqFDh06oLCwEHFxcdixYwcuXryIXbt2Yd++fWjRogUAYOrUqfj999+RnJyMgwcPYvv27cbH7MXhM7xUyhB4C7Mc2g0iIqLaIPhGQJi0D5LCmxU3UgcB/rY76cTtnnrqKXzxxRcYMGCASb3tjBkzcP78ecTExECtVuOZZ57BkCFDjCezskQqlWL9+vV46qmn0KVLF0RFReGTTz5BbGyssc1DDz2EF198EXFxcdBoNBg4cCBmzpyJOXPmGNsMGzYMP/30E+677z5kZWVh5cqVJsEcENfk/f333zFlyhR07twZarUaw4YNw/z582v02QDiUm0dOnQw2da4cWOcPXsWGzduxOTJk9GzZ09IpVLExsZi4cKFAACZTIbMzEyMGTMG6enpCA4OxsMPP2w854FOp8OkSZNw+fJl+Pr6IjY21rhsm71IBJetAbCfnJwc+Pn5ITs722Qd3s2bN2PAgAH2WRbn/A7gq8FAnRbApD0Wm1PN2X1MySE4ru6HY+q8ioqKkJycjIYNG5ZbI7Uyer0eOTk5FS5FRa7JHuNa2c+YubxWEf6UOQsuS0ZERERkFwy8zoI1vERERER2wcDrLAyBV5sP6LSO7QsRERGRG2HgdRaGwAtwlpeIiIjIhhh4nYVUBihLC64ZeImIyIXw+HeyF1v9bDHwOhOebY2IiFyI4VS19jo7GFFBQQGA8meKqyquw+tMVH5A9iWuxUtERC5BLpdDrVbj+vXrUCgUVi9FpdfrUVxcjKKiIi5L5kZsOa6CIKCgoADXrl2Dv7+/8ctVdTHwOhOu1EBERC5EIpEgLCwMycnJ5U6LWxlBEFBYWAhPT0/j6XzJ9dljXP39/REaGlrj/TDwOhOuxUtERC7Gw8MDTZs2rVJZg1arxV9//YWePXvyZCJuxNbjqlAoajyza8DA60xYw0tERC5IKpVW6UxrMpkMJSUlUKlUDLxuxJnHlYUzzoQlDUREREQ2x8DrTDz9xWsGXiIiIiKbYeB1JpzhJSIiIrI5Bl5nYgi8XJaMiIiIyGYYeJ0JZ3iJiIiIbI6B15lwWTIiIiIim2PgdSac4SUiIiKyOQZeZ1J2HV5BcGhXiIiIiNwFA68zMQReXTFQUuTYvhARERG5CQZeZ6L0ASSlQ8KyBiIiIiKbYOB1JhIJ63iJiIiIbIyB19lwLV4iIiIim2LgdTZcmoyIiIjIphh4nQ1LGoiIiIhsioHX2ZRdmoyIiIiIaoyB19kw8BIRERHZFAOvs/H0F69Z0kBERERkEwy8zoY1vEREREQ2xcDrbAyrNHBZMiIiIiKbYOB1NpzhJSIiIrIpBl5nw3V4iYiIiGyKgdfZcIaXiIiIyKYYeJ0NlyUjIiIisikGXmdTdlkyQXBoV4iIiIjcAQOvszHM8Ap6oDjPsX0hIiIicgMMvM5GrgJkHuJtLk1GREREVGMMvM5GIuGBa0REREQ2xMDrjLg0GREREZHNMPA6I87wEhEREdkMA68z4tJkRERERDbDwOuMOMNLREREZDMMvM6o7Fq8RERERFQjDLzOiDO8RERERDbDwOuMDIGX6/ASERER1RgDrzPismRERERENsPA64xY0kBERERkMwy8zojLkhERERHZDAOvM2JJAxEREZHNMPA6Iy5LRkRERGQzDLzOyFDSoMkB9DrH9oWIiIjIxTHwOiOl763bnOUlIiIiqhEGXmck9wAUavE2Ay8RERFRjTDwOiseuEZERERkEwy8zopr8RIRERHZhMMD76effoqoqCioVCpER0dj7969FbY9duwYhg0bhqioKEgkEixYsKDG+3RaXIuXiIiIyCYcGnjXrVuH+Ph4zJ49GwcPHkS7du0QExODa9eumW1fUFCARo0a4d1330VoaKhN9um0OMNLREREZBMODbzz58/HhAkTMH78eLRs2RJLly6FWq3GihUrzLbv3LkzPvjgA4wcORJKpdIm+3RaXIuXiIiIyCbkjnrh4uJiHDhwANOnTzduk0ql6NOnD5KSkmp1nxqNBhqNxng/JycHAKDVaqHVao23y17bm9TDBzIAuvwb0NfSa95pantMqXZwXN0Px9T9cEzdU22Pa1Vex2GBNyMjAzqdDiEhISbbQ0JCcPLkyVrd57x58zB37txy27ds2QK1Wm2yLTExsVp9q6rmV6+hGYCLp/7DkYLNtfKad6raGlOqXRxX98MxdT8cU/dUW+NaUFBgdVuHBV5nMn36dMTHxxvv5+TkIDIyEv369YOvr3gSCK1Wi8TERPTt2xcKhcLufZL+cwFI34SoUH9EDhhg99e7E9X2mFLt4Li6H46p++GYuqfaHlfDX+St4bDAGxwcDJlMhvT0dJPt6enpFR6QZq99KpVKszXBCoWi3ICZ22YX6kAAgFSTCyn/MbCrWhtTqlUcV/fDMXU/HFP3VFvjWpXXcNhBax4eHujYsSO2bdtm3KbX67Ft2zZ069bNafbpMFyWjIiIiMgmHFrSEB8fj7Fjx6JTp07o0qULFixYgPz8fIwfPx4AMGbMGERERGDevHkAxIPSjh8/brx95coVHD58GN7e3mjSpIlV+3QZXJaMiIiIyCYcGnhHjBiB69evY9asWUhLS0P79u2RkJBgPOgsJSUFUumtSeirV6+iQ4cOxvsffvghPvzwQ/Tq1Qs7duywap8ug8uSEREREdmEww9ai4uLQ1xcnNnHDCHWICoqCoIg1GifLoMzvEREREQ24fBTC1MFDIFXWwCUFDu2L0REREQujIHXWSl9b93mLC8RERFRtTHwOiupDFCyrIGIiIiophh4nRmXJiMiIiKqMQZeZ8bAS0RERFRjDLzOjEuTEREREdUYA68z49JkRERERDXGwOvMDIG3MMuh3SAiIiJyZQy8zowzvEREREQ1xsDrzFT+4jUDLxEREVG1MfA6M87wEhEREdUYA68z47JkRERERDXGwOvMOMNLREREVGMMvM6M6/ASERER1RgDrzPjsmRERERENcbA68zKljQIgmP7QkREROSiGHidmWFZMr0W0BY6tCtEREREroqB15l5eAESmXibdbxERERE1cLA68wkEi5NRkRERFRDDLzOjkuTEREREdUIA6+z49JkRERERDXCwOvsOMNLREREVCMMvM6Oa/ESERER1QgDr7PjDC8RERFRjTDwOjvDWrxcpYGIiIioWhh4nR2XJSMiIiKqEQZeZ8eSBiIiIqIaYeB1dsaSBgZeIiIioupg4HV2XIeXiIiIqEYYeJ0dlyUjIiIiqhEGXmfHGl4iIiKiGmHgdXaGGl5NDqDXO7QrRERERK6IgdfZGWZ4BT1QnOfYvhARERG5IAZeZ6dQATKleJtr8RIRERFVGQOvK2AdLxEREVG1MfC6Ai5NRkRERFRtDLyugEuTEREREVUbA68rYEkDERERUbUx8LoCBl4iIiKiamPgdQWGtXgZeImIiIiqjIHXFRhneLMc2g0iIiIiV8TA6wpY0kBERERUbQy8roDLkhERERFVGwOvK+AMLxEREVG1MfC6Aq7DS0RERFRtDLyugDO8RERERNXGwOsKuCwZERERUbUx8LoCQ+AtzgV0JQ7tChEREZGrYeB1BSrfW7c1OY7rBxEREZELYuB1BTIFoPASb/PkE0RERERVwsDrKrgWLxEREVG1MPC6Ci5NRkRERFQtDLyugkuTEREREVULA6+r4NJkRERERNXCwOsqOMNLREREVC0MvK7CGHizHNoNIiIiIlfDwOsqOMNLREREVC0MvK6Cy5IRERERVYvDA++nn36KqKgoqFQqREdHY+/evZW2//7779G8eXOoVCq0adMGmzdvNnk8Ly8PcXFxqFevHjw9PdGyZUssXbrUnm+hdnCGl4iIiKhaHBp4161bh/j4eMyePRsHDx5Eu3btEBMTg2vXrpltv3v3bowaNQpPPfUUDh06hCFDhmDIkCE4evSosU18fDwSEhLwzTff4MSJE5g6dSri4uKwadOm2npb9sF1eImIiIiqxaGBd/78+ZgwYQLGjx9vnIlVq9VYsWKF2fYLFy5EbGwsXnnlFbRo0QJvvfUW7r77bixevNjYZvfu3Rg7dix69+6NqKgoPPPMM2jXrp3FmWOnxxleIiIiomqRO+qFi4uLceDAAUyfPt24TSqVok+fPkhKSjL7nKSkJMTHx5tsi4mJwYYNG4z3u3fvjk2bNuHJJ59EeHg4duzYgdOnT+Pjjz+usC8ajQYajcZ4PycnBwCg1Wqh1WqNt8te1zq5NxQAhKIslDiqD27G4WNKdsFxdT8cU/fDMXVPtT2uVXkdhwXejIwM6HQ6hISEmGwPCQnByZMnzT4nLS3NbPu0tDTj/UWLFuGZZ55BvXr1IJfLIZVKsXz5cvTs2bPCvsybNw9z584tt33Lli1Qq9Um2xITEy2+N3vw1FxHPwD6/Bvl6papZhw1pmRfHFf3wzF1PxxT91Rb41pQUGB1W4cFXntZtGgR9uzZg02bNqFBgwb466+/MGnSJISHh6NPnz5mnzN9+nSTmeOcnBxERkaiX79+8PX1BSB+i0hMTETfvn2hUChq5b2YKMoGjr8EmaDFgH73A3JV7ffBzTh8TMkuOK7uh2Pqfjim7qm2x9XwF3lrOCzwBgcHQyaTIT093WR7eno6QkNDzT4nNDS00vaFhYV4/fXXsX79egwcOBAA0LZtWxw+fBgffvhhhYFXqVRCqVSW265QKMoNmLlttUIWCEACQIBCVwh4+tR+H9yUw8aU7Irj6n44pu6HY+qeamtcq/IaDjtozcPDAx07dsS2bduM2/R6PbZt24Zu3bqZfU63bt1M2gPitLmhvaHmVio1fVsymQx6vd7G76CWSaWASpxt5oFrRERERNZzaElDfHw8xo4di06dOqFLly5YsGAB8vPzMX78eADAmDFjEBERgXnz5gEApkyZgl69euGjjz7CwIEDsXbtWuzfvx/Lli0DAPj6+qJXr1545ZVX4OnpiQYNGuDPP//EV199hfnz5zvsfdqMyk8Mu1yajIiIiMhqDg28I0aMwPXr1zFr1iykpaWhffv2SEhIMB6YlpKSYjJb2717d6xevRozZszA66+/jqZNm2LDhg1o3bq1sc3atWsxffp0jB49Gjdu3ECDBg3wzjvv4Lnnnqv192dzXJqMiIiIqMocftBaXFwc4uLizD62Y8eOctuGDx+O4cOHV7i/0NBQrFy50lbdcy4qf/G6KMuRvSAiIiJyKQ4/tTBVAWd4iYiIiKrM4TO8dzqdXsDe5Bu4lluEuj4qdGkYCJlUYr4xZ3iJiIiIqoyB14ESjqZi7s/HkZpdZNwW5qfC7EEtEds6rPwTOMNLREREVGUsaXCQhKOpmPjNQZOwCwBp2UWY+M1BJBxNLf8kT3/xmoGXiIiIyGoMvA6g0wuY+/NxCGYeM2yb+/Nx6PS3tTDM8HJZMiIiIiKrMfA6wN7kG+VmdssSAKRmF2Fv8g3TB1jSQERERFRlDLwOcC234rBbaTsGXiIiIqIqY+B1gLo+quq1M67SwMBLREREZC0GXgfo0jAQYX4qVLD4GCQQV2vo0jDQ9AHjDG+WHXtHRERE5F4YeB1AJpVg9qCWAFAu9Bruzx7Usvx6vGVLGgRzh7wRERER0e0YeB0ktnUYljx+N0L9TMsWQv1UWPL43ebX4TUsS6YvAbQF9u8kERERkRvgiSccKLZ1GPq2DMWGw1fw0nf/QqWQYuer90Euq+B7iEINSOVi4C3KBjy8arfDRERERC6IM7wOJpNKMLCNOJtbpNUjX6OruLFEwrV4iYiIiKqIgdcJqBQyBHt7AAAuZ1koVeDSZERERERVwsDrJCL8PQEAV24WVt6QS5MRERERVQkDr5OICCgNvFmWAi+XJiMiIiKqCgZeJ2H9DC9LGoiIiIiqgoHXSRgC72UGXiIiIiKbYuB1EhEBagBWlDQY1uJl4CUiIiKyCgOvkzCWNFhbw8tlyYiIiIiswsDrJAwHrd3IL0ZBcUnFDXnQGhEREVGVMPA6CT9PBXyU4onvrlY2y8tlyYiIiIiqhIHXiRhmeSs9cI2Bl4iIiKhKGHidiFV1vCxpICIiIqoSBl4nYjz5RKUzvFyWjIiIiKgqGHidiFUzvMZlyXIAvd7+nSIiIiJycQy8TsSqGV6lb+kNAdDk2L9TRERERC6OgdeJWDXDq1ABcpV4m2UNRERERBYx8DoRwwxvek4RtLpKyhVYx0tERERkNQZeJxLspYSHXAq9AKRlF1XckEuTEREREVmNgdeJSKUSY1lD5WvxcmkyIiIiImsx8DqZqq3FyxleIiIiIksYeJ2MMfBWNsNrXJqMgZeIiIjIEgZeJ2NcmiyroOJGnOElIiIishoDr5OpUklDYZb9O0RERETk4hh4nQxPL0xERERkWwy8TsYww3s1qwh6vWC+EZclIyIiIrIaA6+TCfVTQSoBinV6ZORpzDfismREREREVmPgdTIKmRShvuKpgy9XVMfLkgYiIiIiq1Ur8F66dAmXL1823t+7dy+mTp2KZcuW2axjdzKLdbwMvERERERWq1bgfeyxx7B9+3YAQFpaGvr27Yu9e/fijTfewJtvvmnTDt6JLK7UwHV4iYiIiKxWrcB79OhRdOnSBQDw3XffoXXr1ti9eze+/fZbrFq1ypb9uyNZnuH1F6+L8wCdtnY6RUREROSiqhV4tVotlEolAGDr1q146KGHAADNmzdHamqq7Xp3h4rwVwOoZIZX6XvrdlFOLfSIiIiIyHVVK/C2atUKS5cuxc6dO5GYmIjY2FgAwNWrVxEUFGTTDt6JLM7wyuSAh7d4mys1EBEREVWqWoH3vffew2effYbevXtj1KhRaNeuHQBg06ZNxlIHqr6yNbyCwLV4iYiIiGpCXp0n9e7dGxkZGcjJyUFAQIBx+zPPPAO1Wm2zzt2pDIE3T1OCnMIS+KkV5Rup/ICcy5zhJSIiIrKgWjO8hYWF0Gg0xrB78eJFLFiwAKdOnULdunVt2sE7kaeHDEFeHgCAy1kF5htxaTIiIiIiq1Qr8A4ePBhfffUVACArKwvR0dH46KOPMGTIECxZssSmHbxTWazj5dJkRERERFapVuA9ePAg7r33XgDADz/8gJCQEFy8eBFfffUVPvnkE5t28E5lcS1ewwxvYVbtdIiIiIjIRVUr8BYUFMDHxwcAsGXLFjz88MOQSqXo2rUrLl68aNMO3qmMgZdnWyMiIiKqkWoF3iZNmmDDhg24dOkSfv/9d/Tr1w8AcO3aNfj6+lp4NlnDWNJgaYaXgZeIiIioUtUKvLNmzcLLL7+MqKgodOnSBd26dQMgzvZ26NDBph28U1kuafAXrxl4iYiIiCpVrWXJHnnkEfTo0QOpqanGNXgB4IEHHsDQoUNt1rk7Wb2A0rOtWSxpyKqdDhERERG5qGoFXgAIDQ1FaGgoLl++DACoV68eTzphQ4aShsz8YhQUl0DtcdtQsaSBiIiIyCrVKmnQ6/V488034efnhwYNGqBBgwbw9/fHW2+9Bb1eb+s+3pH8PBXwUYoh96q5sgYGXiIiIiKrVGuG94033sAXX3yBd999F/fccw8A4O+//8acOXNQVFSEd955x6advFNFBHjiZFouLt8sRJO6PqYPch1eIiIiIqtUK/B++eWX+Pzzz/HQQw8Zt7Vt2xYRERF4/vnnGXhtJMJfDLxmD1zjOrxEREREVqlWScONGzfQvHnzctubN2+OGzdu1LhTJKr0bGuGwKvTANqiWuwVERERkWupVuBt164dFi9eXG774sWL0bZt2yrt69NPP0VUVBRUKhWio6Oxd+/eStt///33aN68OVQqFdq0aYPNmzeXa3PixAk89NBD8PPzg5eXFzp37oyUlJQq9csZVLo0mYcPICkdPpY1EBEREVWoWiUN77//PgYOHIitW7ca1+BNSkrCpUuXzAbQiqxbtw7x8fFYunQpoqOjsWDBAsTExODUqVOoW7duufa7d+/GqFGjMG/ePDz44INYvXo1hgwZgoMHD6J169YAgHPnzqFHjx546qmnMHfuXPj6+uLYsWNQqVTVeasOVekMr1QKKH3FZcmKsgGfkNrtHBEREZGLqNYMb69evXD69GkMHToUWVlZyMrKwsMPP4xjx47h66+/tno/8+fPx4QJEzB+/Hi0bNkSS5cuhVqtxooVK8y2X7hwIWJjY/HKK6+gRYsWeOutt3D33XebzDa/8cYbGDBgAN5//3106NABjRs3xkMPPWQ2QDs7yyef4Fq8RERERJZUex3e8PDwcgen/fvvv/jiiy+wbNkyi88vLi7GgQMHMH36dOM2qVSKPn36ICkpyexzkpKSEB8fb7ItJiYGGzZsACAul/brr7/i1VdfRUxMDA4dOoSGDRti+vTpGDJkSIV90Wg00Gg0xvs5OTkAAK1WC61Wa7xd9ro2hHgrAADpOUUoKNJAITP9fiJX+kICoCQvE0It9stdOGJMyf44ru6HY+p+OKbuqbbHtSqvU+3AW1MZGRnQ6XQICTH9U3xISAhOnjxp9jlpaWlm26elpQEArl27hry8PLz77rt4++238d577yEhIQEPP/wwtm/fjl69epnd77x58zB37txy27ds2QK1Wm2yLTEx0er3WFN6AZBLZCgRJFi7MQFBt1VldM/XoQ6Aw3v+xJXTxbXWL3dTm2NKtYfj6n44pu6HY+qeamtcCwoKrG7rsMBrD4aTXgwePBgvvvgiAKB9+/bYvXs3li5dWmHgnT59usnMcU5ODiIjI9GvXz/4+voCEL9FJCYmom/fvlAoFHZ+J7csPPM3LmQW4K4OXRHdMNDkMdkP3wGnjqND84Zo12lArfXJXThqTMm+OK7uh2Pqfjim7qm2x9XwF3lrOCzwBgcHQyaTIT093WR7eno6QkNDzT4nNDS00vbBwcGQy+Vo2bKlSZsWLVrg77//rrAvSqUSSqWy3HaFQlFuwMxts6d6AWpcyCxAWq62/Ouq/QEAMm0uZPwHo9pqe0ypdnBc3Q/H1P1wTN1TbY1rVV6jSoH34YcfrvTxrKwsq/fl4eGBjh07Ytu2bcb6Wr1ej23btiEuLs7sc7p164Zt27Zh6tSpxm2JiYnGlSI8PDzQuXNnnDp1yuR5p0+fRoMGDazumzMxHrhmdi1ef/Gay5IRERERVahKgdfPz8/i42PGjLF6f/Hx8Rg7diw6deqELl26YMGCBcjPz8f48eMBAGPGjEFERATmzZsHAJgyZQp69eqFjz76CAMHDsTatWuxf/9+k4PkXnnlFYwYMQI9e/bEfffdh4SEBPz888/YsWNHVd6q0zAuTZZlpk6FgZeIiIjIoioF3pUrV9r0xUeMGIHr169j1qxZSEtLQ/v27ZGQkGA8MC0lJQVS6a2VCbp3747Vq1djxowZeP3119G0aVNs2LDBuAYvAAwdOhRLly7FvHnz8MILL6BZs2b48ccf0aNHD5v2vbZUujQZlyUjIiIissjhB63FxcVVWMJgblZ2+PDhGD58eKX7fPLJJ/Hkk0/aonsOZ9XphTnDS0RERFShap14gmqPYYb3alYR9HrB9EFPf/GagZeIiIioQgy8Ti7UTwWpBCjW6ZGRpzF9kDO8RERERBYx8Do5hUyKUF/xjBOXb6/jNQTewqza7RQRERGRC2HgdQEV1vGWneEVbit3ICIiIiIADLwuocKVGgzLkgk6oDi/djtFRERE5CIYeF1AhTO8Ck9AWnqWES5NRkRERGQWA68LiPBXAzAzwyuR8MA1IiIiIgsYeF0A1+IlIiIiqj4GXhdQtoZXuP3gNK7FS0RERFQpBl4XYAi8eZoS5BSWmD7IpcmIiIiIKsXA6wI8PWQI8vIAAFzOKjB9kCUNRERERJVi4HURVq3FS0RERETlMPC6CItr8TLwEhEREZnFwOsijIG3whnerNrtEBEREZGLYOB1EcaShnIzvCxpICIiIqoMA6+LqLCkgcuSEREREVWKgddFWDxojcuSEREREZnFwOsi6pWeXjgzvxiFxbpbD/CgNSIiIqJKMfC6CF9PObyVcgC3lTWwhpeIiIioUgy8LkIikRjreC/fLHPyCcMMryYH0Otrv2NERERETo6B14WYXalB5Vt6QwA0nOUlIiIiuh0DrwsxuxavXAnIxe0sayAiIiIqj4HXhXAtXiIiIqKqY+B1IRWebY1r8RIRERFViIHXhVic4eVavERERETlMPC6kHqlM7zpOUXQ6sqsyMCSBiIiIqIKMfC6kGBvJTxkUugFIC276NYDPPkEERERUYUYeF2IVCoxljVcvmnu5BNZtd8pIiIiIifHwOtijAeu8WxrRERERFZh4HUxZldqYOAlIiIiqhADr4u5tVJDmdMLc1kyIiIiogox8LqYSksauCwZERERUTkMvC7GOMPLkgYiIiIiqzDwuhjDDO/VrCLo9YK4kYGXiIiIqEIMvC4m1E8FqQQo1umRkacRN3IdXiIiIqIKMfC6GIVMilBfFQDgsqGO1zDDq80HdFoH9YyIiIjIOTHwuqBydbyGwAtwlpeIiIjoNgy8LqjcSg1SGaD0FW8z8BIRERGZYOB1QZWu1MClyYiIiIhMMPC6oAh/NYCKTi+cVfsdIiIiInJiDLwuiGvxEhEREVmPgdcFla3hFQTDWrz+4jUDLxEREZEJBl4XZAi8eZoS5BSWiBtZ0kBERERkFgOvC/L0kCHIywMAcDmrQNzIkgYiIiIisxh4XVSFa/Ey8BIRERGZYOB1UeXW4vX0F68ZeImIiIhMMPC6KGPgvX2Gl+vwEhEREZlg4HVRxpKGLJY0EBEREVWGgddFlStp4LJkRERERGYx8Lqoig9ay3JMh4iIiIicFAOvi6pXenrhzPxiFBbrTEsaDCejICIiIiIGXlfl6ymHt1IOoLSswRB4dcVASZEDe0ZERETkXBh4XZREIjGt41X6AJLS4WQdLxEREZERA68LM6njlUi4NBkRERGRGQy8LuzWDC9PL0xERERUEQZeF2aY4b3M0wsTERERVYiB14WVP9uav3jNwEtERERkxMDrwio+21qWYzpERERE5IScIvB++umniIqKgkqlQnR0NPbu3Vtp+++//x7NmzeHSqVCmzZtsHnz5grbPvfcc5BIJFiwYIGNe+149UpneNNziqDV6Rl4iYiIiMxweOBdt24d4uPjMXv2bBw8eBDt2rVDTEwMrl27Zrb97t27MWrUKDz11FM4dOgQhgwZgiFDhuDo0aPl2q5fvx579uxBeHi4vd+GQwR7K+Ehk0IvAGnZRazhJSIiIjLD4YF3/vz5mDBhAsaPH4+WLVti6dKlUKvVWLFihdn2CxcuRGxsLF555RW0aNECb731Fu6++24sXrzYpN2VK1cwefJkfPvtt1AoFLXxVmqdVCpBuL8KQOmBa57+4gNcloyIiIjISO7IFy8uLsaBAwcwffp04zapVIo+ffogKSnJ7HOSkpIQHx9vsi0mJgYbNmww3tfr9XjiiSfwyiuvoFWrVhb7odFooNFojPdzcnIAAFqtFlqt1ni77LWzCPdT4UJmAVIyc9FF4QMZAH1hFnRO1k9n5KxjSjXDcXU/HFP3wzF1T7U9rlV5HYcG3oyMDOh0OoSEhJhsDwkJwcmTJ80+Jy0tzWz7tLQ04/333nsPcrkcL7zwglX9mDdvHubOnVtu+5YtW6BWq022JSYmWrXP2qLLlQKQYsfe/9DEKxkdAWRePofdldQ1kylnG1OyDY6r++GYuh+OqXuqrXEtKCiwuq1DA689HDhwAAsXLsTBgwchkUises706dNNZo1zcnIQGRmJfv36wdfXF4D4LSIxMRF9+/Z1qhKJc9vP4Z8/zsGrbn20ayMHLi5FkLcCAwYMcHTXnJ6zjinVDMfV/XBM3Q/H1D3V9rga/iJvDYcG3uDgYMhkMqSnp5tsT09PR2hoqNnnhIaGVtp+586duHbtGurXr298XKfT4aWXXsKCBQtw4cKFcvtUKpVQKpXltisUinIDZm6bI9UP8gYApOYUQe4VBACQarIhdaI+OjtnG1OyDY6r++GYuh+OqXuqrXGtyms49KA1Dw8PdOzYEdu2bTNu0+v12LZtG7p162b2Od26dTNpD4hT54b2TzzxBP777z8cPnzYeAkPD8crr7yC33//3X5vxkFMTj7BVRqIiIiIynF4SUN8fDzGjh2LTp06oUuXLliwYAHy8/Mxfvx4AMCYMWMQERGBefPmAQCmTJmCXr164aOPPsLAgQOxdu1a7N+/H8uWLQMABAUFISgoyOQ1FAoFQkND0axZs9p9c7WgXunJJ65mFUGv9BW/wRRlA4IAWFnSQUREROTOHB54R4wYgevXr2PWrFlIS0tD+/btkZCQYDwwLSUlBVLprYno7t27Y/Xq1ZgxYwZef/11NG3aFBs2bEDr1q0d9RYcKtRPBakEKNbpkVHiiboAIOiB4jxA6ePo7hERERE5nMMDLwDExcUhLi7O7GM7duwot2348OEYPny41fs3V7frLhQyKUJ8VUjNLsLlPAF1ZR6Arlhci5eBl4iIiMjxJ56gmjPW8WbxbGtEREREt2PgdQMRAYbAywPXiIiIiG7HwOsGDAeuiSs1+Isbi7Ic1h8iIiIiZ8LA6wYi/MWzwXGGl4iIiKg8Bl43EBHAtXiJiIiIKsLA6wZuHbRWCMFY0sDAS0RERAQw8LoFQ+DN05RAIy9diqwwy3EdIiIiInIiDLxuwNNDhiAvDwBAtiCGX87wEhEREYkYeN2EoY43s4SBl4iIiKgsBl43YShrSNeqxA0MvEREREQAGHjdhiHwphYpxQ1ch5eIiIgIAAOv2zCUNKQUKsQNnOElIiIiAsDA6zYMM7wX8hl4iYiIiMpi4HUThhneM9kycYMmB9DrHNgjIiIiIufAwOsm6pWeXjilQHFrI2d5iYiIiBh43YWvpxzeSjm0kEMv59JkRERERAYMvG5CIpEY63i1Cl9xIwMvEREREQOvOzHU8RbKSk8vzKXJiIiIiBh43YlhhjdPItbzcoaXiIiIiIHXrRhmeLP1DLxEREREBgy8bsQww5upY+AlIiIiMmDgdSOGGd704tLTCxdmOa4zRERERE6CgdeN1Cud4U0zBF7O8BIREREx8LqTYG8lPGRSZAte4gYGXiIiIiIGXncilUoQ7q9CNhh4iYiIiAwYeN1MRIAncgTDQWtZDu0LERERkTNg4HUzEf6eyOEMLxEREZERA6+bifBXl5nhZeAlIiIiYuB1MxEBnrdqeLksGREREREDr7uJ8C9Tw1tSCJRoHNshIiIiIgdj4HUz9QI8kQf1rQ1FOY7rDBEREZETYOB1M6F+KkAiZR0vERERUSkGXjejkEkR4qtCDrg0GRERERHAwOuWxDpew9JkWQ7tCxEREZGjMfC6oYgAzzIzvCxpICIiojsbA68bivD3RLbAk08QERERAQy8bsnk9MJci5eIiIjucAy8boinFyYiIiK6hYHXDdUrM8MrMPASERHRHY6B1w2F+986vbA274aDe0NERETkWAy8bkjtIYfOwxcAUJx/08G9ISIiInIsBl435eEdAADQFWQ5tiNEREREDsbA66Y8fYLEG6zhJSIiojscA6+b8vEXA6+8OMfBPSEiIiJyLAZeN+UfWAcAoCzJBQTBwb0hIiIichy5oztA9hEULAZeOUoAbSHgobbdzrMuAQWZFT+uDgL8I233ekREREQ1wMDrpsLqBKNEkEIu0Yt1vLYKvFmXgMUdgRJNxW3kSiDuAEMvEREROQWWNLipegFeyIEYcotyK5mNraqCzMrDLiA+XtkMMBEREVEtYuB1U76ecuSVnnwiI+O6g3tDRERE5DgMvG5KIpGgSO4DALh5g4GXiIiI7lwMvG5MqxDPtpZ7k4GXiIiI7lwMvG5MUPoBAApybji4J0RERESOw8DrxmRqfwCAJs+Ggffyftvti4iIiKgWMPC6MYV3AABAV5Blmx2eSgASptlmX0RERES1hIHXjXn6iqcXlhRl13xnx9YD60YDei0gsfBjI1eKJ58gIiIicgI88YQb8/UTQ6dCmwOtTg+FrJrfbw6vATY+Dwh6oPUjwP0zxJNZlHUmEdj+NqAKAJ7eypNOEBERkdNg4HVjXqWB1wcFSMsuQmRgNc62tn8F8MuL4u0OTwCDFgJSWfl2Ia2AAyuBnCtAym4guEkNek5ERERkOyxpcGNStVjD6yvJx7p9l5B0LhM6vWD9DpI+vRV2uzwLDPrEfNgFAJkC6DpRvL17MaDX16DnRERERLbjFIH3008/RVRUFFQqFaKjo7F3795K23///fdo3rw5VCoV2rRpg82bNxsf02q1eO2119CmTRt4eXkhPDwcY8aMwdWrV+39NpzOnqtaAIAf8rF4+1mMWr4HPd77AwlHUyt/oiAAf34A/P66eL/Hi0D/9wCphR+Xu8cAHj5AxingbKIN3gERERFRzTk88K5btw7x8fGYPXs2Dh48iHbt2iEmJgbXrl0z23737t0YNWoUnnrqKRw6dAhDhgzBkCFDcPToUQBAQUEBDh48iJkzZ+LgwYP46aefcOrUKTz00EO1+bYcLuFoKmYkXAYA+EoKjNvTsosw8ZuDFYdeQQC2zRXrcQHgvhnAA7MBicTyi6r8gI5jxdu7F9Wk+0REREQ24/Aa3vnz52PChAkYP348AGDp0qX49ddfsWLFCkybVn4JrIULFyI2NhavvPIKAOCtt95CYmIiFi9ejKVLl8LPzw+Jiaazi4sXL0aXLl2QkpKC+vXrl9unRqOBRqMx3s/JyQEgzhZrtVrj7bLXzkynFzBn0zHoBLFm1wcFkEAPAVIIACQA5v58DL2bBkEmLRNkBT2kiTMg27dM3E+fN6GPfh4oKbH+xTtNgPyfpZBc2Altyj4grL3N3petudKYkvU4ru6HY+p+OKbuqbbHtSqv49DAW1xcjAMHDmD69OnGbVKpFH369EFSUpLZ5yQlJSE+Pt5kW0xMDDZs2FDh62RnZ0MikcDf39/s4/PmzcPcuXPLbd+yZQvUatMDvW4P087oTLYEaTkyKOEFAJBJBHijCLkQ34sAIDVbg8XrEtDUr7SmV9Cj3aWViMr8EwDwb+Q4XMiMAsqUi1jrbr8uiLy5G+nrZ+BA1PO2eEt25QpjSlXHcXU/HFP3wzF1T7U1rgUFBZYblXJo4M3IyIBOp0NISIjJ9pCQEJw8edLsc9LS0sy2T0tLM9u+qKgIr732GkaNGgVfX1+zbaZPn24SonNychAZGYl+/foZn6PVapGYmIi+fftCoVBY/R4d4ef/UoHjR6CBBzSCAkqJFr7INwZeg0at2mNA2zBAp4Xs5zhIM/+EIJFC9+AitGw7Ai2r24G0esAX9yMiax9C7mkD+DnnEmWuNKZkPY6r++GYuh+OqXuq7XE1/EXeGg4vabAnrVaLRx99FIIgYMmSJRW2UyqVUCqV5bYrFIpyA2Zum7MJ8/cy3s6BGnWQDV9JAa4I5dspJHpgwwTg5C+AVA7JsM8hbzW0Zh2I7Ag07AVJ8p9Q7P8ciP1fzfZnZ64wplR1HFf3wzF1PxxT91Rb41qV13DoQWvBwcGQyWRIT0832Z6eno7Q0FCzzwkNDbWqvSHsXrx4EYmJiRXO7rqjLg0DEeanggRAtiCGX1+YTvvX9VGiSz1PYO1jYtiVKYER3wI1DbsG3V8Qrw9+CRRm2WafRERERNXg0MDr4eGBjh07Ytu2bcZter0e27ZtQ7du3cw+p1u3bibtAbFWpGx7Q9g9c+YMtm7diqCgO+s0tzKpBLMHiQUJOaVlDH6SPNM2JfnQfv0IcHYroFADj60DmsXarhNNHgDqtgSK84ADq2y3XyIiIqIqcviyZPHx8Vi+fDm+/PJLnDhxAhMnTkR+fr5x1YYxY8aYHNQ2ZcoUJCQk4KOPPsLJkycxZ84c7N+/H3FxcQDEsPvII49g//79+Pbbb6HT6ZCWloa0tDQUFxc75D06QmzrMCx5/G5oZD4Abi1NFuKrRBMfHRbr3oLq8i7oFd7A4z8Bje+zbQckEqCbOCb4ZylQcud89kRERORcHF7DO2LECFy/fh2zZs1CWloa2rdvj4SEBOOBaSkpKZCWOeFB9+7dsXr1asyYMQOvv/46mjZtig0bNqB169YAgCtXrmDTpk0AgPbt25u81vbt29G7d+9aeV8Ol3UJsYGZ0DcMAM4DzzbXYEwzb7QKEqD/ZS4U2rPIErzwkmQW5vi0g10OK2vzCLDtTSA3FTj6I9B+lD1exblkXQIKMit+XB0E+DvnQXxERETuyuGBFwDi4uKMM7S327FjR7ltw4cPx/Dhw822j4qKgiBU4fS57ijrErC4I1CiMU7hNz23Cji3CgAgg7g02f9UL2Nbdj2cXLYH657tinoBavP7qy65Eoh+VjyRxe5FQLuR1p3AwlWV+dwrJFcCcQcYeomIiGqRw0sayA4KMisPXRBPPvHaIz3QMNgLV7IKMXLZHlzJKrR9XzqNBxRewLVjwLk/bL9/Z2LF544STeUzwERERGRzDLx3sCAvD6yZ0BUNgtS4fLMQI5cl4aqtQ69nAHD3GPE2TzdMREREDsDAe4cL9VNhzYSuqB+oxqUbhRi1fA9Ss20certOBCRS4Px2IO2IbfdNREREZAEDLyHc3xNrnumKyEBPXMwswKhle5CWXWS7FwhoALQcLN5O+tR2+3U2lsoZiIiIyCEYeAkAEOHviTUTuqJegCcuZBbgseV7kJ5jw9DbfbJ4feR7IPuK7fbrDIoLgN2LgdUjHN0TIiIiMoOBl4zqBaixZkJXRPh74nxGPkYt34Nrtgq9ER2BBvcA+hJg72e22aejFeeLdckL2wJb3gCKblr3PE2ufftFREREJhh4yURkoBprn+mKcD8Vzl8vDb25Ngq9hlne/SuBohzb7NMRivOBXZ8AC9sBW2YA+dcB//pAz1ete/6PTwEXdtm3j0RERGTEwOuO1EHieq+VkSvFdmaIobcbwvxUOHc9H6OX/4PruTaoT20aAwQ1BTQ5wKGva76/2lacD+xaCCxoCyTOFINuQBTw0GJg8kFxNQpLnzskQF46sGqgeFIOnbY2ek5ERHRHc4oTT5CN+UeKJzeowRm/6geJ5Q0jl+3BmWt5GP35Hqye0BXB3pYCXSWkUqB7HPDzFGDPEqDLM4BMUf391RZNHrBvuVi+YPhMA6KAnq8AbUfceg/WfO5yFZC0CDj0DbDzI+DcdmDY50BQY7u/DSIiojsVA6+78o+s8dm8ooK9sOaZrhi5LAmn0/Mwevk/WD0hGkE1Cb1tRwJ/vA1kXwKObxRPP+ysNLnA3tKgW3hD3BbQsDToPmo+rFvzuQ/+FGjSVwz+Vw8CS+8F+r8LdHjCvc9ER0RE5CAsaaBKNQz2wpoJXVHXR4lT6bkY/fk/uJFfXP0dKlTizC4A7P4EqO3TQGddAq4eFi+p/8Kv4AKQ+u+tbVmXxKC78yOxdGHbXDHsBjYChiwF4vYDHUbXfGa61RBg4m4g6l5Amw9smgx89wRQcKOm75CIiIhuwxlesqhRHe/Smd49OJkmht7VT0fD11OBvck3cC23CHV9VOjSMBAyqRUzlJ2eAnbOF4PmhZ1Aw572fxOAGGYXdzSul6sA0BsATpVpI5UBCm9Aky3eD2wM9HoVaP0IILPxr4tfBDBmoziD/MfbwImfgcv7gaFLgUa9bftaREREdzAGXrJK4zreWDMhGiOX/YMTqTkYtOhvaPV6pOfcOpgtzE+F2YNaIrZ1WOU78woSZ0n3fS6GvdoKvAWZlk8OodeJYTeoibjqQuthtg+6ZUllQI+pQKNewI8TgMwzwFeDxRUt7p9pxUFwREREZAlLGshqTer6YM2EaPio5LicVWgSdgEgLbsIE785iISjqZZ31vV5ABLgzBbg2kn7dLi67psBTNoLtBth37BbVngH4Nk/gY7jxfu7FwGfPwBcP1X584iIiMgiBl6qkkZ1vKGUm/+xMVTjzv35OHR6C7W5QY2BFg+Kt5MW266DttC0rzjzWts8vIBBC4CRqwHPQCDtCPBZT3EmvLZrnYmIiNwIAy9Vyd7kG8jIq/igNQFAanYR9iZbcfBV9xfE6//WAbnptumgO2g+EHg+CWh8P1BSBPz6ErBmJHC1zMF15i5ZlxzYaSIiIufFGl6qEmvPumZVu8guQGQ0cOkfYO8y4IGZNeydBa50djefUGD0j+JpmBNnAacTxEtl5EpxHeAaLkdHRETkbjjDS1VS10dlVburWYUQrPkzfLc48Xrf5+KZzOzl8n7gpwn22789SKVA14nAhO2Af5Tl9iWayk96QUREdIdi4KUq6dIwEGF+KlhafOy9hFN4aPEu/H4sDfrK6nmbDxRP5lCUBRz61pZdFQmCeFa3FbFAXprt918bQlsDDy9zdC+IiIhcFgMvVYlMKsHsQS0BoFzoNdx/oHldeCpkOHIlG89+fQCxC//CxsNXzB/IJpUB3SaJt5MWi8uC2Uphlngyh4RpgF4LNOkDyCws8yVXiqdddjZcnoyIiKjaWMNLVRbbOgxLHr8bc38+jtTsW7W6oWXW4b2RX4wVfyfjy90XcDo9D1PWHsaCrWcwsVdjDOkQAY+yKz20Hw1s/x+QdVE8+UKrITXv5NXDwPdjgZsXAKkCiHlHPMNb9mXjn/21JSXYtWsX7rnnHijkpb8K6iDWwBIREbkZBl6qltjWYejbMrTCM60Fenng5ZhmmNCzEb5OuoAv/k5GckY+Xv3xPyzcdgbP9WqE4Z0ioVLIAA810Plp4K/3xdMNtxwMSKw4Y5s5ggDs/wJImA7oigG/+sDwVUC9juLj/pG3Aq1Wi2z1FSCsHaCo4amCnQaXLyMiIrodSxqo2mRSCbo1DsLg9hHo1jjI7GmF/TwViLu/Kf5+7X68MaAF6vgocSWrEDM3HsO972/H8r/OI19TAnSZIJYbXDkApOypXoc0ucAPT4rLeOmKgWYDgOf+uhV27wSJc4ACK5aEIyIiuoMw8FKt8FLKMaFnI+x89T68NbgVIvw9cT1Xg3c2n0CP9/7A4r3ZKG79qNh49yIAgE4vIOlcJjYevoKkc5mVn8wi7SiwrDdw7CdAKgf6vV16AocA+785Z5K8A/i/bsDZrY7uCRERkdNgSQPVKpVChie6RWFE5/rYcOgK/m/HWVzILMCHW05ji/JubJJ8DeHUZuxM2o3XdhSa1AiHlakRNhIE4OBXwG+viidp8I0QSxgiu9T+m7MndZB44FqJpuI2Mg/x/d9MBr4ZBnSeAPR9UywZISIiuoMx8JJDeMileLRzJB6+OwK/HknFp9vP4r90IFFxN/rKDiLl1w+RWvKUyXPSsosw8ZuDWPL43WLoLc4HfokH/lsrNmjSFxj6GeDlhKss1JR/pHhSicrW2VUHiZetc8QTVuxbDpzfLi5pFnEHlXUQERHdhoGXHEouk2Jw+wgMahuOLcfTkfj7cPTNPYhHZH9hfslw3ICvsa0AcemzuT8fR9/gm5D9MA7IOAVIZMD9M4B7poona3BXZQ+4q8yA94FmscCG54HMs8DnfYFerwH3vgTI+CtPRER3HjdOB+RKpFIJYluHYujg4TisbwSVRIsnZInl2gkAuuduAZbfL4Zd71Bg7M/AvfHuHXarqvH9wMTdQKuHAUEH7PgfsCIGyDjr6J4RERHVOiYEcirX8orxQ0kvAMB4+W/oIDmNVpJktJIk427JKSyTf4SPPJZCpivEed8u2N1vIwrDuzq4105KHQgMXwkM+wJQ+gFX9gOf3Qvs+0KsfSYiIrpD8O+b5FTqSTMRo/gGAOAvKcB65ZxybQQBWF4yAO9eewz61efgIU9Gl6hA3Ns0GD3vqoPmoT6QWFjHV6cX8E/yDRzIkCAo+Qa6Nalrdlk1t9DmEaB+V2DDRCD5L+DXeODUb8DgxYBPqKN7R0REZHcMvORU2gfpIJNoK20jkQDN+j6J4Rkh+OvMdaRmF+Hvsxn4+2wG5v12EnV8lLi3STDuvSsYPZrUQR0f09PyJhxNLXOWOBm+OrPf/AoQ7sSvHvDERuCfpeJBbWcTxeXLBi0EWj7k6N4RERHZFQMvORWZlWdY63VXHfTq3RaCIODc9XzsPHMdO89kIOlcJq7navDToSv46dAVAEDLMF/ce1cwejatg8w8DaasPVzufGTlVoBwR1Ip0O15oPF9wE8TgLQjwHdPAO0eA/q/CxTlWF4FgqddJiIiF8TASy5NIpGgSV1vNKnrjfH3NISmRIcDF29i55kM7DxzHUev5OB4qnj57M/zFe7HZAWIlqHuW94AAHVbAE//AeyYB+xaAPy7Gji/Ayi4DugqmV2XK8Wl0Rh6qTZkXbr1BaykBH4FF4DUfwF56X9b/AJGRFXAwEtuRSmXoXvjYHRvHIzXYpsjI0+DXWcz8NfpDGw7kY6swooDnQAgNbsIPxy4hIfaRcDTQ1btfuj0AvYm38C13CLU9VGhS8NA5wrRcg+gz2zgrhhg/bPAzQuWn1OiEQMIQwbZW9YlYHFH44lWFAB6A8CpMm34BYyIqoCBl9xasLcSg9tHYHD7CGw8dAVT1h22+JzXfjyC1348gjA/FaKCvBAV7IWGwWo0DPZGw2A1IgPVUMorDsOmNcIip60Rrt8VeO5vMfSe/NXRvSFbKztLao6zzpIWZFZ+VkGAX8CIqEoYeOmOUddXZVU7Lw8Z8ot1SM0uQmp2EZLOmwYGqQSICPBEVJAXGgaLl6hgLzQM8sKxq9mIW33ItWqElT5Az1ftG3jtHbzs+edvVw2Nt82SmlXTWVJX/WyI6I7DwEt3jC4NAxHmp0JadlG5QAqINbyhfir8/dr9yCnUIjkzHxcy8pFcermQmY/k6/nIL9bh0o1CXLpRiJ1nMqx6bVvWCDu0XOKbYUBoG6BOc6BOs1vX6sCKn2Pv4GXPP3/XRmi0F3vPktrzsynOq3p/qoJBneiOw8BLzkUdJP4naek/UXVQlXctk0owe1BLTPzmICSASeg1xMXZg1pCJpUgwMsDAV4euLt+gMk+BEHA9TwNkq+XBuCMAiRn5OFCRgHOX8+DVl/xCR0MNcKjP9+DzlGBaFTHq7RMwgt+ngqr3oPDyyUKMoDz28VLWd4hpgG4TgvxtleQ/YOXPfdfG39ad9XwVZPPpjALyEoRL9mXbt3OuiheF2Vb14ctM4AG3YG6LcVLYCPLp8925S8x5Diu+ntaG1zkAFMGXnIu/pHifzR2+ocltnUYljx+d7nQGGplaJRIJKjro0JdHxWiG5mG7g2HrmCqFTXCe87fwJ7zN0y2BXt7GMsjGtURQ3CjYC/UD7pVL5xwNBUTvzno2HKJwUvEUxVfP1l6OSUGlrx08ZL8l2l7dTDgW8+6fQsCoNcBgr70THDCbbdL75vchvXhyBnZMnwJApCfAdw4B2SeA1KSrOvDD0+JJyBR+VV88fQ3ve/hY/VbxJHvgX/Xlgm1KYDGRmN2Yad4MZB5AMHNgJCW4mokdUuv/SLFBbwB168PZvCqffySVDEXOsCUgZecj3+kXX8xYluHoW/LUCSdvYYtO/9Bv3ujbXKmtRAra4Qfj64PnQCcv56H5Ix8XMvVICOvGBl5xdh34aZJW6kEqBegRlSQGvsv3jRbilGrS6qFtATC25tu0+QCGaeBa2VC8PWT4mxdQYZ4scby3rburallvcRAJJUDUoU4E2jptqVgZJD6H6DwFAO+pz8gtXKFj6qGL2OoPX8r2Bpu30gGNDnWvW5ZN86KlyqRAB5e1jVNWmx+uzoY8K9/26WBeF10E1gRa3nf3eKAoizg2gnx50+bD6QfES9lefiUBuAWYmB3Va4evFxkJrAcV/+SZE8u9Nkw8NIdSSaVILphIDJPCIi2UQ2stTXCcwe3Nnm9PE0JLmTk41xpAE7OyMf56+J1nqYEKTcKkHKjoNLXNpRLvLjuMNpF+qOOjxLB3h6o461EsLcS/mpF5adbVgdBJ/WATF9cYROd1AMyc6UkSh8goqN4Kas4XwzCZxKB7e9U2v9aoysWL7b28+RbtyVSwDNA/M9bHSzWN3sFl7kfJJZ6qIOAvGvW7X/rHKDwphhuKw21EvGseoGNxGB3YpPlfff/QOxPUbZ1l5IiAIL1dbaN7gPC2oqzrIZA6x9ZeWC+eti6fbcZfusLmF4PZKcA6ceBa8dLQ/AJ8WewOBe4vFe8uDJXLrGpjZlAV579tmffXflzsSEGXiIbqUqNcFneSjlaR/ihdYTpzFPZeuGfDl3Bun2XLPZh079Xsenfq+W2K2QSBHkpEexzKwQH+yjF2z5KBKpVmCdZCGhumNmr2H+5TzB+9K0Hq1cn9vACwjuIz7Ym8I7ZCIS2LX1BiRgcIan8NiTiGeOsmR1+fD1Q5y7x5Bp6HaDXlt4uES/G21pAV7ot84wYNi3xrSeGqqJssdSiILP0P5jTlp9rDZOaaUOobQgENgaCGosBN7AxEBAFKEr/0nD1sHWBN7JL+Vn7ymiLxNCd8g/w3eOW2/eZU7X9A9Wr5ZdKxfcfEAU0H3Bre0mxOANuCMEXk4CLf1vuw875QNM+QFg7sSZd7mF9/101YNhzBtkVD6IsygZuXixfqlWRKwfFL7u+EZZrycuy5+duj33rdUBuqrjvC1b8LjkJBl4iG6ppjXBZZeuF9QKsCrwxrUIgl0mRkatBRp4G13M1yCkqgVYnIC2nCGk5RZU826/0UoEc4OPEU+jWOFgMzN4eCFB7QGqrEgqVf+WrPVTEytNRQx0oBsWquHoYwBzL7UZ+K4Y6nRYouFEaeDPE6/yMWwG47O2CTCDvOiCUWN5/9ESg4b3lQ60jKFTixZ6B7bZafm1JCXbt2oV77rkHiqr++VvucaucARDHdFkvy887sVG8AGIpTN2WYvgNby9e121lfhxsFTB0JeKMdcZZIPOs+OXryiHL/QaAVQPFGXXf8NsuEYBPmHjbM6D8744L/Xm6nOr0XVso1pTfvFh6wOTFW7dvXhTLZari1xfFa6lc/PwDG976EhYQBQSU3lf51rzv1qrOvosLgOzL4vEZ2ZfEn2nD/axLQM4V8VgOF8PAS2RjhhphWy4dZm25xP+N7ljudTQlOmTmFeN6mRCckSfWDV/P1eB6ngYXSmuJLVm8/RwWbz9nvC+TShDo5WEMwHW8lQjyNtwXZ4/DC3LR1Ir3qBME62ePnZVMAfiEiBdrXD0ELOttuV27kbUzS+pMytbya7XIVl8Rg6bCuhVNaqztSHEWK/WwONOXeli8HPxSfFwqF2d+w9rdCsIhraoWMPzqideZZ4GMM2KozTwn3r6ZXP3ym+I84PoJ8VIRuap8CBYqXmXGRF4acP20WN5iuGgNtzVASaF4rS28dT/L8hd2AMCe/xNLX+RKsS5erhIvChUg96x4e5GV9et/vCW2zbooHmhriTpYvGSctNzWL1Lcp65YHL+byebbeQaahmGJE/zLt2WG+HOTdcm64y6kcvFnxzMQSLXyi5iDMfAS2YFMKkG3xrYLEtUtlwDE0y2H+3si3N+zwv0nncvEqOV7LPajRZgPtDoBGXkaZBVoodMLYmiuJCyHIwN/KBVQSSo+rXORoMDHf2UgrH4yvFUKeCvl8FHJ4a2Uw1slh0/ptadCVr4WuSb1x5bYPTTa8QDDMrOkOkHAsSs5uFFQjEC1B1pF+EImkdTsT+uuHqgt6TpRDLGCIIaj1H/F2eHUf8XgW5B56wC5w9+Iz5FIAb/61u1//XNioK5sFlGuulW2EtxUnGneMc/yvod/Kc4i5lwFclLFGbmcq0DuVfG6IFMMpzfOi5eqWj2i6s+x1n/r7LdvADi71fS+hw8Q0EAM2bdf+9cHlN7W/1VgxDdiWVZuamngvXDrcqP0fkEGUHgDuHIDuHKgan1f+5j4pVqvF2dY9boy13rxYrJNd2s1G0vKrnYCiJ+Lf6T4pcyv9MunX+St294h4sG51n42ToCBl8hF2LJc4nbWziD/MvleY6jW6vTIzCsunS02rDShMZZTGO5fuSnD/ZqPECDJrfD1bwo+uPpvMfDv8Ur7KZUAXspbAdhbKYeXUo7L2vlQl1S81JXMOwjfe4VDac2HUZZ/JHb0+w0frk8q97kYourLA7qht7P9edfAPxIJl+W3/cwUI8yvRPyZCa/BMnZ2XkLQbqoa1CWSWzNxLQeL2wRBDJEmIfhfceYz64J1/TDOvkrEEGEItUFNxEtwU7E2XCq99Zyrh60LvAFRlf9FQFskhrKcq6XXpYE4/ThwwYp6VVnpLKuidMbVMNtqnHFVlW4vMyNblA38u8byvts8Kh5wWVJYZta46LbbZWaOtUXitbXBLvo5oH63W6HWXGlHTUilgF+EeInqUf5xTa5YLlE2EKf+Z90BlTlXbNfP23V/QfxcDCFX5W/bz8UJMPASuRB7lEsA1ZtBVsikCPVTIdSv8npSw+zxVSG40nb33VUHaqUceZoS8VIkXucWaZGnKYFeAPQCkFtUgtyiEsAk3waWXiqQCzSbmQB/tQKBXh4I8vJAkJcSgd7i7cDSS7C30vh4gJcHpBIJpm/LQqrQ0OxuJQCmb8vC352Eao2BzjMQJVBAiYpnvzVQQO4ZWK1yD7uv3VxadmDPs//p9AL+Sb6BAxkSBCXfqPkSgraY+ZaUHjjoVw9oPvDW9tw04Nh6IGGa5X70mQs06SMGXUXFf32xC4Wq9KDH236urZ2te2pL1Utsrh62LvB2m1T1fQPA5f3A5w9YbtdulGPLg5Q+QGhr8WJg7ec+aBFQt7lYAiGVin9RkMjEmVbjtfTWtUQmLhH59RDL+249rHqfuwv9pYeBl8jF2LpcwsBeM8jWzh5/Pq5zhUFGEAQUanXIKypBrqYE+aWBOFdTgr9OX8e3/6RY1ZesAi2yCrQ4fz3fqvZeHjLkF1d8cEbZs+f5qhQo0QvQ6vTQ6vQo0QnQ6gWUmNzXQ1sioESvh1YnQKPVIbDE8ux34NcXEe5/zTijrVbK4O0h3jZs81LKjLe9lXKoFDLM2XTM7ms32/Psf6b7luGrM/tts297zXz7hIqzZNZo1Ns09FjDhcJFrZPaMc44y18zwtpWPZRaU6dcE7Y8wNTOGHiJyMgeM8g1qT82tpNIoPaQQ+0hR93bHvNVKawKvJ89fjca1vFGZl4xbuQX40a+WHYh3hbLLwy3bxYUQy+g0rBb1u1nzquKqwi2OPt99WoOjl6txkklKmEI66+vP4K29fzg56mAv6cH/NUK+Hkq4KdWwEcpr3T9ZnvOILvqvu3K3nXZ9uTqYd3OJ0RyaWX+0vPP2Wv4o6Ah5EWRNjmhky0x8BKRCXvMIDtD/XEfw0ymFQso6PQCsgqKsf3kNbz8w38W24/t1gBNQ3ygkEmgkEkhl0mhkBpul15LJVDIpVBIb207eiULU9f9a3H/k+5rjDA/T+QbZrc1OvG6uMRkW0Gx4XYJirTW1TSu23epwiXvZFKJGH5LL4Yw7O+pgI+nAl/uvlDhDDIAvLH+KPw9PSCR3NpmWAhAgGDcWPYxAQL0egGv/3S00n3P2HAU9QO9oFTc+kzlMonJ5yuXSiCTSkxCu04vYO7Pxx1/1sLqsmddtj1DaWlY333kFD776zwy8m4dZBrs7YFnezZC9zbNnP4gSruU77j0gbciu/01xoYYeImoVjhT/bE1+wzyVmLo3fXwUeJpi2F61qBW1XofDYO98F7CKYv7j+/brMr7//vMdTz+heUDYXrdFQwPuQzZBVpkF2qRVViMrAItNCV66PSCcda7OjLzizHSitU/qiMjrxgDPtlpuSHEE6/IS4MwINaBV6RsmUqEvxpKhRQquQxKhRRKuRQqhQxKuRRKucz0vkK87VkgR1NXrcu280GaCZflmPirBgIiTPedC/z1qwZLAuSI9a/WrmvlAFN7le/ofOthmHwRtLnmlwOr1ol/DGrpc3GFv5gw8BJRrXG1+mN7hOna2n+3xsFWzXyvGNfF7P6LtDoxABuCcEExsgq1yCnddvhSFv4+a3m9zro+Snir5JAAxplWw6tJJICk9F7ZyomcohJczSq0uG9vpQxSiQQlesFYI21uKVmtToBWp0MlGbQcsUyleqUq4bBcl639v1Pw90w2BmaVQgaVQgqlQgaVXLx9+2Mecik+TjxT6cz36z8dMU5V6/RAiV4PvSBApwf0egE6QUCJXpxF1+mF0seE0s9Qj+U7M5BXwUGaADDlt0y8Ib0ET4UMHnKpMfwbbqsUUnjIbn1B8Ch9HIBdZ9Z1esGuB5hWJ9QZjj24WSD+/mQXaJFV+vtzs6DY+Ht1/no+Duf4APCpuAM5wPAlu1EvUG1cocZQs+9jqN1XyeGtlBnr+A21/Lb6XARBgF4QV+gx/MxotDrM2mj/YwVsQSII1q40fefIycmBn58fsrOz4esrnhFFq9Vi8+bNGDBgABS1tfA52RXH1P3o9AKSzl7Dlp3/oN+90TarIbPngVn23L/hP2nAfJiuycyLtWs3r5nQtcpfcmqyb13pgYMlxgMGxYMES3Ti9gMXb+IVK8tUwvw9odHqoSnRoaj0WlOiR5FWvDa5XXp9M1/8YkCmpBJxlRVLIgM8ofaQm10Ry9wXJsN1nqYEFzIKLO6/c1QA6vqqoJBKxNKjMrP/ijL3FTLxcUNZzMeJp5FTyV8GPBUy3NMkCDmFJbhZ+uUwu0CLYp2Vy6U5WJivCgq5tDTIir8vJaVfisoG3Oqqzr8D1jCX1yrCGV4ichsyqQTRDQOReUJAtA2XxrJXOYa99+8MtdNdGlb9dNE12bdMKoFMWvEffhsEeWG+HctUrA3rbw5uhSZ1vaHRiqG5qERX5nbptdYQqMXHzmfk4fClitebvvUe1ajjrYRUKoFMItY2SyVicBOvDZ+TFDIJjO0u3yxAkhUHYLYI9YGfWoHi0tCvKdGX3taVuS2GJANrs9Klm5Zn9mti34WbdtlvoVaHrSeumX1MIZPAz9MDAWpDHbx4cKh/aV38jfxirNh1weJrTLi3IUJ8VcjT3KrVN9bzly7jmF9867amxPqwnVrpaedr7lquffdvDQZeIiIr2Kscw977d6XaaVffN2B9WB8d3aDKr2FtmH734bbV+llKOpeJpPOW9z9rUCur9l+i06NYp4dGq0fS+Uw8/+1Bi8+ZMaAFWoSLM3Vl//4slH6atw56LL0u3XAiNQfvJZyyuP8n74lC/UB16RKCt5YN1Jr5i0Bx6XKCKTfyrfqi8Wineuh1V10xzKoV8Fd7wN9TAbWHmTNElqHTC/jtaJrFn5lp/VtU6WdGq9Njx6lrmPCV5TO6zR7UEu0i/Y0z2gqZFDKpxOL9fck38Njn/1jcf12fytdrrw0MvEREbs7Vaqdded/2DNT2nFW3x/7lpSuWqD2AmFahVu17fI+G1fps7m1aB18lXbS4/zcGVv2zt/aLxtAO9ar1e2avnxmFTIr7m4dY9bmP6RZVrc89ulGQXX8mbYmBl4iIqs2e5R6GfdujLtve/eZBlO7Td3t/0QD4M1MbpJab2N+nn36KqKgoqFQqREdHY+/eypfS+f7779G8eXOoVCq0adMGmzdvNnlcEATMmjULYWFh8PT0RJ8+fXDmzBl7vgUiojuWYQZ5cPsIdGscZNP/3Ax12R2DbVuXbdi3vfod2zoMf792P9ZM6IqFI9tjzYSu+Pu1+2t8kKMhGN1+Su9QP5VNln+y5/5dte+GUAfcCnEGtgx1/JmxL4fP8K5btw7x8fFYunQpoqOjsWDBAsTExODUqVOoW/f2cyoBu3fvxqhRozBv3jw8+OCDWL16NYYMGYKDBw+idWvxNI3vv/8+PvnkE3z55Zdo2LAhZs6ciZiYGBw/fhwqlePrSIiIyP25Wl12bezfnrP2ZffvSgeAluXqPzP2GldbcPiyZNHR0ejcuTMWL14MANDr9YiMjMTkyZMxbdq0cu1HjBiB/Px8/PLLL8ZtXbt2Rfv27bF06VIIgoDw8HC89NJLePnllwEA2dnZCAkJwapVqzBy5EiLfeKyZHcGjql74ri6H46p+3HVMbXLmdbcSG2Pq8ssS1ZcXIwDBw5g+vTpxm1SqRR9+vRBUlKS2eckJSUhPj7eZFtMTAw2bNgAAEhOTkZaWhr69OljfNzPzw/R0dFISkoyG3g1Gg00mlun3cvJEc9Zr9VqodVqjbfLXpPr45i6J46r++GYuh9XHtNO9X0BiOFKryuBXufY/jiT2h7XqryOQwNvRkYGdDodQkJMT24fEhKCkydPmn1OWlqa2fZpaWnGxw3bKmpzu3nz5mHu3Lnltm/ZsgVqtdpkW2JiYiXviFwRx9Q9cVzdD8fU/XBM3VNtjWtBgeWTjRg4vIbXGUyfPt1k1jgnJweRkZHo16+fSUlDYmIi+vbt61J/fqGKcUzdE8fV/XBM3Q/H1D3V9rga/iJvDYcG3uDgYMhkMqSnp5tsT09PR2hoqNnnhIaGVtrecJ2eno6wsDCTNu3btze7T6VSCaVSWW67QqEoN2DmtpFr45i6J46r++GYuh+OqXuqrXGtyms4dFkyDw8PdOzYEdu2bTNu0+v12LZtG7p162b2Od26dTNpD4hT54b2DRs2RGhoqEmbnJwc/PPPPxXuk4iIiIjcl8NLGuLj4zF27Fh06tQJXbp0wYIFC5Cfn4/x48cDAMaMGYOIiAjMmzcPADBlyhT06tULH330EQYOHIi1a9di//79WLZsGQBAIpFg6tSpePvtt9G0aVPjsmTh4eEYMmSIo94mERERETmIwwPviBEjcP36dcyaNQtpaWlo3749EhISjAedpaSkQCq9NRHdvXt3rF69GjNmzMDrr7+Opk2bYsOGDcY1eAHg1VdfRX5+Pp555hlkZWWhR48eSEhI4Bq8RERERHcghwdeAIiLi0NcXJzZx3bs2FFu2/DhwzF8+PAK9yeRSPDmm2/izTfftFUXiYiIiMhFOcWphYmIiIiI7IWBl4iIiIjcGgMvEREREbk1Bl4iIiIicmsMvERERETk1hh4iYiIiMitOcWyZM5GEAQApudo1mq1KCgoQE5ODk+D6CY4pu6J4+p+OKbuh2Pqnmp7XA05zZDbKsPAa0Zubi4AIDIy0sE9ISIiIqLK5Obmws/Pr9I2EsGaWHyH0ev1uHr1Knx8fCCRSACI3yIiIyNx6dIl+Pr6OriHZAscU/fEcXU/HFP3wzF1T7U9roIgIDc3F+Hh4SZn5TWHM7xmSKVS1KtXz+xjvr6+/OV0MxxT98RxdT8cU/fDMXVPtTmulmZ2DXjQGhERERG5NQZeIiIiInJrDLxWUiqVmD17NpRKpaO7QjbCMXVPHFf3wzF1PxxT9+TM48qD1oiIiIjIrXGGl4iIiIjcGgMvEREREbk1Bl4iIiIicmsMvERERETk1hh4rfDpp58iKioKKpUK0dHR2Lt3r6O7RDUwZ84cSCQSk0vz5s0d3S2qgr/++guDBg1CeHg4JBIJNmzYYPK4IAiYNWsWwsLC4OnpiT59+uDMmTOO6SxZzdK4jhs3rtzvbmxsrGM6S1aZN28eOnfuDB8fH9StWxdDhgzBqVOnTNoUFRVh0qRJCAoKgre3N4YNG4b09HQH9ZgssWZMe/fuXe539bnnnnNQj0UMvBasW7cO8fHxmD17Ng4ePIh27dohJiYG165dc3TXqAZatWqF1NRU4+Xvv/92dJeoCvLz89GuXTt8+umnZh9///338cknn2Dp0qX4559/4OXlhZiYGBQVFdVyT6kqLI0rAMTGxpr87q5Zs6YWe0hV9eeff2LSpEnYs2cPEhMTodVq0a9fP+Tn5xvbvPjii/j555/x/fff488//8TVq1fx8MMPO7DXVBlrxhQAJkyYYPK7+v777zuox6UEqlSXLl2ESZMmGe/rdDohPDxcmDdvngN7RTUxe/ZsoV27do7uBtkIAGH9+vXG+3q9XggNDRU++OAD47asrCxBqVQKa9ascUAPqTpuH1dBEISxY8cKgwcPdkh/yDauXbsmABD+/PNPQRDE302FQiF8//33xjYnTpwQAAhJSUmO6iZVwe1jKgiC0KtXL2HKlCmO65QZnOGtRHFxMQ4cOIA+ffoYt0mlUvTp0wdJSUkO7BnV1JkzZxAeHo5GjRph9OjRSElJcXSXyEaSk5ORlpZm8nvr5+eH6Oho/t66gR07dqBu3bpo1qwZJk6ciMzMTEd3iaogOzsbABAYGAgAOHDgALRarcnva/PmzVG/fn3+vrqI28fU4Ntvv0VwcDBat26N6dOno6CgwBHdM5I79NWdXEZGBnQ6HUJCQky2h4SE4OTJkw7qFdVUdHQ0Vq1ahWbNmiE1NRVz587Fvffei6NHj8LHx8fR3aMaSktLAwCzv7eGx8g1xcbG4uGHH0bDhg1x7tw5vP766+jfvz+SkpIgk8kc3T2yQK/XY+rUqbjnnnvQunVrAOLvq4eHB/z9/U3a8vfVNZgbUwB47LHH0KBBA4SHh+O///7Da6+9hlOnTuGnn35yWF8ZeOmO079/f+Pttm3bIjo6Gg0aNMB3332Hp556yoE9I6LKjBw50ni7TZs2aNu2LRo3bowdO3bggQcecGDPyBqTJk3C0aNHecyEG6loTJ955hnj7TZt2iAsLAwPPPAAzp07h8aNG9d2NwHwoLVKBQcHQyaTlTtaND09HaGhoQ7qFdmav78/7rrrLpw9e9bRXSEbMPxu8vfW/TVq1AjBwcH83XUBcXFx+OWXX7B9+3bUq1fPuD00NBTFxcXIysoyac/fV+dX0ZiaEx0dDQAO/V1l4K2Eh4cHOnbsiG3bthm36fV6bNu2Dd26dXNgz8iW8vLycO7cOYSFhTm6K2QDDRs2RGhoqMnvbU5ODv755x/+3rqZy5cvIzMzk7+7TkwQBMTFxWH9+vX4448/0LBhQ5PHO3bsCIVCYfL7eurUKaSkpPD31UlZGlNzDh8+DAAO/V1lSYMF8fHxGDt2LDp16oQuXbpgwYIFyM/Px/jx4x3dNaqml19+GYMGDUKDBg1w9epVzJ49GzKZDKNGjXJ018hKeXl5JjMFycnJOHz4MAIDA1G/fn1MnToVb7/9Npo2bYqGDRti5syZCA8Px5AhQxzXabKosnENDAzE3LlzMWzYMISGhuLcuXN49dVX0aRJE8TExDiw11SZSZMmYfXq1di4cSN8fHyMdbl+fn7w9PSEn58fnnrqKcTHxyMwMBC+vr6YPHkyunXrhq5duzq492SOpTE9d+4cVq9ejQEDBiAoKAj//fcfXnzxRfTs2RNt27Z1XMcdvUyEK1i0aJFQv359wcPDQ+jSpYuwZ88eR3eJamDEiBFCWFiY4OHhIURERAgjRowQzp496+huURVs375dAFDuMnbsWEEQxKXJZs6cKYSEhAhKpVJ44IEHhFOnTjm202RRZeNaUFAg9OvXT6hTp46gUCiEBg0aCBMmTBDS0tIc3W2qhLnxBCCsXLnS2KawsFB4/vnnhYCAAEGtVgtDhw4VUlNTHddpqpSlMU1JSRF69uwpBAYGCkqlUmjSpInwyiuvCNnZ2Q7tt0QQBKE2AzYRERERUW1iDS8RERERuTUGXiIiIiJyawy8REREROTWGHiJiIiIyK0x8BIRERGRW2PgJSIiIiK3xsBLRERERG6NgZeIiIiI3BoDLxERmZBIJNiwYYOju0FEZDMMvERETmTcuHGQSCTlLrGxsY7uGhGRy5I7ugNERGQqNjYWK1euNNmmVCod1BsiItfHGV4iIiejVCoRGhpqcgkICAAglhssWbIE/fv3h6enJxo1aoQffvjB5PlHjhzB/fffD09PTwQFBeGZZ55BXl6eSZsVK1agVatWUCqVCAsLQ1xcnMnjGRkZGDp0KNRqNZo2bYpNmzYZH7t58yZGjx6NOnXqwNPTE02bNi0X0ImInAkDLxGRi5k5cyaGDRuGf//9F6NHj8bIkSNx4sQJAEB+fj5iYmIQEBCAffv24fvvv8fWrVtNAu2SJUswadIkPPPMMzhy5Ag2bdqEJk2amLzG3Llz8eijj+K///7DgAEDMHr0aNy4ccP4+sePH8dvv/2GEydOYMmSJQgODq69D4CIqIokgiAIju4EERGJxo0bh2+++QYqlcpk++uvv47XX38dEokEzz33HJYsWWJ8rGvXrrj77rvxf//3f1i+fDlee+01XLp0CV5eXgCAzZs3Y9CgQbh69SpCQkIQERGB8ePH4+233zbbB4lEghkzZuCtt94CIIZob29v/Pbbb4iNjcVDDz2E4OBgrFixwk6fAhGRbbGGl4jIydx3330mgRYAAgMDjbe7detm8li3bt1w+PBhAMCJEyfQrl07Y9gFgHvuuQd6vR6nTp2CRCLB1atX8cADD1Tah7Zt2xpve3l5wdfXF9euXQMATJw4EcOGDcPBgwfRr18/DBkyBN27d6/WeyUiqg0MvERETsbLy6tciYGteHp6WtVOoVCY3JdIJNDr9QCA/v374+LFi9i8eTMSExPxwAMPYNKkSfjwww9t3l8iIltgDS8RkYvZs2dPufstWrQAALRo0QL//vsv8vPzjY/v2rULUqkUzZo1g4+PD6KiorBt27Ya9aFOnToYO3YsvvnmGyxYsADLli2r0f6IiOyJM7xERE5Go9EgLS3NZJtcLjceGPb999+jU6dO6NGjB7799lvs3bsXX3zxBQBg9OjRmD17NsaOHYs5c+bg+vXrmDx5Mp544gmEhIQAAObMmYPnnnsOdevWRf/+/ZGbm4tdu3Zh8uTJVvVv1qxZ6NixI1q1agWNRoNffvnFGLiJiJwRAy8RkZNJSEhAWFiYybZmzZrh5MmTAMQVFNauXYvnn38eYWFhWLNmDVq2bAkAUKvV+P333zFlyhR07twZarUaw4YNw/z58437Gjt2LIqKivDxxx/j5ZdfRnBwMB555BGr++fh4YHp06fjwoUL8PT0xL333ou1a9fa4J0TEdkHV2kgInIhEokE69evx5AhQxzdFSIil8EaXiIiIiJyawy8REREROTWWMNLRORCWIVGRFR1nOElIiIiIrfGwEtEREREbo2Bl4iIiIjcGgMvEREREbk1Bl4iIiIicmsMvERERETk1hh4iYiIiMitMfASERERkVv7f87tTwHN5CTVAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGiHpYYikrqv",
        "outputId": "2c127eca-499c-453c-bbb2-5e8225cfd3db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-c3455c24d392>:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_load_path, map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully.\n",
            "\n",
            "Evaluating with external test dataset...\n",
            "\n",
            "Test Loss: 0.0050, Accuracy: 0.9835, Precision: 0.9936, Recall: 0.9932, F1-score: 0.9934\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   overdrive       1.00      0.99      1.00      3028\n",
            "  distortion       1.00      0.99      1.00      4544\n",
            "        fuzz       1.00      1.00      1.00      5300\n",
            "     tremolo       1.00      1.00      1.00      4542\n",
            "      phaser       1.00      1.00      1.00      4542\n",
            "     flanger       1.00      0.99      0.99      3028\n",
            "      chorus       1.00      1.00      1.00      5300\n",
            "       delay       0.99      1.00      0.99      8328\n",
            " hall_reverb       0.97      0.98      0.98      3788\n",
            "plate_reverb       0.98      0.99      0.99      3028\n",
            "     octaver       0.99      0.99      0.99      2271\n",
            " auto_filter       1.00      0.99      1.00      3785\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     51484\n",
            "   macro avg       0.99      0.99      0.99     51484\n",
            "weighted avg       0.99      0.99      0.99     51484\n",
            " samples avg       0.97      0.97      0.97     51484\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load test dataset\n",
        "h5_test_path = \"/content/final_datasets/test_extra_TRM_DLY.h5\"\n",
        "csv_test_path = \"/content/final_datasets/test_extra_TRM_DLY.csv\"\n",
        "\n",
        "model_load_path = \"/content/drive/MyDrive/Capstone 210/Models/final_multi_effects_alt9.mod\"\n",
        "\n",
        "test_dataset = SpectrogramDataset(h5_test_path, csv_test_path)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=12, pin_memory=True)\n",
        "\n",
        "num_classes = len(test_dataset.label_map)\n",
        "\n",
        "# Load a saved model for test dataset metrics\n",
        "model = spectrogramCNN(num_classes).to(device)\n",
        "model.load_state_dict(torch.load(model_load_path, map_location=device))\n",
        "model.eval()\n",
        "print(\"Model loaded successfully.\")\n",
        "\n",
        "print(\"\\nEvaluating with external test dataset...\")\n",
        "\n",
        "model.eval()\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "test_loss = 0.0\n",
        "test_preds, test_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for spectrograms, labels in test_loader:\n",
        "        spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "        outputs = model(spectrograms)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # Convert logits to binary predictions\n",
        "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "\n",
        "        test_preds.extend(predicted.cpu().numpy())\n",
        "        test_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "test_loss /= len(test_loader)\n",
        "\n",
        "# Compute test metrics\n",
        "test_preds = np.array(test_preds)\n",
        "test_labels = np.array(test_labels)\n",
        "test_accuracy = accuracy_score(test_labels, test_preds)\n",
        "test_precision = precision_score(test_labels, test_preds, average=\"macro\", zero_division=0)\n",
        "test_recall = recall_score(test_labels, test_preds, average=\"macro\", zero_division=0)\n",
        "test_f1 = f1_score(test_labels, test_preds, average=\"macro\", zero_division=0)\n",
        "\n",
        "print(f\"\\nTest Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1-score: {test_f1:.4f}\\n\")\n",
        "\n",
        "# Print classification report\n",
        "class_names = test_dataset.label_map\n",
        "print(classification_report(test_labels, test_preds, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4M37nJkp9Vq1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "885601f4-bc87-41f3-f88e-ec9f7ed7ff88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-5-a87bdd7aeb2c>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_load_path, map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully.\n",
            "\n",
            "Evaluating with external test dataset...\n",
            "\n",
            "Test Loss: 0.0951, Accuracy: 0.7859, Precision: 0.9025, Recall: 0.9216, F1-score: 0.9048\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   overdrive       0.84      0.79      0.81      3432\n",
            "  distortion       0.99      0.97      0.98      5148\n",
            "        fuzz       0.99      0.96      0.97      6006\n",
            "     tremolo       0.87      0.99      0.92      4290\n",
            "      phaser       0.99      0.96      0.98      5148\n",
            "     flanger       0.99      0.73      0.84      3432\n",
            "      chorus       0.95      0.95      0.95      6006\n",
            "       delay       0.93      0.93      0.93      7722\n",
            " hall_reverb       0.89      0.98      0.93      5148\n",
            "plate_reverb       0.96      0.87      0.91      3432\n",
            "     octaver       0.57      0.99      0.73      2574\n",
            " auto_filter       0.87      0.94      0.90      4290\n",
            "\n",
            "   micro avg       0.91      0.93      0.92     56628\n",
            "   macro avg       0.90      0.92      0.90     56628\n",
            "weighted avg       0.92      0.93      0.92     56628\n",
            " samples avg       0.87      0.89      0.87     56628\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load test dataset\n",
        "# h5_test_path = \"/content/drive/MyDrive/Capstone 210/Data/Final Datasets/final_real.h5\"\n",
        "# csv_test_path = \"/content/drive/MyDrive/Capstone 210/Data/Final Datasets/final_real.csv\"\n",
        "\n",
        "h5_test_path = \"/content/final_datasets/final_real.h5\"\n",
        "csv_test_path = \"/content/final_datasets/final_real.csv\"\n",
        "\n",
        "model_load_path = \"/content/drive/MyDrive/Capstone 210/Models/final_multi_effects_alt9.mod\"\n",
        "\n",
        "test_dataset = SpectrogramDataset(h5_test_path, csv_test_path)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=12, pin_memory=True)\n",
        "\n",
        "num_classes = len(test_dataset.label_map)\n",
        "\n",
        "# Load a saved model for test dataset metrics\n",
        "model = spectrogramCNN(num_classes).to(device)\n",
        "model.load_state_dict(torch.load(model_load_path, map_location=device))\n",
        "model.eval()\n",
        "print(\"Model loaded successfully.\")\n",
        "\n",
        "print(\"\\nEvaluating with external test dataset...\")\n",
        "\n",
        "model.eval()\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "test_loss = 0.0\n",
        "test_preds, test_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for spectrograms, labels in test_loader:\n",
        "        spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "        outputs = model(spectrograms)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # Convert logits to binary predictions\n",
        "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "\n",
        "        test_preds.extend(predicted.cpu().numpy())\n",
        "        test_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "test_loss /= len(test_loader)\n",
        "\n",
        "# Compute test metrics\n",
        "test_preds = np.array(test_preds)\n",
        "test_labels = np.array(test_labels)\n",
        "test_accuracy = accuracy_score(test_labels, test_preds)\n",
        "test_precision = precision_score(test_labels, test_preds, average=\"macro\", zero_division=0)\n",
        "test_recall = recall_score(test_labels, test_preds, average=\"macro\", zero_division=0)\n",
        "test_f1 = f1_score(test_labels, test_preds, average=\"macro\", zero_division=0)\n",
        "\n",
        "print(f\"\\nTest Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1-score: {test_f1:.4f}\\n\")\n",
        "\n",
        "# Print classification report\n",
        "class_names = test_dataset.label_map\n",
        "print(classification_report(test_labels, test_preds, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "v-liaT6r8uXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B-QKEy3qc2hc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}