{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gbdionne/toneclone/blob/main/SpectrogramDatasetBuilder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_r1aZ2bIVCE3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import wave\n",
        "import h5py\n",
        "import scipy.signal\n",
        "from scipy import stats\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "class SpectrogramDatasetBuilder:\n",
        "    DSP_FEATURES = [\n",
        "        'modulation_freq', 'modulation_strength',\n",
        "        'spectral_centroid', 'spectral_flatness',\n",
        "        'freq_rolloff', 'spectral_bandwidth', 'zcr',\n",
        "        'crest_factor', 'flat_top_indicator',\n",
        "        'clipping_score'\n",
        "    ]\n",
        "\n",
        "    EFFECT_LABELS = {\n",
        "        \"ODV\": \"overdrive\", \"DST\": \"distortion\", \"FUZ\": \"fuzz\", \"TRM\": \"tremolo\",\n",
        "        \"PHZ\": \"phaser\", \"FLG\": \"flanger\", \"CHR\": \"chorus\", \"DLY\": \"delay\", \"HLL\": \"hall_reverb\",\n",
        "        \"PLT\": \"plate_reverb\", \"OCT\": \"octaver\", \"FLT\": \"auto_filter\"\n",
        "    }\n",
        "\n",
        "    def __init__(self, data_dir, output_dir, sample_length=10, overlap=5, sample_rate=32000, num_mels=128, n_fft=2048, hop_length=512):\n",
        "        self.data_dir = data_dir\n",
        "        self.output_dir = output_dir\n",
        "        self.sample_length = sample_length\n",
        "        self.overlap = overlap\n",
        "        self.sample_rate = sample_rate\n",
        "        self.num_mels = num_mels\n",
        "        self.n_fft = n_fft\n",
        "        self.hop_length = hop_length\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        self.label_file = os.path.join(output_dir, \"test.csv\")\n",
        "\n",
        "        if not os.path.exists(self.label_file):\n",
        "            columns = ['key'] + self.DSP_FEATURES + list(self.EFFECT_LABELS.values())\n",
        "            pd.DataFrame(columns=columns).to_csv(self.label_file, index=False)\n",
        "\n",
        "    def extract_effect_labels(self, filename):\n",
        "        labels = {name: 0 for name in self.EFFECT_LABELS.values()} # Initialize multi-hot row to all 0s\n",
        "        effects_found = []\n",
        "\n",
        "        for code, name in self.EFFECT_LABELS.items():\n",
        "            if code in filename:\n",
        "                effects_found.append(name)\n",
        "            elif 'CLN' in filename:\n",
        "                effects_found.append('clean')\n",
        "\n",
        "        if 'clean' in effects_found: # Example of clean guitar, no effects, return all 0 labels\n",
        "            return labels\n",
        "        elif effects_found:\n",
        "            for effect in effects_found:\n",
        "                if effect != 'clean':\n",
        "                    labels[effect] = 1\n",
        "            return labels\n",
        "        else: # No valid effects found\n",
        "            raise ValueError(f\"No valid effects found in filename: {filename}\")\n",
        "\n",
        "    def split_wav(self, file_path):\n",
        "        with wave.open(file_path, 'rb') as wav:\n",
        "            num_channels = wav.getnchannels()\n",
        "            sample_rate = wav.getframerate()\n",
        "            num_frames = wav.getnframes()\n",
        "\n",
        "            audio_data = np.frombuffer(wav.readframes(num_frames), dtype=np.int16)\n",
        "            if num_channels == 2:\n",
        "                audio_data = audio_data.reshape(-1, 2).mean(axis=1) # Convert stereo to mono if necessary\n",
        "\n",
        "            samples_per_segment = self.sample_rate * self.sample_length\n",
        "            overlap_samples = int(self.sample_rate * (self.overlap / 100))\n",
        "            step_size = samples_per_segment - overlap_samples\n",
        "\n",
        "            segments = []\n",
        "            start = 0\n",
        "            while start + samples_per_segment <= len(audio_data):\n",
        "                segment_data = audio_data[start:start + samples_per_segment]\n",
        "                segments.append(segment_data)\n",
        "                start += step_size\n",
        "\n",
        "            return segments, sample_rate\n",
        "\n",
        "    def extract_am_modulation_strength(self, y, sr):\n",
        "        \"\"\" Extracts dominant AM modulation frequency and its relative strength. \"\"\"\n",
        "\n",
        "        # Compute amplitude envelope\n",
        "        analytic_signal = scipy.signal.hilbert(y)\n",
        "        amplitude_envelope = np.abs(analytic_signal)\n",
        "\n",
        "        # Compute FFT of the amplitude envelope\n",
        "        fft_vals = np.abs(np.fft.rfft(amplitude_envelope))\n",
        "        fft_freqs = np.fft.rfftfreq(len(amplitude_envelope), 1 / sr)\n",
        "\n",
        "        # Focus on modulation frequencies between 4-20 Hz (common tremolo range)\n",
        "        mod_range = (fft_freqs >= 4) & (fft_freqs <= 20)\n",
        "\n",
        "        if np.any(mod_range):\n",
        "            # Find dominant modulation frequency\n",
        "            dominant_mod_freq = fft_freqs[mod_range][np.argmax(fft_vals[mod_range])]\n",
        "\n",
        "            # Energy at dominant frequency\n",
        "            dominant_energy = np.max(fft_vals[mod_range])\n",
        "\n",
        "            # Compute total modulation energy across all frequencies\n",
        "            total_mod_energy = np.sum(fft_vals)\n",
        "\n",
        "            # Normalize modulation strength (percentage of total modulation energy at dominant frequency)\n",
        "            mod_strength = dominant_energy / (total_mod_energy + 1e-8)  # Avoid division by zero\n",
        "        else:\n",
        "            dominant_mod_freq = 0  # No clear modulation detected\n",
        "            mod_strength = 0\n",
        "\n",
        "        return dominant_mod_freq, mod_strength\n",
        "\n",
        "    def extract_autocorrelation_delay_fft(self, y, sr, max_lag_ms=300):\n",
        "        \"\"\"Detects delay effects using windowed autocorrelation analysis.\"\"\"\n",
        "\n",
        "        max_lag_samples = int((max_lag_ms / 1000) * sr)  # Convert max lag to samples\n",
        "\n",
        "        # Use FFT-based cross-correlation for speed\n",
        "        autocorr = scipy.signal.fftconvolve(y, y[::-1], mode='full')\n",
        "        autocorr = autocorr[len(y)-1:len(y)-1+max_lag_samples]  # Keep only positive lags\n",
        "\n",
        "        # Normalize autocorrelation to avoid scale dependency\n",
        "        autocorr /= np.max(np.abs(autocorr) + 1e-8)\n",
        "\n",
        "        # Convert lag indices to time in milliseconds\n",
        "        lag_times = np.arange(len(autocorr)) / sr * 1000  # Convert to ms\n",
        "\n",
        "        # Find peaks with minimum prominence and distance\n",
        "        peak_indices, peak_props = scipy.signal.find_peaks(\n",
        "            autocorr, height=0.1, distance=int(sr * 0.02)  # 20ms min distance\n",
        "        )\n",
        "\n",
        "        if peak_indices.size > 0:\n",
        "            dominant_peak_idx = peak_indices[0]  # First peak is the dominant delay time\n",
        "            dominant_delay_time = lag_times[dominant_peak_idx]\n",
        "            dominant_echo_strength = peak_props['peak_heights'][0]\n",
        "\n",
        "            # Normalize echo strength\n",
        "            normalized_echo_strength = dominant_echo_strength / (np.sum(autocorr) + 1e-8)\n",
        "\n",
        "            # Count strong peaks (multiple echoes)\n",
        "            echo_count = len(peak_indices)\n",
        "        else:\n",
        "            dominant_delay_time = 0\n",
        "            normalized_echo_strength = 0\n",
        "            echo_count = 0\n",
        "\n",
        "        return dominant_delay_time, normalized_echo_strength, echo_count\n",
        "\n",
        "    def extract_spectral_features(self, y, sr):\n",
        "        \"\"\" Compute spectral centroid and flatness features. \"\"\"\n",
        "        # librosa expects float32\n",
        "        y = y.astype(np.float32) / (np.max(np.abs(y)) + np.finfo(np.float32).eps)\n",
        "\n",
        "        spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
        "        spectral_flatness = np.mean(librosa.feature.spectral_flatness(y=y))\n",
        "        return spectral_centroid, spectral_flatness\n",
        "\n",
        "    def extract_freq_rolloff(self, y, sr):\n",
        "        \"\"\" Compute frequency rolloff feature. \"\"\"\n",
        "        y = y.astype(np.float32) / (np.max(np.abs(y)) + np.finfo(np.float32).eps)\n",
        "        freq_rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr))\n",
        "        return freq_rolloff\n",
        "\n",
        "    def extract_spectral_bandwidth(self, y, sr):\n",
        "        \"\"\" Compute spectral bandwidth feature. \"\"\"\n",
        "        y = y.astype(np.float32) / (np.max(np.abs(y)) + np.finfo(np.float32).eps)\n",
        "        spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr))\n",
        "        return spectral_bandwidth\n",
        "\n",
        "    def extract_zero_crossing_rate(self, y):\n",
        "        \"\"\" Compute zero crossing rate feature. \"\"\"\n",
        "        y = y.astype(np.float32) / (np.max(np.abs(y)) + np.finfo(np.float32).eps)\n",
        "        return np.mean(librosa.feature.zero_crossing_rate(y))\n",
        "\n",
        "    def extract_crest_factor(self, y):\n",
        "        \"\"\" Compute crest factor feature (Peak-to_RMS Ratio), ignore silent samples. \"\"\"\n",
        "        threshold_ratio = 0.01\n",
        "        # Get max absolute amplitude\n",
        "        peak_amplitude = np.max(np.abs(y))\n",
        "\n",
        "        # Set threshold based on the max amplitude\n",
        "        min_valid_amplitude = threshold_ratio * peak_amplitude\n",
        "\n",
        "        # Select samples that exceed the threshold\n",
        "        valid_samples = y[np.abs(y) >= min_valid_amplitude]\n",
        "\n",
        "        if valid_samples.size == 0:\n",
        "            return np.nan  # No valid samples found\n",
        "\n",
        "        # Compute RMS on valid samples\n",
        "        rms_amplitude = np.sqrt(np.mean(valid_samples**2))\n",
        "\n",
        "        if rms_amplitude == 0:\n",
        "            return np.nan  # Avoid division by zero\n",
        "\n",
        "        return peak_amplitude / rms_amplitude\n",
        "\n",
        "    def extract_flat_top_indicator(self, y, threshold=0.95):\n",
        "        \"\"\" Compute flat top indicator feature. \"\"\"\n",
        "        peak_amplitude = np.max(np.abs(y))\n",
        "        if peak_amplitude == 0:\n",
        "            return 0.0  # Avoid division by zero (silent signal case)\n",
        "\n",
        "        # Count samples within threshold of peak amplitude\n",
        "        flat_top_samples = np.sum(np.abs(y) >= threshold * peak_amplitude)\n",
        "        total_samples = len(y)\n",
        "\n",
        "        return flat_top_samples / total_samples\n",
        "\n",
        "    def clipping_score(self, y, silence_threshold_ratio=0.005):\n",
        "        \"\"\"\n",
        "        Computes a Clipping Score based on kurtosis, attempts to ignore silence\n",
        "        \"\"\"\n",
        "        # Convert to NumPy array\n",
        "        x = np.asarray(y, dtype=float)\n",
        "\n",
        "        # Remove DC offset (center the signal)\n",
        "        x = x - np.mean(x)\n",
        "\n",
        "        # Compute RMS-based silence threshold (instead of peak-based)\n",
        "        rms_amplitude = np.sqrt(np.mean(x**2))\n",
        "        silence_threshold = silence_threshold_ratio * rms_amplitude\n",
        "\n",
        "        # Define valid (non-silent) samples\n",
        "        valid_samples = x[np.abs(x) >= silence_threshold]\n",
        "\n",
        "        if valid_samples.size == 0:\n",
        "            return 0.0  # If all samples are silent, return 0 (no clipping detected)\n",
        "\n",
        "        # Compute kurtosis on non-silent samples\n",
        "        k = stats.kurtosis(valid_samples, fisher=False, bias=False)\n",
        "\n",
        "        if k == 0 or np.isnan(k):\n",
        "            return 0.0  # Avoid division errors\n",
        "\n",
        "        # Compute Clipping Score as 1/kurtosis\n",
        "        return 1.0 / k\n",
        "\n",
        "    def generate_spectrogram(self, audio_segment, sample_rate, spectrogram_type='mel'):\n",
        "        audio_float = audio_segment.astype(np.float32) / (np.max(np.abs(audio_segment))  + np.finfo(np.float32).eps)\n",
        "        if spectrogram_type == 'mel':\n",
        "            sgrm = librosa.feature.melspectrogram(y=audio_float, sr=sample_rate, n_fft=self.n_fft, hop_length=self.hop_length, n_mels=self.num_mels)\n",
        "        else:\n",
        "            sgrm = librosa.stft(audio_float, n_fft=self.n_fft, hop_length=self.hop_length)\n",
        "        return librosa.amplitude_to_db(sgrm, ref=np.max)\n",
        "\n",
        "    def process_data(self, spectrogram_type='mel'):\n",
        "        label_buffer = []\n",
        "        hdf5_path = os.path.join(self.output_dir, \"test.h5\")\n",
        "\n",
        "        effect_columns = list(self.EFFECT_LABELS.values())  # Extract effect names\n",
        "        all_columns = ['key'] + self.DSP_FEATURES + list(self.EFFECT_LABELS.values())\n",
        "\n",
        "        with h5py.File(hdf5_path, 'w') as h5f:\n",
        "            for file in os.listdir(self.data_dir):\n",
        "                if file.endswith(\".wav\"):\n",
        "                    print(f\"Processing file: {file}\")\n",
        "                    file_path = os.path.join(self.data_dir, file)\n",
        "                    segments, sample_rate = self.split_wav(file_path)\n",
        "                    effect_labels = self.extract_effect_labels(file)  # Extract effect labels (e.g., {'distortion': 1})\n",
        "\n",
        "                    for i, segment in enumerate(segments):\n",
        "                        # sgrm_db = self.generate_spectrogram(segment, sample_rate, spectrogram_type)\n",
        "                        key = f\"{file}_seg_{i+1}\"\n",
        "                        # h5f.create_dataset(key, data=sgrm_db)\n",
        "\n",
        "                        # Compute AM modulation features\n",
        "                        dominant_mod_freq, mod_strength = self.extract_am_modulation_strength(segment, sample_rate)\n",
        "                        #dominant_mod_freq, mod_strength = 0, 0\n",
        "\n",
        "                        # Compute spectral features\n",
        "                        spectral_centroid, spectral_flatness = self.extract_spectral_features(segment, sample_rate)\n",
        "                        #spectral_centroid, spectral_flatness = 0, 0\n",
        "\n",
        "                        # Compute Frequency Rolloff\n",
        "                        freq_rolloff = self.extract_freq_rolloff(segment, sample_rate)\n",
        "\n",
        "                        # Compute Spectral Bandwidth\n",
        "                        spectral_bandwidth = self.extract_spectral_bandwidth(segment, sample_rate)\n",
        "\n",
        "                        # Compute Zero Crossing Rate\n",
        "                        zero_crossing_rate = self.extract_zero_crossing_rate(segment)\n",
        "\n",
        "                        # Compute Crest Factor\n",
        "                        crest_factor = self.extract_crest_factor(segment)\n",
        "\n",
        "                        # Compute Flat Top Indicator\n",
        "                        flat_top_indicator = self.extract_flat_top_indicator(segment)\n",
        "\n",
        "                        # Compute Clipping Score\n",
        "                        clipping_score = self.clipping_score(segment)\n",
        "\n",
        "                        # Ensure all columns exist and are initialized to 0\n",
        "                        label_row = {col: 0 if col in effect_columns else None for col in all_columns}\n",
        "                        #print(f\"Label row init: {label_row}\")\n",
        "\n",
        "                        # Explicitly update effect labels\n",
        "                        for effect in effect_columns:\n",
        "                            label_row[effect] = effect_labels.get(effect, 0)\n",
        "                        #print(f\"Label row after adding effects: {label_row}\")\n",
        "\n",
        "                        # Add computed features (ensuring no overwrites)\n",
        "                        label_row.update({\n",
        "                            'key': key,\n",
        "                            'modulation_freq': round(float(dominant_mod_freq), 2),\n",
        "                            'modulation_strength': round(float(mod_strength), 5),\n",
        "                            'spectral_centroid': round(float(spectral_centroid), 2),\n",
        "                            'spectral_flatness': round(float(spectral_flatness), 5),\n",
        "                            'freq_rolloff': round(float(freq_rolloff), 5),\n",
        "                            'spectral_bandwidth': round(float(spectral_bandwidth), 1),\n",
        "                            'zcr': round(float(zero_crossing_rate), 5),\n",
        "                            'crest_factor': round(float(crest_factor), 5),\n",
        "                            'flat_top_indicator': round(float(flat_top_indicator), 5),\n",
        "                            'clipping_score': round(float(self.clipping_score(segment)), 5)\n",
        "                        })\n",
        "\n",
        "                        #print(f\"Label row after updating with key and DSP features: {label_row}\")\n",
        "                        label_buffer.append(label_row)\n",
        "\n",
        "                        # Write in 100-row batches for efficiency\n",
        "                        if len(label_buffer) >= 100:\n",
        "                            df = pd.DataFrame(label_buffer, columns=all_columns)  # Ensure correct column order\n",
        "                            df.to_csv(self.label_file, mode='a', header=False, index=False)\n",
        "                            print(f\"Wrote {len(label_buffer)} rows to CSV file.\")\n",
        "                            label_buffer.clear()\n",
        "\n",
        "        # Final batch write to ensure all rows are saved\n",
        "        if label_buffer:\n",
        "            df = pd.DataFrame(label_buffer, columns=all_columns)  # Maintain column consistency\n",
        "            df.to_csv(self.label_file, mode='a', header=False, index=False)\n",
        "            print(f\"Final batch: Wrote {len(label_buffer)} rows to CSV file.\")\n",
        "\n",
        "        print(\"Data processing completed. Spectrograms saved to HDF5 file.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/wav_files\n",
        "!cp -r \"/content/drive/MyDrive/Capstone 210/Data/Distortion Types\" \"/content/wav_files\""
      ],
      "metadata": {
        "id": "XyaInreiFq8s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgPzP12Zaxzh",
        "outputId": "3611e162-3b74-4415-b245-5f6e2397e4cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: final_test_ODV.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-58cee0917c78>:197: RuntimeWarning: invalid value encountered in sqrt\n",
            "  rms_amplitude = np.sqrt(np.mean(valid_samples**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote 100 rows to CSV file.\n",
            "Wrote 100 rows to CSV file.\n",
            "Wrote 100 rows to CSV file.\n",
            "Wrote 100 rows to CSV file.\n",
            "Wrote 100 rows to CSV file.\n",
            "Wrote 100 rows to CSV file.\n",
            "Wrote 100 rows to CSV file.\n",
            "Processing file: final_test_DST.wav\n",
            "Wrote 100 rows to CSV file.\n",
            "Wrote 100 rows to CSV file.\n",
            "Wrote 100 rows to CSV file.\n",
            "Wrote 100 rows to CSV file.\n",
            "Wrote 100 rows to CSV file.\n",
            "Wrote 100 rows to CSV file.\n",
            "Wrote 100 rows to CSV file.\n",
            "Wrote 100 rows to CSV file.\n",
            "Processing file: final_test_FUZ.wav\n",
            "Wrote 100 rows to CSV file.\n",
            "Wrote 100 rows to CSV file.\n",
            "Wrote 100 rows to CSV file.\n",
            "Wrote 100 rows to CSV file.\n",
            "Wrote 100 rows to CSV file.\n",
            "Wrote 100 rows to CSV file.\n",
            "Wrote 100 rows to CSV file.\n",
            "Final batch: Wrote 71 rows to CSV file.\n",
            "Data processing completed. Spectrograms saved to HDF5 file.\n"
          ]
        }
      ],
      "source": [
        "data_dir = \"/content/wav_files/Distortion Types\"\n",
        "output_dir = \"/content/drive/MyDrive/Capstone 210/Output\"\n",
        "data_loader = SpectrogramDatasetBuilder(data_dir, output_dir)\n",
        "data_loader.process_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RyB_wigr6hyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "xV25uksG8Mnc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VoSjvnZILh4i"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}