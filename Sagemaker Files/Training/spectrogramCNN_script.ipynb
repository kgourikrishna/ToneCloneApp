{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a7bf20a-aab4-4fab-8ded-c81721dd83c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/pytorch-toneclone\"\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b5e6f3d-d987-47b3-be2c-1bb34b9a45fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mnumpy\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mas\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mnp\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mh5py\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mpandas\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mas\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mpd\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36margparse\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mjson\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mlogging\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36msys\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmetrics\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mimport\u001b[39;49;00m accuracy_score, precision_score, recall_score, f1_score\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#import sagemaker_containers\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdistributed\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mas\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mdist\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mas\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctional\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mas\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mF\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptim\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mas\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36moptim\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mimport\u001b[39;49;00m Dataset, DataLoader\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdistributed\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mtorchvision\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mimport\u001b[39;49;00m datasets, transforms\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmetrics\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mimport\u001b[39;49;00m classification_report\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[32mSpectrogramDataset\u001b[39;49;00m(Dataset):\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m    Custom dataset for spectrogram data.\u001b[39;49;00m\n",
      "\u001b[33m\u001b[39;49;00m\n",
      "\u001b[33m    When the Spectrogram dataset is used to create a dataloader object, the\u001b[39;49;00m\n",
      "\u001b[33m    dataloader consists of batches of spectrograms and their corresponding labels.\u001b[39;49;00m\n",
      "\u001b[33m    Here is info on the shape of the spectrogram and label objects in each batch:\u001b[39;49;00m\n",
      "\u001b[33m\u001b[39;49;00m\n",
      "\u001b[33m    Spectrogram Tensor Dimensions in Batch - (32, 1, 128, 626)\u001b[39;49;00m\n",
      "\u001b[33m        Batch Size: 32\u001b[39;49;00m\n",
      "\u001b[33m        Channels: 1 - Think of it as a grayscale image, rather than RGB\u001b[39;49;00m\n",
      "\u001b[33m        Mel Bands (Height): 128 - 128 Mel filter banks (typical for Mel spectrograms)\u001b[39;49;00m\n",
      "\u001b[33m        Time Steps (Width): 626 - Number of frames\u001b[39;49;00m\n",
      "\u001b[33m\u001b[39;49;00m\n",
      "\u001b[33m    Label Tensor Dimensions in Batch - (32, 12)\u001b[39;49;00m\n",
      "\u001b[33m        Batch Size: 32\u001b[39;49;00m\n",
      "\u001b[33m        Number of Labels: 12 - Multi-hot encoded vector of the 12 effects. This\u001b[39;49;00m\n",
      "\u001b[33m            would increase if we added additional effects.\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, hdf5_file, csv_file):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.hdf5_file_path = hdf5_file\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.labels = pd.read_csv(csv_file)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.label_map = \u001b[36mself\u001b[39;49;00m.labels.columns[\u001b[34m1\u001b[39;49;00m:].tolist() \u001b[37m# Get effect label names\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.hdf5_file = \u001b[34mNone\u001b[39;49;00m   \u001b[37m# File will be opened for each worker\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[32m__len__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.labels)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[32m__getitem__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, idx):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# Open HDF5 file once per worker\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.hdf5_file \u001b[35mis\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.hdf5_file = h5py.File(\u001b[36mself\u001b[39;49;00m.hdf5_file_path, \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, swmr=\u001b[34mTrue\u001b[39;49;00m) \u001b[37m# SWMR ensures multi-thread safe\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        key = \u001b[36mself\u001b[39;49;00m.labels.iloc[idx][\u001b[33m'\u001b[39;49;00m\u001b[33mkey\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        spectrogram = torch.tensor(\u001b[36mself\u001b[39;49;00m.hdf5_file[key][()], dtype=torch.float32).unsqueeze(\u001b[34m0\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        label_values = \u001b[36mself\u001b[39;49;00m.labels.iloc[idx][\u001b[34m1\u001b[39;49;00m:].infer_objects().fillna(\u001b[34m0\u001b[39;49;00m).astype(\u001b[36mfloat\u001b[39;49;00m).values  \u001b[37m# Convert all label columns to float\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        label = torch.tensor(label_values, dtype=torch.float32)  \u001b[37m# Convert to tensor\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m spectrogram, label\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[32m__del__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.hdf5_file \u001b[35mis\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.hdf5_file.close()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[32mspectrogramCNN\u001b[39;49;00m(nn.Module):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, num_classes):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36msuper\u001b[39;49;00m(spectrogramCNN, \u001b[36mself\u001b[39;49;00m).\u001b[32m__init__\u001b[39;49;00m()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.conv1 = nn.Conv2d(\u001b[34m1\u001b[39;49;00m, \u001b[34m32\u001b[39;49;00m, kernel_size=\u001b[34m3\u001b[39;49;00m, stride=\u001b[34m1\u001b[39;49;00m, padding=\u001b[34m1\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.bn1 = nn.BatchNorm2d(\u001b[34m32\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.conv2 = nn.Conv2d(\u001b[34m32\u001b[39;49;00m, \u001b[34m64\u001b[39;49;00m, kernel_size=\u001b[34m3\u001b[39;49;00m, stride=\u001b[34m1\u001b[39;49;00m, padding=\u001b[34m1\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.bn2 = nn.BatchNorm2d(\u001b[34m64\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.conv3 = nn.Conv2d(\u001b[34m64\u001b[39;49;00m, \u001b[34m128\u001b[39;49;00m, kernel_size=\u001b[34m3\u001b[39;49;00m, stride=\u001b[34m1\u001b[39;49;00m, padding=\u001b[34m1\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.bn3 = nn.BatchNorm2d(\u001b[34m128\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.conv4 = nn.Conv2d(\u001b[34m128\u001b[39;49;00m, \u001b[34m256\u001b[39;49;00m, kernel_size=\u001b[34m3\u001b[39;49;00m, stride=\u001b[34m1\u001b[39;49;00m, padding=\u001b[34m1\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.bn4 = nn.BatchNorm2d(\u001b[34m256\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.conv5 = nn.Conv2d(\u001b[34m256\u001b[39;49;00m, \u001b[34m512\u001b[39;49;00m, kernel_size=\u001b[34m3\u001b[39;49;00m, stride=\u001b[34m1\u001b[39;49;00m, padding=\u001b[34m1\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.bn5 = nn.BatchNorm2d(\u001b[34m512\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.pool = nn.MaxPool2d(kernel_size=\u001b[34m2\u001b[39;49;00m, stride=\u001b[34m2\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.flatten_size = (\u001b[34m512\u001b[39;49;00m * (\u001b[34m128\u001b[39;49;00m // \u001b[34m32\u001b[39;49;00m) * (\u001b[34m626\u001b[39;49;00m // \u001b[34m32\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.fc1 = nn.Linear(\u001b[36mself\u001b[39;49;00m.flatten_size, \u001b[34m512\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.fc2 = nn.Linear(\u001b[34m512\u001b[39;49;00m, \u001b[34m256\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.fc3 = nn.Linear(\u001b[34m256\u001b[39;49;00m, num_classes)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.sigmoid = nn.Sigmoid()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[32mforward\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, x):\u001b[37m\u001b[39;49;00m\n",
      "        x = \u001b[36mself\u001b[39;49;00m.pool(torch.relu(\u001b[36mself\u001b[39;49;00m.bn1(\u001b[36mself\u001b[39;49;00m.conv1(x))))\u001b[37m\u001b[39;49;00m\n",
      "        x = \u001b[36mself\u001b[39;49;00m.pool(torch.relu(\u001b[36mself\u001b[39;49;00m.bn2(\u001b[36mself\u001b[39;49;00m.conv2(x))))\u001b[37m\u001b[39;49;00m\n",
      "        x = \u001b[36mself\u001b[39;49;00m.pool(torch.relu(\u001b[36mself\u001b[39;49;00m.bn3(\u001b[36mself\u001b[39;49;00m.conv3(x))))\u001b[37m\u001b[39;49;00m\n",
      "        x = \u001b[36mself\u001b[39;49;00m.pool(torch.relu(\u001b[36mself\u001b[39;49;00m.bn4(\u001b[36mself\u001b[39;49;00m.conv4(x))))\u001b[37m\u001b[39;49;00m\n",
      "        x = \u001b[36mself\u001b[39;49;00m.pool(torch.relu(\u001b[36mself\u001b[39;49;00m.bn5(\u001b[36mself\u001b[39;49;00m.conv5(x))))\u001b[37m\u001b[39;49;00m\n",
      "        x = x.view(x.size(\u001b[34m0\u001b[39;49;00m), -\u001b[34m1\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        x = torch.relu(\u001b[36mself\u001b[39;49;00m.fc1(x))\u001b[37m\u001b[39;49;00m\n",
      "        x = torch.relu(\u001b[36mself\u001b[39;49;00m.fc2(x))\u001b[37m\u001b[39;49;00m\n",
      "        x = \u001b[36mself\u001b[39;49;00m.fc3(x) \u001b[37m# Sigmoid is redundant if using BCEWithLogitcsLoss\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m x\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[32mtrain\u001b[39;49;00m(args):\u001b[37m\u001b[39;49;00m\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    training_dir = args.training\u001b[37m\u001b[39;49;00m\n",
      "    validation_dir = args.validation\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    h5_train_path = os.path.join(training_dir,\u001b[33m'\u001b[39;49;00m\u001b[33mfinal_train.h5\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    csv_train_path = os.path.join(training_dir,\u001b[33m'\u001b[39;49;00m\u001b[33mfinal_train.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    h5_val_path = os.path.join(validation_dir,\u001b[33m'\u001b[39;49;00m\u001b[33mfinal_validate.h5\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    csv_val_path = os.path.join(validation_dir,\u001b[33m'\u001b[39;49;00m\u001b[33mfinal_validate.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    train_dataset = SpectrogramDataset(h5_train_path, csv_train_path)\u001b[37m\u001b[39;49;00m\n",
      "    val_dataset = SpectrogramDataset(h5_val_path, csv_val_path)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    train_loader = DataLoader(train_dataset, batch_size=\u001b[34m32\u001b[39;49;00m, shuffle=\u001b[34mTrue\u001b[39;49;00m, num_workers=\u001b[34m12\u001b[39;49;00m, pin_memory=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    val_loader = DataLoader(val_dataset, batch_size=\u001b[34m32\u001b[39;49;00m, shuffle=\u001b[34mFalse\u001b[39;49;00m, num_workers=\u001b[34m6\u001b[39;49;00m, pin_memory=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    num_classes = \u001b[36mlen\u001b[39;49;00m(train_dataset.label_map)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    model = spectrogramCNN(num_classes).to(device)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    criterion = nn.BCEWithLogitsLoss()\u001b[37m\u001b[39;49;00m\n",
      "    optimizer = optim.Adam(model.parameters(), lr=\u001b[34m0.0001\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=\u001b[34m0.398\u001b[39;49;00m)  \u001b[37m# 0.0001 → 0.00001 over 5 epochs\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Training loop\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    num_epochs = args.epochs\u001b[37m\u001b[39;49;00m\n",
      "    print_freq = \u001b[34m10\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m epoch \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(num_epochs):\u001b[37m\u001b[39;49;00m\n",
      "        model.train()\u001b[37m\u001b[39;49;00m\n",
      "        running_loss = \u001b[34m0.0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m batch_idx, (spectrograms, labels) \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(train_loader):\u001b[37m\u001b[39;49;00m\n",
      "            spectrograms, labels = spectrograms.to(device), labels.to(device)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "            optimizer.zero_grad()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "            outputs = model(spectrograms)\u001b[37m\u001b[39;49;00m\n",
      "            loss = criterion(outputs, labels)\u001b[37m\u001b[39;49;00m\n",
      "            loss.backward()\u001b[37m\u001b[39;49;00m\n",
      "            optimizer.step()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "            running_loss += loss.item()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mif\u001b[39;49;00m (batch_idx + \u001b[34m1\u001b[39;49;00m) % print_freq == \u001b[34m0\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mEpoch [\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mepoch+\u001b[34m1\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnum_epochs\u001b[33m}\u001b[39;49;00m\u001b[33m], Batch [\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mbatch_idx+\u001b[34m1\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[36mlen\u001b[39;49;00m(train_loader)\u001b[33m}\u001b[39;49;00m\u001b[33m], Loss: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mloss.item()\u001b[33m:\u001b[39;49;00m\u001b[33m.4f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        epoch_loss = running_loss / \u001b[36mlen\u001b[39;49;00m(train_loader)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mEpoch \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mepoch+\u001b[34m1\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnum_epochs\u001b[33m}\u001b[39;49;00m\u001b[33m, Loss: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mepoch_loss\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# Update learning rate\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        scheduler.step()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUpdated Learning Rate: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mscheduler.get_last_lr()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# Validation step\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        model.eval()\u001b[37m\u001b[39;49;00m\n",
      "        val_loss = \u001b[34m0.0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        all_preds = []\u001b[37m\u001b[39;49;00m\n",
      "        all_labels = []\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mwith\u001b[39;49;00m torch.no_grad():\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mfor\u001b[39;49;00m spectrograms, labels \u001b[35min\u001b[39;49;00m val_loader:\u001b[37m\u001b[39;49;00m\n",
      "                spectrograms, labels = spectrograms.to(device), labels.to(device)\u001b[37m\u001b[39;49;00m\n",
      "                outputs = model(spectrograms)\u001b[37m\u001b[39;49;00m\n",
      "                loss = criterion(outputs, labels)\u001b[37m\u001b[39;49;00m\n",
      "                val_loss += loss.item()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[37m# Compute accuracy\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "                predicted = (torch.sigmoid(outputs) > \u001b[34m0.5\u001b[39;49;00m).float()  \u001b[37m# Convert logits to binary predictions\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[37m# Store for metric computation\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "                all_preds.extend(predicted.cpu().numpy())\u001b[37m\u001b[39;49;00m\n",
      "                all_labels.extend(labels.cpu().numpy())\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        val_loss /= \u001b[36mlen\u001b[39;49;00m(val_loader)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# Convert lists to numpy arrays for metric calculations\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        all_preds = np.array(all_preds)\u001b[37m\u001b[39;49;00m\n",
      "        all_labels = np.array(all_labels)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# Compute metrics\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        accuracy = accuracy_score(all_labels, all_preds)\u001b[37m\u001b[39;49;00m\n",
      "        precision = precision_score(all_labels, all_preds, average=\u001b[33m\"\u001b[39;49;00m\u001b[33mmacro\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, zero_division=\u001b[34m0\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        recall = recall_score(all_labels, all_preds, average=\u001b[33m\"\u001b[39;49;00m\u001b[33mmacro\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, zero_division=\u001b[34m0\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        f1 = f1_score(all_labels, all_preds, average=\u001b[33m\"\u001b[39;49;00m\u001b[33mmacro\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, zero_division=\u001b[34m0\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Print classification report\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    class_names = train_dataset.label_map\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(classification_report(all_labels, all_preds, target_names=class_names))\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mValidation Loss: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mval_loss\u001b[33m:\u001b[39;49;00m\u001b[33m.4f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m, Accuracy: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00maccuracy\u001b[33m:\u001b[39;49;00m\u001b[33m.4f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m, Precision: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mprecision\u001b[33m:\u001b[39;49;00m\u001b[33m.4f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m, Recall: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mrecall\u001b[33m:\u001b[39;49;00m\u001b[33m.4f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m, F1-score: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mf1\u001b[33m:\u001b[39;49;00m\u001b[33m.4f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    save_model(model, args.model_dir)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\u001b[37m\u001b[39;49;00m\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    model = torch.nn.DataParallel(spectrogramCNN())\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(os.path.join(model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), \u001b[33m\"\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\u001b[37m\u001b[39;49;00m\n",
      "        model.load_state_dict(torch.load(f))\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m model.to(device)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[32msave_model\u001b[39;49;00m(model, model_dir):\u001b[37m\u001b[39;49;00m\n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mSaving the model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    path = os.path.join(model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# recommended way from http://pytorch.org/docs/master/notes/serialization.html\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    torch.save(model.cpu().state_dict(), path)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    parser = argparse.ArgumentParser()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Data and model checkpoints directories\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        default=\u001b[34m10\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mnumber of epochs to train (default: 10)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Container environment\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--training\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--validation\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_VALIDATION\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--num-gpus\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_NUM_GPUS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    train(parser.parse_args())\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize spectrogramCNN_sagemaker.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "570a1e38-2e79-4c41-9f42-84928c5a151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"spectrogramCNN_sagemaker.py\",\n",
    "    role=role,\n",
    "    py_version=\"py38\",\n",
    "    framework_version=\"1.11.0\",\n",
    "    instance_count=2,\n",
    "    instance_type=\"ml.g5.12xlarge\",\n",
    "    hyperparameters={\"epochs\": 1},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6daa9399-08fe-4335-af38-82678fa9cfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2025-02-15-19-50-01-824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 19:50:03 Starting - Starting the training job...\n",
      "2025-02-15 19:50:35 Downloading - Downloading input data....................................................................................\n",
      "2025-02-15 20:04:38 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2025-02-15 15:04:43,688 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2025-02-15 15:04:43,690 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2025-02-15 15:04:43,692 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-02-15 15:04:43,703 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2025-02-15 15:04:43,711 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2025-02-15 15:04:44,043 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2025-02-15 15:04:44,045 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-02-15 15:04:44,059 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2025-02-15 15:04:44,061 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-02-15 15:04:44,076 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2025-02-15 15:04:44,078 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-02-15 15:04:44,090 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\",\n",
      "                \"algo-2\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"job_name\": \"pytorch-training-2025-02-15-19-50-01-824\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-692859912226/pytorch-training-2025-02-15-19-50-01-824/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"spectrogramCNN_sagemaker\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"spectrogramCNN_sagemaker.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=spectrogramCNN_sagemaker.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.m5.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=spectrogramCNN_sagemaker\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-692859912226/pytorch-training-2025-02-15-19-50-01-824/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.m5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"epochs\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"job_name\":\"pytorch-training-2025-02-15-19-50-01-824\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-692859912226/pytorch-training-2025-02-15-19-50-01-824/source/sourcedir.tar.gz\",\"module_name\":\"spectrogramCNN_sagemaker\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"spectrogramCNN_sagemaker.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.26b20230214-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 spectrogramCNN_sagemaker.py --epochs 1\u001b[0m\n",
      "\u001b[34m2025-02-15 15:04:44,800 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:489: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\u001b[0m\n",
      "\u001b[34m[2025-02-15 15:04:47.608 algo-1:47 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.26b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.26b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[2025-02-15 15:04:47.862 algo-1:47 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2025-02-15 15:04:47.864 algo-1:47 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2025-02-15 15:04:47.864 algo-1:47 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2025-02-15 15:04:47.865 algo-1:47 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2025-02-15 15:04:47.865 algo-1:47 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[35mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[35mbash: no job control in this shell\u001b[0m\n",
      "\u001b[35m2025-02-15 15:04:45,491 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[35m2025-02-15 15:04:45,493 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2025-02-15 15:04:45,495 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[35m2025-02-15 15:04:45,506 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[35m2025-02-15 15:04:45,515 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[35m2025-02-15 15:04:45,856 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2025-02-15 15:04:45,859 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[35m2025-02-15 15:04:45,873 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2025-02-15 15:04:45,875 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[35m2025-02-15 15:04:45,890 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2025-02-15 15:04:45,892 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[35m2025-02-15 15:04:45,904 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[35mTraining Env:\u001b[0m\n",
      "\u001b[35m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\",\n",
      "                \"algo-2\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": false,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"job_name\": \"pytorch-training-2025-02-15-19-50-01-824\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-692859912226/pytorch-training-2025-02-15-19-50-01-824/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"spectrogramCNN_sagemaker\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"current_instance_type\": \"ml.m5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"spectrogramCNN_sagemaker.py\"\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mEnvironment variables:\u001b[0m\n",
      "\u001b[35mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[35mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[35mSM_HPS={\"epochs\":1}\u001b[0m\n",
      "\u001b[35mSM_USER_ENTRY_POINT=spectrogramCNN_sagemaker.py\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[35mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[35mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[35mSM_CHANNELS=[\"training\",\"validation\"]\u001b[0m\n",
      "\u001b[35mSM_CURRENT_HOST=algo-2\u001b[0m\n",
      "\u001b[35mSM_CURRENT_INSTANCE_TYPE=ml.m5.2xlarge\u001b[0m\n",
      "\u001b[35mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[35mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[35mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[35mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}}\u001b[0m\n",
      "\u001b[35mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[35mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[35mSM_MODULE_NAME=spectrogramCNN_sagemaker\u001b[0m\n",
      "\u001b[35mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[35mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[35mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[35mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[35mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[35mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[35mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[35mSM_MODULE_DIR=s3://sagemaker-us-west-2-692859912226/pytorch-training-2025-02-15-19-50-01-824/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[35mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-2\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.m5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"epochs\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}},\"is_hetero\":false,\"is_master\":false,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"job_name\":\"pytorch-training-2025-02-15-19-50-01-824\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-692859912226/pytorch-training-2025-02-15-19-50-01-824/source/sourcedir.tar.gz\",\"module_name\":\"spectrogramCNN_sagemaker\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"spectrogramCNN_sagemaker.py\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ARGS=[\"--epochs\",\"1\"]\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[35mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[35mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[35mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[35mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.26b20230214-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[35mInvoking script with the following command:\u001b[0m\n",
      "\u001b[35m/opt/conda/bin/python3.8 spectrogramCNN_sagemaker.py --epochs 1\u001b[0m\n",
      "\u001b[35m2025-02-15 15:04:46,602 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:489: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\u001b[0m\n",
      "\u001b[35m[2025-02-15 15:04:49.354 algo-2:47 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.26b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.26b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[35m[2025-02-15 15:04:49.590 algo-2:47 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[35m[2025-02-15 15:04:49.591 algo-2:47 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[35m[2025-02-15 15:04:49.591 algo-2:47 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[35m[2025-02-15 15:04:49.592 algo-2:47 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[35m[2025-02-15 15:04:49.592 algo-2:47 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [10/4062], Loss: 0.3815\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [10/4062], Loss: 0.3932\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [20/4062], Loss: 0.3187\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [20/4062], Loss: 0.3501\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [30/4062], Loss: 0.3206\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [30/4062], Loss: 0.3270\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [40/4062], Loss: 0.2985\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [40/4062], Loss: 0.3334\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [50/4062], Loss: 0.2557\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [50/4062], Loss: 0.2718\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [60/4062], Loss: 0.2751\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [60/4062], Loss: 0.2285\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [70/4062], Loss: 0.2698\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [70/4062], Loss: 0.2692\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [80/4062], Loss: 0.2504\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [80/4062], Loss: 0.2185\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [90/4062], Loss: 0.2093\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [90/4062], Loss: 0.2317\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [100/4062], Loss: 0.1740\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [100/4062], Loss: 0.1724\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [110/4062], Loss: 0.1811\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [110/4062], Loss: 0.1944\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [120/4062], Loss: 0.1549\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [120/4062], Loss: 0.1741\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [130/4062], Loss: 0.1314\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [130/4062], Loss: 0.2404\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [140/4062], Loss: 0.1524\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [140/4062], Loss: 0.1781\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [150/4062], Loss: 0.1304\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [150/4062], Loss: 0.0925\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [160/4062], Loss: 0.0984\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [160/4062], Loss: 0.1852\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [170/4062], Loss: 0.1235\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [170/4062], Loss: 0.1514\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [180/4062], Loss: 0.1410\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [180/4062], Loss: 0.1186\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [190/4062], Loss: 0.1246\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [190/4062], Loss: 0.1294\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [200/4062], Loss: 0.1169\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [200/4062], Loss: 0.1416\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [210/4062], Loss: 0.1515\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [220/4062], Loss: 0.1054\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [210/4062], Loss: 0.1590\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [230/4062], Loss: 0.1166\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [220/4062], Loss: 0.1170\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [240/4062], Loss: 0.1171\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [230/4062], Loss: 0.1052\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [250/4062], Loss: 0.1165\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [240/4062], Loss: 0.1037\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [260/4062], Loss: 0.0647\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [250/4062], Loss: 0.1059\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [270/4062], Loss: 0.1170\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [260/4062], Loss: 0.0718\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [280/4062], Loss: 0.1131\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [270/4062], Loss: 0.0775\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [290/4062], Loss: 0.0984\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [280/4062], Loss: 0.0911\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [300/4062], Loss: 0.0905\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [290/4062], Loss: 0.1011\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [310/4062], Loss: 0.1014\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [300/4062], Loss: 0.0824\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [320/4062], Loss: 0.0600\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [310/4062], Loss: 0.0832\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [330/4062], Loss: 0.1048\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [320/4062], Loss: 0.0793\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [340/4062], Loss: 0.0655\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [330/4062], Loss: 0.0981\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [350/4062], Loss: 0.0959\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [340/4062], Loss: 0.0620\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [360/4062], Loss: 0.0807\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [350/4062], Loss: 0.0724\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [370/4062], Loss: 0.1084\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [360/4062], Loss: 0.1033\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [380/4062], Loss: 0.0928\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [390/4062], Loss: 0.0723\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [370/4062], Loss: 0.0755\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [400/4062], Loss: 0.0701\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [380/4062], Loss: 0.0655\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [410/4062], Loss: 0.0593\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [390/4062], Loss: 0.0732\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [420/4062], Loss: 0.0521\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [400/4062], Loss: 0.0598\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [430/4062], Loss: 0.0918\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [410/4062], Loss: 0.0476\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [440/4062], Loss: 0.1065\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [420/4062], Loss: 0.0770\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [450/4062], Loss: 0.0835\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [430/4062], Loss: 0.0563\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [460/4062], Loss: 0.0593\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [440/4062], Loss: 0.0683\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [470/4062], Loss: 0.0861\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [480/4062], Loss: 0.0522\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [450/4062], Loss: 0.0801\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [490/4062], Loss: 0.0544\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [460/4062], Loss: 0.0524\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [500/4062], Loss: 0.0763\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [470/4062], Loss: 0.0608\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [510/4062], Loss: 0.0855\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [480/4062], Loss: 0.0554\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [520/4062], Loss: 0.0519\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [490/4062], Loss: 0.0634\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [530/4062], Loss: 0.0679\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [500/4062], Loss: 0.0337\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [540/4062], Loss: 0.0758\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [510/4062], Loss: 0.0718\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [550/4062], Loss: 0.0643\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [520/4062], Loss: 0.0752\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [560/4062], Loss: 0.0535\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [530/4062], Loss: 0.0638\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [570/4062], Loss: 0.0399\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [540/4062], Loss: 0.0975\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [580/4062], Loss: 0.0665\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [550/4062], Loss: 0.0967\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [590/4062], Loss: 0.0775\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [560/4062], Loss: 0.0434\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [600/4062], Loss: 0.0548\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [570/4062], Loss: 0.0394\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [610/4062], Loss: 0.0708\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [580/4062], Loss: 0.0805\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [620/4062], Loss: 0.0454\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [590/4062], Loss: 0.0475\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [630/4062], Loss: 0.0707\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [600/4062], Loss: 0.0677\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [640/4062], Loss: 0.0487\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [610/4062], Loss: 0.0646\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [650/4062], Loss: 0.0573\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [620/4062], Loss: 0.0575\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [660/4062], Loss: 0.0470\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [630/4062], Loss: 0.0667\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [670/4062], Loss: 0.0461\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [680/4062], Loss: 0.0500\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [640/4062], Loss: 0.0556\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [690/4062], Loss: 0.0554\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [650/4062], Loss: 0.0648\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [700/4062], Loss: 0.0493\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [660/4062], Loss: 0.0577\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [710/4062], Loss: 0.0349\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [670/4062], Loss: 0.0602\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [720/4062], Loss: 0.0483\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [680/4062], Loss: 0.0627\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [730/4062], Loss: 0.0648\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [690/4062], Loss: 0.0438\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [740/4062], Loss: 0.0302\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [700/4062], Loss: 0.0491\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [750/4062], Loss: 0.0458\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [710/4062], Loss: 0.0434\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [760/4062], Loss: 0.0335\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [720/4062], Loss: 0.0494\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [770/4062], Loss: 0.0659\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [730/4062], Loss: 0.0508\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [780/4062], Loss: 0.0583\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [740/4062], Loss: 0.0728\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [790/4062], Loss: 0.0750\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [750/4062], Loss: 0.0321\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [800/4062], Loss: 0.0884\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [760/4062], Loss: 0.0637\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [810/4062], Loss: 0.0463\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [770/4062], Loss: 0.0558\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [820/4062], Loss: 0.0463\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [780/4062], Loss: 0.0483\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [830/4062], Loss: 0.0330\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [790/4062], Loss: 0.0574\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [840/4062], Loss: 0.0351\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [800/4062], Loss: 0.0481\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [850/4062], Loss: 0.0511\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [810/4062], Loss: 0.0570\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [860/4062], Loss: 0.0445\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [820/4062], Loss: 0.0471\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [870/4062], Loss: 0.0477\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [830/4062], Loss: 0.0481\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [880/4062], Loss: 0.0355\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [890/4062], Loss: 0.0500\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [840/4062], Loss: 0.0539\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [900/4062], Loss: 0.0362\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [850/4062], Loss: 0.0231\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [910/4062], Loss: 0.0543\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [860/4062], Loss: 0.0243\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [920/4062], Loss: 0.0518\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [870/4062], Loss: 0.0571\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [930/4062], Loss: 0.0757\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [880/4062], Loss: 0.0305\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [940/4062], Loss: 0.0409\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [890/4062], Loss: 0.0568\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [950/4062], Loss: 0.0343\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [900/4062], Loss: 0.0368\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [960/4062], Loss: 0.0540\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [910/4062], Loss: 0.0467\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [970/4062], Loss: 0.0188\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [920/4062], Loss: 0.0301\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [980/4062], Loss: 0.0875\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [930/4062], Loss: 0.0519\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [990/4062], Loss: 0.0360\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [940/4062], Loss: 0.0205\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1000/4062], Loss: 0.0194\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [950/4062], Loss: 0.0376\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1010/4062], Loss: 0.0306\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [960/4062], Loss: 0.0292\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1020/4062], Loss: 0.0326\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [970/4062], Loss: 0.0497\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1030/4062], Loss: 0.0307\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [980/4062], Loss: 0.0412\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1040/4062], Loss: 0.0350\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [990/4062], Loss: 0.0272\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1050/4062], Loss: 0.0168\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1000/4062], Loss: 0.0331\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1060/4062], Loss: 0.0467\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1010/4062], Loss: 0.0231\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1070/4062], Loss: 0.0375\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1020/4062], Loss: 0.0316\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1080/4062], Loss: 0.0460\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1090/4062], Loss: 0.0472\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1030/4062], Loss: 0.0339\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1100/4062], Loss: 0.0348\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1040/4062], Loss: 0.0520\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1110/4062], Loss: 0.0354\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1050/4062], Loss: 0.0304\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1060/4062], Loss: 0.0446\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1120/4062], Loss: 0.0248\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1130/4062], Loss: 0.0289\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1070/4062], Loss: 0.0232\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1140/4062], Loss: 0.0299\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1080/4062], Loss: 0.0420\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1150/4062], Loss: 0.0466\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1090/4062], Loss: 0.0209\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1160/4062], Loss: 0.0267\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1100/4062], Loss: 0.0381\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1170/4062], Loss: 0.0292\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1110/4062], Loss: 0.0503\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1180/4062], Loss: 0.0704\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1120/4062], Loss: 0.0347\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1190/4062], Loss: 0.0376\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1130/4062], Loss: 0.0360\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1200/4062], Loss: 0.0283\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1140/4062], Loss: 0.0252\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1210/4062], Loss: 0.0147\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1150/4062], Loss: 0.0737\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1220/4062], Loss: 0.0211\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1160/4062], Loss: 0.0468\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1230/4062], Loss: 0.0338\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1170/4062], Loss: 0.0300\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1240/4062], Loss: 0.0333\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1180/4062], Loss: 0.0406\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1250/4062], Loss: 0.0510\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1190/4062], Loss: 0.0399\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1260/4062], Loss: 0.0222\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1200/4062], Loss: 0.0400\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1270/4062], Loss: 0.0424\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1280/4062], Loss: 0.0223\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1210/4062], Loss: 0.0468\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1290/4062], Loss: 0.0429\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1220/4062], Loss: 0.0173\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1300/4062], Loss: 0.0351\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1230/4062], Loss: 0.0450\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1310/4062], Loss: 0.0879\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1240/4062], Loss: 0.0464\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1320/4062], Loss: 0.0608\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1250/4062], Loss: 0.0150\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1330/4062], Loss: 0.0368\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1260/4062], Loss: 0.0412\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1340/4062], Loss: 0.0357\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1270/4062], Loss: 0.0171\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1350/4062], Loss: 0.0316\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1280/4062], Loss: 0.0278\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1360/4062], Loss: 0.0508\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1290/4062], Loss: 0.0162\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1370/4062], Loss: 0.0438\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1300/4062], Loss: 0.0310\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1380/4062], Loss: 0.0455\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1310/4062], Loss: 0.0462\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1390/4062], Loss: 0.0333\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1320/4062], Loss: 0.0404\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1400/4062], Loss: 0.0280\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1330/4062], Loss: 0.0243\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1410/4062], Loss: 0.0284\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1340/4062], Loss: 0.0468\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1420/4062], Loss: 0.0153\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1350/4062], Loss: 0.0518\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1430/4062], Loss: 0.0486\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1440/4062], Loss: 0.0292\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1360/4062], Loss: 0.0201\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1450/4062], Loss: 0.0323\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1370/4062], Loss: 0.0182\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1460/4062], Loss: 0.0340\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1380/4062], Loss: 0.0282\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1470/4062], Loss: 0.0233\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1390/4062], Loss: 0.0287\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1480/4062], Loss: 0.0331\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1400/4062], Loss: 0.0269\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1490/4062], Loss: 0.0271\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1410/4062], Loss: 0.0225\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1500/4062], Loss: 0.0288\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1420/4062], Loss: 0.0209\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1510/4062], Loss: 0.0119\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1430/4062], Loss: 0.0398\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1520/4062], Loss: 0.0277\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1440/4062], Loss: 0.0281\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1530/4062], Loss: 0.0253\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1450/4062], Loss: 0.0547\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1540/4062], Loss: 0.0227\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1460/4062], Loss: 0.0433\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1550/4062], Loss: 0.0204\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1470/4062], Loss: 0.0186\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1560/4062], Loss: 0.0269\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1480/4062], Loss: 0.0152\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1570/4062], Loss: 0.0348\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1490/4062], Loss: 0.0181\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1580/4062], Loss: 0.0114\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1500/4062], Loss: 0.0186\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1590/4062], Loss: 0.0186\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1510/4062], Loss: 0.0348\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1600/4062], Loss: 0.0476\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1520/4062], Loss: 0.0160\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1610/4062], Loss: 0.0286\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1530/4062], Loss: 0.0226\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1620/4062], Loss: 0.0466\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1540/4062], Loss: 0.0156\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1630/4062], Loss: 0.0153\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1550/4062], Loss: 0.0152\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1640/4062], Loss: 0.0276\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1560/4062], Loss: 0.0111\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1650/4062], Loss: 0.0454\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1570/4062], Loss: 0.0112\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1660/4062], Loss: 0.0414\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1670/4062], Loss: 0.0368\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1580/4062], Loss: 0.0258\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1680/4062], Loss: 0.0372\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1590/4062], Loss: 0.0442\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1690/4062], Loss: 0.0399\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1600/4062], Loss: 0.0283\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1700/4062], Loss: 0.0308\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1610/4062], Loss: 0.0202\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1710/4062], Loss: 0.0106\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1620/4062], Loss: 0.0635\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1720/4062], Loss: 0.0203\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1630/4062], Loss: 0.0522\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1730/4062], Loss: 0.0392\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1640/4062], Loss: 0.0242\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1740/4062], Loss: 0.0231\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1650/4062], Loss: 0.0302\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1750/4062], Loss: 0.0518\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1660/4062], Loss: 0.0170\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1760/4062], Loss: 0.0154\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1670/4062], Loss: 0.0372\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1770/4062], Loss: 0.0223\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1680/4062], Loss: 0.0128\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1780/4062], Loss: 0.0183\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1690/4062], Loss: 0.0259\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1790/4062], Loss: 0.0289\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1700/4062], Loss: 0.0207\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1800/4062], Loss: 0.0303\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1710/4062], Loss: 0.0127\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1810/4062], Loss: 0.0153\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1720/4062], Loss: 0.0217\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1820/4062], Loss: 0.0509\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1730/4062], Loss: 0.0530\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1830/4062], Loss: 0.0418\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1740/4062], Loss: 0.0240\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1840/4062], Loss: 0.0302\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1750/4062], Loss: 0.0303\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1850/4062], Loss: 0.0188\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1760/4062], Loss: 0.0229\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1860/4062], Loss: 0.0257\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1870/4062], Loss: 0.0423\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1770/4062], Loss: 0.0116\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1880/4062], Loss: 0.0395\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1780/4062], Loss: 0.0321\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1890/4062], Loss: 0.0181\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1790/4062], Loss: 0.0165\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1900/4062], Loss: 0.0346\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1800/4062], Loss: 0.0476\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1910/4062], Loss: 0.0157\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1810/4062], Loss: 0.0112\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1920/4062], Loss: 0.0069\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1820/4062], Loss: 0.0256\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1930/4062], Loss: 0.0150\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1830/4062], Loss: 0.0110\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1940/4062], Loss: 0.0231\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1840/4062], Loss: 0.0377\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1950/4062], Loss: 0.0298\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1850/4062], Loss: 0.0260\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1960/4062], Loss: 0.0081\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1860/4062], Loss: 0.0096\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1970/4062], Loss: 0.0279\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1870/4062], Loss: 0.0502\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1980/4062], Loss: 0.0404\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1880/4062], Loss: 0.0100\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [1990/4062], Loss: 0.0254\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1890/4062], Loss: 0.0458\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2000/4062], Loss: 0.0425\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1900/4062], Loss: 0.0172\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2010/4062], Loss: 0.0312\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1910/4062], Loss: 0.0244\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2020/4062], Loss: 0.0353\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1920/4062], Loss: 0.0290\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2030/4062], Loss: 0.0238\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1930/4062], Loss: 0.0318\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2040/4062], Loss: 0.0110\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1940/4062], Loss: 0.0227\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2050/4062], Loss: 0.0519\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1950/4062], Loss: 0.0161\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2060/4062], Loss: 0.0292\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2070/4062], Loss: 0.0307\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1960/4062], Loss: 0.0245\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2080/4062], Loss: 0.0167\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1970/4062], Loss: 0.0558\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2090/4062], Loss: 0.0276\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1980/4062], Loss: 0.0162\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2100/4062], Loss: 0.0200\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [1990/4062], Loss: 0.0506\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2110/4062], Loss: 0.0220\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2000/4062], Loss: 0.0333\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2120/4062], Loss: 0.0141\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2010/4062], Loss: 0.0175\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2130/4062], Loss: 0.0164\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2020/4062], Loss: 0.0529\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2140/4062], Loss: 0.0279\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2030/4062], Loss: 0.0198\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2150/4062], Loss: 0.0208\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2040/4062], Loss: 0.0336\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2160/4062], Loss: 0.0157\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2050/4062], Loss: 0.0292\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2170/4062], Loss: 0.0263\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2060/4062], Loss: 0.0178\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2180/4062], Loss: 0.0368\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2070/4062], Loss: 0.0086\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2190/4062], Loss: 0.0224\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2080/4062], Loss: 0.0233\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2200/4062], Loss: 0.0133\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2090/4062], Loss: 0.0159\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2210/4062], Loss: 0.0608\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2100/4062], Loss: 0.0171\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2220/4062], Loss: 0.0174\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2230/4062], Loss: 0.0155\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2110/4062], Loss: 0.0202\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2240/4062], Loss: 0.0076\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2120/4062], Loss: 0.0333\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2250/4062], Loss: 0.0110\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2130/4062], Loss: 0.0129\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2260/4062], Loss: 0.0279\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2140/4062], Loss: 0.0153\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2270/4062], Loss: 0.0118\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2150/4062], Loss: 0.0436\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2280/4062], Loss: 0.0065\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2160/4062], Loss: 0.0212\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2290/4062], Loss: 0.0293\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2170/4062], Loss: 0.0150\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2300/4062], Loss: 0.0143\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2180/4062], Loss: 0.0275\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2310/4062], Loss: 0.0106\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2190/4062], Loss: 0.0217\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2320/4062], Loss: 0.0068\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2200/4062], Loss: 0.0130\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2330/4062], Loss: 0.0131\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2210/4062], Loss: 0.0192\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2340/4062], Loss: 0.0190\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2220/4062], Loss: 0.0241\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2350/4062], Loss: 0.0140\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2230/4062], Loss: 0.0279\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2360/4062], Loss: 0.0224\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2240/4062], Loss: 0.0161\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2370/4062], Loss: 0.0414\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2380/4062], Loss: 0.0290\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2250/4062], Loss: 0.0375\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2390/4062], Loss: 0.0297\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2260/4062], Loss: 0.0152\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2400/4062], Loss: 0.0303\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2270/4062], Loss: 0.0133\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2410/4062], Loss: 0.0108\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2280/4062], Loss: 0.0173\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2420/4062], Loss: 0.0586\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2290/4062], Loss: 0.0541\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2430/4062], Loss: 0.0234\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2300/4062], Loss: 0.0076\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2440/4062], Loss: 0.0104\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2310/4062], Loss: 0.0652\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2450/4062], Loss: 0.0293\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2320/4062], Loss: 0.0044\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2460/4062], Loss: 0.0339\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2330/4062], Loss: 0.0138\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2470/4062], Loss: 0.0604\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2340/4062], Loss: 0.0158\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2480/4062], Loss: 0.0386\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2350/4062], Loss: 0.0192\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2490/4062], Loss: 0.0270\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2360/4062], Loss: 0.0202\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2500/4062], Loss: 0.0063\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2370/4062], Loss: 0.0285\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2510/4062], Loss: 0.0215\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2380/4062], Loss: 0.0217\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2520/4062], Loss: 0.0094\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2390/4062], Loss: 0.0101\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2530/4062], Loss: 0.0013\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2400/4062], Loss: 0.0150\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2540/4062], Loss: 0.0128\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2410/4062], Loss: 0.0079\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2550/4062], Loss: 0.0176\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2420/4062], Loss: 0.0256\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2560/4062], Loss: 0.0122\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2430/4062], Loss: 0.0136\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2570/4062], Loss: 0.0098\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2580/4062], Loss: 0.0361\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2440/4062], Loss: 0.0238\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2590/4062], Loss: 0.0197\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2450/4062], Loss: 0.0137\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2600/4062], Loss: 0.0281\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2460/4062], Loss: 0.0031\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2610/4062], Loss: 0.0068\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2470/4062], Loss: 0.0109\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2620/4062], Loss: 0.0141\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2480/4062], Loss: 0.0203\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2630/4062], Loss: 0.0139\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2490/4062], Loss: 0.0163\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2640/4062], Loss: 0.0202\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2500/4062], Loss: 0.0122\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2650/4062], Loss: 0.0069\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2510/4062], Loss: 0.0130\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2660/4062], Loss: 0.0225\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2520/4062], Loss: 0.0285\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2670/4062], Loss: 0.0153\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2530/4062], Loss: 0.0364\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2680/4062], Loss: 0.0151\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2540/4062], Loss: 0.0301\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2690/4062], Loss: 0.0239\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2550/4062], Loss: 0.0143\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2700/4062], Loss: 0.0156\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2560/4062], Loss: 0.0332\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2710/4062], Loss: 0.0330\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2570/4062], Loss: 0.0383\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2720/4062], Loss: 0.0340\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2580/4062], Loss: 0.0190\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2730/4062], Loss: 0.0348\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2590/4062], Loss: 0.0207\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2740/4062], Loss: 0.0224\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2600/4062], Loss: 0.0062\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2750/4062], Loss: 0.0073\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2610/4062], Loss: 0.0156\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2760/4062], Loss: 0.0221\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2770/4062], Loss: 0.0187\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2620/4062], Loss: 0.0224\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2780/4062], Loss: 0.0268\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2630/4062], Loss: 0.0180\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2790/4062], Loss: 0.0275\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2640/4062], Loss: 0.0367\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2800/4062], Loss: 0.0254\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2650/4062], Loss: 0.0051\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2810/4062], Loss: 0.0249\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2660/4062], Loss: 0.0180\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2820/4062], Loss: 0.0065\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2670/4062], Loss: 0.0100\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2830/4062], Loss: 0.0211\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2680/4062], Loss: 0.0419\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2840/4062], Loss: 0.0267\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2690/4062], Loss: 0.0069\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2850/4062], Loss: 0.0308\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2700/4062], Loss: 0.0347\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2860/4062], Loss: 0.0122\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2710/4062], Loss: 0.0109\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2870/4062], Loss: 0.0072\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2720/4062], Loss: 0.0080\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2880/4062], Loss: 0.0113\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2890/4062], Loss: 0.0740\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2730/4062], Loss: 0.0135\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2900/4062], Loss: 0.0054\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2740/4062], Loss: 0.0103\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2910/4062], Loss: 0.0235\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2750/4062], Loss: 0.0076\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2920/4062], Loss: 0.0181\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2760/4062], Loss: 0.0220\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2930/4062], Loss: 0.0358\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2770/4062], Loss: 0.0249\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2940/4062], Loss: 0.0324\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2780/4062], Loss: 0.0158\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2950/4062], Loss: 0.0137\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2790/4062], Loss: 0.0049\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2960/4062], Loss: 0.0205\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2800/4062], Loss: 0.0179\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2970/4062], Loss: 0.0065\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2810/4062], Loss: 0.0119\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2980/4062], Loss: 0.0180\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2820/4062], Loss: 0.0314\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [2990/4062], Loss: 0.0206\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2830/4062], Loss: 0.0141\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3000/4062], Loss: 0.0067\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2840/4062], Loss: 0.0077\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3010/4062], Loss: 0.0213\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2850/4062], Loss: 0.0168\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3020/4062], Loss: 0.0188\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2860/4062], Loss: 0.0167\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3030/4062], Loss: 0.0052\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2870/4062], Loss: 0.0229\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3040/4062], Loss: 0.0156\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2880/4062], Loss: 0.0215\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3050/4062], Loss: 0.0314\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2890/4062], Loss: 0.0285\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3060/4062], Loss: 0.0136\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3070/4062], Loss: 0.0176\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2900/4062], Loss: 0.0069\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3080/4062], Loss: 0.0242\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2910/4062], Loss: 0.0301\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3090/4062], Loss: 0.0182\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2920/4062], Loss: 0.0166\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3100/4062], Loss: 0.0242\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2930/4062], Loss: 0.0157\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3110/4062], Loss: 0.0110\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2940/4062], Loss: 0.0065\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3120/4062], Loss: 0.0178\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2950/4062], Loss: 0.0154\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3130/4062], Loss: 0.0175\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2960/4062], Loss: 0.0109\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3140/4062], Loss: 0.0145\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2970/4062], Loss: 0.0133\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3150/4062], Loss: 0.0348\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2980/4062], Loss: 0.0156\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3160/4062], Loss: 0.0124\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [2990/4062], Loss: 0.0057\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3170/4062], Loss: 0.0547\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3180/4062], Loss: 0.0177\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3000/4062], Loss: 0.0327\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3190/4062], Loss: 0.0126\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3010/4062], Loss: 0.0362\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3200/4062], Loss: 0.0046\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3020/4062], Loss: 0.0287\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3210/4062], Loss: 0.0174\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3030/4062], Loss: 0.0047\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3220/4062], Loss: 0.0084\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3040/4062], Loss: 0.0147\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3230/4062], Loss: 0.0310\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3050/4062], Loss: 0.0407\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3240/4062], Loss: 0.0304\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3060/4062], Loss: 0.0265\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3250/4062], Loss: 0.0035\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3070/4062], Loss: 0.0197\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3260/4062], Loss: 0.0321\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3080/4062], Loss: 0.0259\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3270/4062], Loss: 0.0484\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3090/4062], Loss: 0.0188\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3280/4062], Loss: 0.0090\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3100/4062], Loss: 0.0158\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3290/4062], Loss: 0.0220\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3110/4062], Loss: 0.0222\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3300/4062], Loss: 0.0116\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3120/4062], Loss: 0.0200\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3310/4062], Loss: 0.0131\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3130/4062], Loss: 0.0059\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3320/4062], Loss: 0.0215\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3140/4062], Loss: 0.0168\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3330/4062], Loss: 0.0301\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3150/4062], Loss: 0.0086\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3340/4062], Loss: 0.0080\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3160/4062], Loss: 0.0201\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3350/4062], Loss: 0.0245\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3360/4062], Loss: 0.0072\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3170/4062], Loss: 0.0272\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3370/4062], Loss: 0.0025\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3180/4062], Loss: 0.0296\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3380/4062], Loss: 0.0149\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3190/4062], Loss: 0.0201\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3390/4062], Loss: 0.0088\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3200/4062], Loss: 0.0085\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3400/4062], Loss: 0.0263\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3210/4062], Loss: 0.0104\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3410/4062], Loss: 0.0212\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3220/4062], Loss: 0.0142\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3420/4062], Loss: 0.0178\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3230/4062], Loss: 0.0202\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3430/4062], Loss: 0.0082\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3240/4062], Loss: 0.0237\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3440/4062], Loss: 0.0102\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3250/4062], Loss: 0.0072\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3450/4062], Loss: 0.0062\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3260/4062], Loss: 0.0265\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3460/4062], Loss: 0.0225\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3270/4062], Loss: 0.0294\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3470/4062], Loss: 0.0175\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3280/4062], Loss: 0.0040\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3480/4062], Loss: 0.0111\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3290/4062], Loss: 0.0032\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3490/4062], Loss: 0.0149\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3500/4062], Loss: 0.0089\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3300/4062], Loss: 0.0113\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3510/4062], Loss: 0.0052\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3310/4062], Loss: 0.0054\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3520/4062], Loss: 0.0256\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3320/4062], Loss: 0.0172\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3530/4062], Loss: 0.0093\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3330/4062], Loss: 0.0335\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3540/4062], Loss: 0.0132\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3340/4062], Loss: 0.0430\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3550/4062], Loss: 0.0227\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3350/4062], Loss: 0.0361\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3560/4062], Loss: 0.0146\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3360/4062], Loss: 0.0078\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3570/4062], Loss: 0.0125\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3370/4062], Loss: 0.0287\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3580/4062], Loss: 0.0083\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3380/4062], Loss: 0.0142\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3590/4062], Loss: 0.0184\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3390/4062], Loss: 0.0155\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3600/4062], Loss: 0.0284\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3400/4062], Loss: 0.0201\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3610/4062], Loss: 0.0125\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3410/4062], Loss: 0.0248\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3620/4062], Loss: 0.0018\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3420/4062], Loss: 0.0148\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3630/4062], Loss: 0.0123\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3640/4062], Loss: 0.0247\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3430/4062], Loss: 0.0125\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3650/4062], Loss: 0.0036\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3440/4062], Loss: 0.0218\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3660/4062], Loss: 0.0223\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3450/4062], Loss: 0.0409\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3670/4062], Loss: 0.0112\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3460/4062], Loss: 0.0111\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3680/4062], Loss: 0.0631\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3470/4062], Loss: 0.0191\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3690/4062], Loss: 0.0085\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3480/4062], Loss: 0.0053\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3700/4062], Loss: 0.0070\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3490/4062], Loss: 0.0187\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3710/4062], Loss: 0.0053\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3500/4062], Loss: 0.0026\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3720/4062], Loss: 0.0179\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3510/4062], Loss: 0.0070\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3730/4062], Loss: 0.0091\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3520/4062], Loss: 0.0285\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3740/4062], Loss: 0.0026\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3530/4062], Loss: 0.0067\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3750/4062], Loss: 0.0167\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3540/4062], Loss: 0.0482\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3760/4062], Loss: 0.0176\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3550/4062], Loss: 0.0012\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3770/4062], Loss: 0.0106\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3560/4062], Loss: 0.0154\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3780/4062], Loss: 0.0172\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3570/4062], Loss: 0.0047\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3790/4062], Loss: 0.0158\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3580/4062], Loss: 0.0060\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3800/4062], Loss: 0.0155\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3590/4062], Loss: 0.0229\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3810/4062], Loss: 0.0096\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3600/4062], Loss: 0.0127\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3820/4062], Loss: 0.0173\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3610/4062], Loss: 0.0085\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3830/4062], Loss: 0.0171\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3620/4062], Loss: 0.0126\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3840/4062], Loss: 0.0079\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3630/4062], Loss: 0.0093\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3850/4062], Loss: 0.0051\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3640/4062], Loss: 0.0155\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3860/4062], Loss: 0.0618\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3650/4062], Loss: 0.0079\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3870/4062], Loss: 0.0134\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3880/4062], Loss: 0.0285\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3660/4062], Loss: 0.0299\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3890/4062], Loss: 0.0224\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3670/4062], Loss: 0.0400\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3900/4062], Loss: 0.0077\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3680/4062], Loss: 0.0314\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3910/4062], Loss: 0.0225\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3690/4062], Loss: 0.0639\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3920/4062], Loss: 0.0040\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3700/4062], Loss: 0.0267\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3930/4062], Loss: 0.0286\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3710/4062], Loss: 0.0112\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3940/4062], Loss: 0.0126\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3720/4062], Loss: 0.0251\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3950/4062], Loss: 0.0056\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3730/4062], Loss: 0.0095\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3960/4062], Loss: 0.0069\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3740/4062], Loss: 0.0129\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3970/4062], Loss: 0.0192\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3750/4062], Loss: 0.0150\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3980/4062], Loss: 0.0263\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3760/4062], Loss: 0.0137\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [3990/4062], Loss: 0.0086\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3770/4062], Loss: 0.0089\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [4000/4062], Loss: 0.0179\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3780/4062], Loss: 0.0171\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [4010/4062], Loss: 0.0256\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3790/4062], Loss: 0.0083\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [4020/4062], Loss: 0.0127\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3800/4062], Loss: 0.0202\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [4030/4062], Loss: 0.0131\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3810/4062], Loss: 0.0217\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [4040/4062], Loss: 0.0203\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3820/4062], Loss: 0.0165\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [4050/4062], Loss: 0.0357\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3830/4062], Loss: 0.0188\u001b[0m\n",
      "\u001b[34mEpoch [1/1], Batch [4060/4062], Loss: 0.0079\u001b[0m\n",
      "\u001b[34mEpoch 1/1, Loss: 0.0413228488914401\u001b[0m\n",
      "\u001b[34mUpdated Learning Rate: [3.9800000000000005e-05]\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3840/4062], Loss: 0.0305\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3850/4062], Loss: 0.0117\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3860/4062], Loss: 0.0325\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3870/4062], Loss: 0.0179\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3880/4062], Loss: 0.0071\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3890/4062], Loss: 0.0228\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3900/4062], Loss: 0.0081\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3910/4062], Loss: 0.0179\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3920/4062], Loss: 0.0150\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3930/4062], Loss: 0.0067\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3940/4062], Loss: 0.0081\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3950/4062], Loss: 0.0092\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3960/4062], Loss: 0.0080\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3970/4062], Loss: 0.0077\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3980/4062], Loss: 0.0106\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [3990/4062], Loss: 0.0486\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [4000/4062], Loss: 0.0040\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [4010/4062], Loss: 0.0094\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [4020/4062], Loss: 0.0075\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [4030/4062], Loss: 0.0077\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [4040/4062], Loss: 0.0053\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [4050/4062], Loss: 0.0037\u001b[0m\n",
      "\u001b[35mEpoch [1/1], Batch [4060/4062], Loss: 0.0150\u001b[0m\n",
      "\u001b[35mEpoch 1/1, Loss: 0.041055746151450544\u001b[0m\n",
      "\u001b[35mUpdated Learning Rate: [3.9800000000000005e-05]\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\u001b[0m\n",
      "\u001b[34mprecision    recall  f1-score   support\n",
      "       clean       1.00      0.69      0.82       753\n",
      "   overdrive       1.00      0.99      0.99      3012\n",
      "  distortion       0.99      1.00      0.99      4518\n",
      "        fuzz       0.99      1.00      1.00      5271\n",
      "     tremolo       1.00      1.00      1.00      3765\n",
      "      phaser       0.99      1.00      0.99      4518\n",
      "     flanger       0.85      1.00      0.92      3012\n",
      "      chorus       0.91      1.00      0.95      5271\n",
      "       delay       0.95      0.97      0.96      6777\n",
      " hall_reverb       0.93      0.92      0.92      4518\u001b[0m\n",
      "\u001b[34mplate_reverb       0.86      0.98      0.92      3012\n",
      "     octaver       1.00      0.99      0.99      2259\n",
      " auto_filter       1.00      0.96      0.98      3765\n",
      "   micro avg       0.95      0.98      0.97     50451\n",
      "   macro avg       0.96      0.96      0.96     50451\u001b[0m\n",
      "\u001b[34mweighted avg       0.96      0.98      0.97     50451\n",
      " samples avg       0.95      0.97      0.96     50451\u001b[0m\n",
      "\u001b[34mValidation Loss: 0.0261, Accuracy: 0.8965, Precision: 0.9593, Recall: 0.9605, F1-score: 0.9568\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"spectrogramCNN_sagemaker.py\", line 229, in <module>\u001b[0m\n",
      "\u001b[34mtrain(parser.parse_args())\n",
      "  File \"spectrogramCNN_sagemaker.py\", line 196, in train\u001b[0m\n",
      "\u001b[34msave_model(model, args.model_dir)\n",
      "  File \"spectrogramCNN_sagemaker.py\", line 206, in save_model\u001b[0m\n",
      "\u001b[34mlogger.info(\"Saving the model.\")\u001b[0m\n",
      "\u001b[34mNameError: name 'logger' is not defined\u001b[0m\n",
      "\u001b[34m2025-02-15 17:56:17,692 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2025-02-15 17:56:17,693 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 1 from exiting process.\u001b[0m\n",
      "\u001b[34m2025-02-15 17:56:17,694 sagemaker-training-toolkit ERROR    Reporting training FAILURE\u001b[0m\n",
      "\u001b[34m2025-02-15 17:56:17,694 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mExitCode 1\u001b[0m\n",
      "\u001b[34mErrorMessage \"NameError: name 'logger' is not defined\"\u001b[0m\n",
      "\u001b[34mCommand \"/opt/conda/bin/python3.8 spectrogramCNN_sagemaker.py --epochs 1\"\u001b[0m\n",
      "\u001b[34m2025-02-15 17:56:17,694 sagemaker-training-toolkit ERROR    Encountered exit_code 1\u001b[0m\n",
      "\n",
      "2025-02-15 22:56:43 Uploading - Uploading generated training model\n",
      "2025-02-15 22:56:43 Failed - Training job failed\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job pytorch-training-2025-02-15-19-50-01-824: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"NameError: name 'logger' is not defined\"\nCommand \"/opt/conda/bin/python3.8 spectrogramCNN_sagemaker.py --epochs 1\", exit code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms3://toneclone-bucket/Training Data/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms3://toneclone-bucket/Validation Data/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/workflow/pipeline_context.py:346\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/estimator.py:1350\u001b[0m, in \u001b[0;36mEstimatorBase.fit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job)\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 1350\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_training_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/estimator.py:2720\u001b[0m, in \u001b[0;36m_TrainingJob.wait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   2718\u001b[0m \u001b[38;5;66;03m# If logs are requested, call logs_for_jobs.\u001b[39;00m\n\u001b[1;32m   2719\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logs \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 2720\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogs_for_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2721\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2722\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mwait_for_job(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_name)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/session.py:5853\u001b[0m, in \u001b[0;36mSession.logs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   5832\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlogs_for_job\u001b[39m(\u001b[38;5;28mself\u001b[39m, job_name, wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, poll\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, log_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll\u001b[39m\u001b[38;5;124m\"\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   5833\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Display logs for a given training job, optionally tailing them until job is complete.\u001b[39;00m\n\u001b[1;32m   5834\u001b[0m \n\u001b[1;32m   5835\u001b[0m \u001b[38;5;124;03m    If the output is a tty or a Jupyter cell, it will be color-coded\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5851\u001b[0m \u001b[38;5;124;03m        exceptions.UnexpectedStatusException: If waiting and the training job fails.\u001b[39;00m\n\u001b[1;32m   5852\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5853\u001b[0m     \u001b[43m_logs_for_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/session.py:8455\u001b[0m, in \u001b[0;36m_logs_for_job\u001b[0;34m(sagemaker_session, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   8452\u001b[0m             last_profiler_rule_statuses \u001b[38;5;241m=\u001b[39m profiler_rule_statuses\n\u001b[1;32m   8454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 8455\u001b[0m     \u001b[43m_check_job_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrainingJobStatus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   8456\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dot:\n\u001b[1;32m   8457\u001b[0m         \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/session.py:8508\u001b[0m, in \u001b[0;36m_check_job_status\u001b[0;34m(job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   8502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCapacityError\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(reason):\n\u001b[1;32m   8503\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mCapacityError(\n\u001b[1;32m   8504\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   8505\u001b[0m         allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   8506\u001b[0m         actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   8507\u001b[0m     )\n\u001b[0;32m-> 8508\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedStatusException(\n\u001b[1;32m   8509\u001b[0m     message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   8510\u001b[0m     allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   8511\u001b[0m     actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   8512\u001b[0m )\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job pytorch-training-2025-02-15-19-50-01-824: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"NameError: name 'logger' is not defined\"\nCommand \"/opt/conda/bin/python3.8 spectrogramCNN_sagemaker.py --epochs 1\", exit code: 1"
     ]
    }
   ],
   "source": [
    "estimator.fit({\"training\": 's3://toneclone-bucket/Training Data/',\"validation\": 's3://toneclone-bucket/Validation Data/'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec093f0f-940e-40d1-8e7c-7af047895baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2efa90e-6dfc-4516-b842-b1c65b3edc73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1f90ba-8cf9-4c5e-9ee8-e9fbdb796078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
